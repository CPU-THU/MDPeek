diff --git a/llvm/include/llvm/Bitcode/LLVMBitCodes.h b/llvm/include/llvm/Bitcode/LLVMBitCodes.h
index de4fe663032..15603e9543a 100644
--- a/llvm/include/llvm/Bitcode/LLVMBitCodes.h
+++ b/llvm/include/llvm/Bitcode/LLVMBitCodes.h
@@ -635,6 +635,7 @@ enum AttributeKindCodes {
   ATTR_KIND_OPT_FOR_FUZZING = 57,
   ATTR_KIND_SHADOWCALLSTACK = 58,
   ATTR_KIND_SPECULATIVE_LOAD_HARDENING = 59,
+  ATTR_KIND_MDU_MITIGATE = 69,
   ATTR_KIND_IMMARG = 60,
   ATTR_KIND_WILLRETURN = 61,
   ATTR_KIND_NOFREE = 62,
diff --git a/llvm/include/llvm/IR/Attributes.td b/llvm/include/llvm/IR/Attributes.td
index 395f9dbfb17..e8445ebf170 100644
--- a/llvm/include/llvm/IR/Attributes.td
+++ b/llvm/include/llvm/IR/Attributes.td
@@ -214,6 +214,9 @@ def SanitizeMemTag : EnumAttr<"sanitize_memtag">;
 /// this attribute will always be lowered with hardening enabled.
 def SpeculativeLoadHardening : EnumAttr<"speculative_load_hardening">;
 
+/// MDU Mitigation is enabled.
+def MDUMitigation : EnumAttr<"mdu_mitigation">;
+
 /// Argument is swift error.
 def SwiftError : EnumAttr<"swifterror">;
 
@@ -280,6 +283,7 @@ def : MergeRule<"setOR<NoImplicitFloatAttr>">;
 def : MergeRule<"setOR<NoJumpTablesAttr>">;
 def : MergeRule<"setOR<ProfileSampleAccurateAttr>">;
 def : MergeRule<"setOR<SpeculativeLoadHardeningAttr>">;
+def : MergeRule<"setOR<MDUMitigationAttr>">;
 def : MergeRule<"adjustCallerSSPLevel">;
 def : MergeRule<"adjustCallerStackProbes">;
 def : MergeRule<"adjustCallerStackProbeSize">;
diff --git a/llvm/lib/AsmParser/LLParser.cpp b/llvm/lib/AsmParser/LLParser.cpp
index c9f21ee8382..3f0a8052b5e 100644
--- a/llvm/lib/AsmParser/LLParser.cpp
+++ b/llvm/lib/AsmParser/LLParser.cpp
@@ -1348,6 +1348,9 @@ bool LLParser::ParseFnAttributeValuePairs(AttrBuilder &B,
     case lltok::kw_speculative_load_hardening:
       B.addAttribute(Attribute::SpeculativeLoadHardening);
       break;
+    case lltok::kw_mdu_mitigation:
+      B.addAttribute(Attribute::MDUMitigation);
+      break;
     case lltok::kw_strictfp: B.addAttribute(Attribute::StrictFP); break;
     case lltok::kw_uwtable: B.addAttribute(Attribute::UWTable); break;
     case lltok::kw_willreturn: B.addAttribute(Attribute::WillReturn); break;
@@ -1724,6 +1727,7 @@ bool LLParser::ParseOptionalParamAttrs(AttrBuilder &B) {
     case lltok::kw_sanitize_memory:
     case lltok::kw_sanitize_thread:
     case lltok::kw_speculative_load_hardening:
+    case lltok::kw_mdu_mitigation:
     case lltok::kw_ssp:
     case lltok::kw_sspreq:
     case lltok::kw_sspstrong:
@@ -1827,6 +1831,7 @@ bool LLParser::ParseOptionalReturnAttrs(AttrBuilder &B) {
     case lltok::kw_sanitize_memory:
     case lltok::kw_sanitize_thread:
     case lltok::kw_speculative_load_hardening:
+    case lltok::kw_mdu_mitigation:
     case lltok::kw_ssp:
     case lltok::kw_sspreq:
     case lltok::kw_sspstrong:
diff --git a/llvm/lib/AsmParser/LLToken.h b/llvm/lib/AsmParser/LLToken.h
index 0fb3bae77dd..982a48d9a85 100644
--- a/llvm/lib/AsmParser/LLToken.h
+++ b/llvm/lib/AsmParser/LLToken.h
@@ -232,6 +232,7 @@ enum Kind {
   kw_sanitize_thread,
   kw_sanitize_memory,
   kw_speculative_load_hardening,
+  kw_mdu_mitigation,
   kw_strictfp,
   kw_swifterror,
   kw_swiftself,
diff --git a/llvm/lib/Bitcode/Reader/BitcodeReader.cpp b/llvm/lib/Bitcode/Reader/BitcodeReader.cpp
index 659e26c2bd2..1c7a623f920 100644
--- a/llvm/lib/Bitcode/Reader/BitcodeReader.cpp
+++ b/llvm/lib/Bitcode/Reader/BitcodeReader.cpp
@@ -1282,6 +1282,8 @@ static uint64_t getRawAttributeMask(Attribute::AttrKind Val) {
   case Attribute::ShadowCallStack: return 1ULL << 59;
   case Attribute::SpeculativeLoadHardening:
     return 1ULL << 60;
+  case Attribute::MDUMitigation:
+    return 1ULL << 64;
   case Attribute::ImmArg:
     return 1ULL << 61;
   case Attribute::WillReturn:
@@ -1512,6 +1514,8 @@ static Attribute::AttrKind getAttrFromCode(uint64_t Code) {
     return Attribute::SanitizeMemory;
   case bitc::ATTR_KIND_SPECULATIVE_LOAD_HARDENING:
     return Attribute::SpeculativeLoadHardening;
+  case bitc::ATTR_KIND_MDU_MITIGATE:
+    return Attribute::MDUMitigation;
   case bitc::ATTR_KIND_SWIFT_ERROR:
     return Attribute::SwiftError;
   case bitc::ATTR_KIND_SWIFT_SELF:
diff --git a/llvm/lib/Bitcode/Writer/BitcodeWriter.cpp b/llvm/lib/Bitcode/Writer/BitcodeWriter.cpp
index 9c15a5f9f19..515e0ef3d9b 100644
--- a/llvm/lib/Bitcode/Writer/BitcodeWriter.cpp
+++ b/llvm/lib/Bitcode/Writer/BitcodeWriter.cpp
@@ -713,6 +713,8 @@ static uint64_t getAttrKindEncoding(Attribute::AttrKind Kind) {
     return bitc::ATTR_KIND_SANITIZE_MEMORY;
   case Attribute::SpeculativeLoadHardening:
     return bitc::ATTR_KIND_SPECULATIVE_LOAD_HARDENING;
+  case Attribute::MDUMitigation:
+    return bitc::ATTR_KIND_MDU_MITIGATE;
   case Attribute::SwiftError:
     return bitc::ATTR_KIND_SWIFT_ERROR;
   case Attribute::SwiftSelf:
diff --git a/llvm/lib/IR/Attributes.cpp b/llvm/lib/IR/Attributes.cpp
index f67d96a854f..06927a12936 100644
--- a/llvm/lib/IR/Attributes.cpp
+++ b/llvm/lib/IR/Attributes.cpp
@@ -415,6 +415,8 @@ std::string Attribute::getAsString(bool InAttrGrp) const {
     return "signext";
   if (hasAttribute(Attribute::SpeculativeLoadHardening))
     return "speculative_load_hardening";
+  if (hasAttribute(Attribute::MDUMitigation))
+    return "mdu_mitigation";
   if (hasAttribute(Attribute::Speculatable))
     return "speculatable";
   if (hasAttribute(Attribute::StackProtect))
diff --git a/llvm/lib/IR/Verifier.cpp b/llvm/lib/IR/Verifier.cpp
index c518ae87ea9..2bf84d2bdb4 100644
--- a/llvm/lib/IR/Verifier.cpp
+++ b/llvm/lib/IR/Verifier.cpp
@@ -1582,6 +1582,7 @@ static bool isFuncOnlyAttr(Attribute::AttrKind Kind) {
   case Attribute::InaccessibleMemOrArgMemOnly:
   case Attribute::AllocSize:
   case Attribute::SpeculativeLoadHardening:
+  case Attribute::MDUMitigation:
   case Attribute::Speculatable:
   case Attribute::StrictFP:
   case Attribute::NullPointerIsValid:
diff --git a/llvm/lib/Target/X86/CMakeLists.txt b/llvm/lib/Target/X86/CMakeLists.txt
index 729934b294b..7a2d605bee9 100644
--- a/llvm/lib/Target/X86/CMakeLists.txt
+++ b/llvm/lib/Target/X86/CMakeLists.txt
@@ -65,6 +65,7 @@ set(sources
   X86SelectionDAGInfo.cpp
   X86ShuffleDecodeConstantPool.cpp
   X86SpeculativeLoadHardening.cpp
+  X86MDUMitigation.cpp
   X86SpeculativeExecutionSideEffectSuppression.cpp
   X86Subtarget.cpp
   X86TargetMachine.cpp
diff --git a/llvm/lib/Target/X86/X86.h b/llvm/lib/Target/X86/X86.h
index 91ba4e3d091..00daff3485c 100644
--- a/llvm/lib/Target/X86/X86.h
+++ b/llvm/lib/Target/X86/X86.h
@@ -143,6 +143,7 @@ InstructionSelector *createX86InstructionSelector(const X86TargetMachine &TM,
 FunctionPass *createX86LoadValueInjectionLoadHardeningPass();
 FunctionPass *createX86LoadValueInjectionRetHardeningPass();
 FunctionPass *createX86SpeculativeLoadHardeningPass();
+FunctionPass *createX86MDUMitigationPass();
 FunctionPass *createX86SpeculativeExecutionSideEffectSuppression();
 
 void initializeEvexToVexInstPassPass(PassRegistry &);
@@ -165,6 +166,7 @@ void initializeX86LoadValueInjectionRetHardeningPassPass(PassRegistry &);
 void initializeX86OptimizeLEAPassPass(PassRegistry &);
 void initializeX86PartialReductionPass(PassRegistry &);
 void initializeX86SpeculativeLoadHardeningPassPass(PassRegistry &);
+void initializeX86MDUMitigationPassPass(PassRegistry &);
 void initializeX86SpeculativeExecutionSideEffectSuppressionPass(PassRegistry &);
 
 namespace X86AS {
diff --git a/llvm/lib/Target/X86/X86MDUMitigation.cpp b/llvm/lib/Target/X86/X86MDUMitigation.cpp
new file mode 100644
index 00000000000..6f2e4f56b3d
--- /dev/null
+++ b/llvm/lib/Target/X86/X86MDUMitigation.cpp
@@ -0,0 +1,2120 @@
+#include "X86.h"
+#include "X86InstrBuilder.h"
+#include "X86InstrInfo.h"
+#include "X86Subtarget.h"
+#include "llvm/ADT/ArrayRef.h"
+#include "llvm/ADT/DenseMap.h"
+#include "llvm/ADT/Optional.h"
+#include "llvm/ADT/STLExtras.h"
+#include "llvm/ADT/ScopeExit.h"
+#include "llvm/ADT/SmallPtrSet.h"
+#include "llvm/ADT/SmallSet.h"
+#include "llvm/ADT/SmallVector.h"
+#include "llvm/ADT/SparseBitVector.h"
+#include "llvm/ADT/Statistic.h"
+#include "llvm/CodeGen/MachineBasicBlock.h"
+#include "llvm/CodeGen/MachineConstantPool.h"
+#include "llvm/CodeGen/MachineFunction.h"
+#include "llvm/CodeGen/MachineFunctionPass.h"
+#include "llvm/CodeGen/MachineInstr.h"
+#include "llvm/CodeGen/MachineInstrBuilder.h"
+#include "llvm/CodeGen/MachineModuleInfo.h"
+#include "llvm/CodeGen/MachineOperand.h"
+#include "llvm/CodeGen/MachineRegisterInfo.h"
+#include "llvm/CodeGen/MachineSSAUpdater.h"
+#include "llvm/CodeGen/TargetInstrInfo.h"
+#include "llvm/CodeGen/TargetRegisterInfo.h"
+#include "llvm/CodeGen/TargetSchedule.h"
+#include "llvm/CodeGen/TargetSubtargetInfo.h"
+#include "llvm/IR/DebugLoc.h"
+#include "llvm/MC/MCSchedule.h"
+#include "llvm/Pass.h"
+#include "llvm/Support/CommandLine.h"
+#include "llvm/Support/Debug.h"
+#include "llvm/Support/raw_ostream.h"
+#include "llvm/Support/Alignment.h"
+#include "llvm/Target/TargetMachine.h"
+#include <algorithm>
+#include <cassert>
+#include <iterator>
+#include <utility>
+
+using namespace llvm;         // 使用 llvm 命名空间
+
+#define PASS_KEY "x86-mdu"    // X86 MDU Pass 的唯一标识符
+#define DEBUG_TYPE PASS_KEY   // X86 MDU Pass 的调试标识符
+
+/**
+ * ====================================== 
+ *  调试计数器定义 
+ * ======================================
+ */
+
+// 被分析到的条件分支数量
+// 由于加固而额外插入的指令数量
+STATISTIC(NumInstsInserted, "Number of instructions inserted");
+// 由于加固而额外插入的 lfence 指令数量
+STATISTIC(NumFENCEsInserted, "Number of lfence instructions inserted");
+
+/**
+ * ====================================== 
+ *  设置 Pass 的命令行控制参数
+ * ======================================
+ */
+
+// 是否使用 MDU 防御 Pass
+// 命令行参数: -x86-mdu-mitigation
+// 默认: false
+static cl::opt<bool> EnableMDUMitigation(
+    "x86-mdu-mitigation",
+    cl::desc("Force enable mdu mitigation"), cl::init(false),
+    cl::Hidden);
+
+// 是否使用 store-load coupling 加固 load，如果是，则屏蔽其他加固方式
+// 命令行参数: -x86-mdu-coupling
+// 默认: true
+static cl::opt<bool> EnableCoupling(
+    PASS_KEY "-coupling",
+    cl::desc("Harden loads with store-load coupling"), cl::init(true),
+    cl::Hidden);
+
+// 是否使用 fence 加固 load，以及使用哪类 fence
+// 命令行参数: -x86-mdu-fence-load
+// 0: 不使用 fence
+// 1: 使用 lfence
+// 2: 使用 mfence
+// 3: 使用 push pop
+// 默认: 0
+// warning: 如果 rsp 不在栈顶，使用 push pop 可能破坏程序 stack，导致程序出错
+static cl::opt<int> FenceLoad(
+    PASS_KEY "-fence-load",
+    cl::desc("Harden loads with fence instructions"), cl::init(0),
+    cl::Hidden);
+
+// 是否使用 fence 加固 store，以及使用哪类 fence
+// 命令行参数: -x86-mdu-fence-store
+// 0: 不使用 fence
+// 1: 使用 lfence，插在 store 前
+// 2: 使用 mfence，插在 store 前
+// 3: 使用 lfence，插在 store 后
+// 4: 使用 mfence，插在 store 后
+// 默认: 0
+static cl::opt<int> FenceStore(
+    PASS_KEY "-fence-store",
+    cl::desc("Harden stores with fence instructions"), cl::init(0),
+    cl::Hidden);
+
+// 是否 dump 存储分析结果的数据结构
+// 命令行参数: -x86-mdu-dump-for-debug
+// 默认: false
+static cl::opt<bool> AlignLoad(
+    PASS_KEY "-align-load",
+    cl::desc("Align load instructions to 256 bytes"), cl::init(false),
+    cl::Hidden);
+
+// 是否需要使用 WhiteList 进行优化
+// 命令行参数: -x86-mdu-enable-whitelist
+// 默认: false
+static cl::opt<bool> EnableWhiteList(
+    PASS_KEY "-enable-whitelist",
+    cl::desc("Enable Whitelist Optimization"), cl::init(false),
+    cl::Hidden);
+
+// 最大的 delay capacity
+// 命令行参数: -x86-mdu-delay-capacity-max
+// 默认: 224 (Skylake ROB Size)
+static cl::opt<int> DelayCapacityMax(
+    PASS_KEY "-delay-capacity-max",
+    cl::desc("Max Delay Capacity, Suggested to be the same Size as ROB"),
+    cl::init(224),
+    cl::Hidden);
+
+// 数据移动指令的 delay capacity
+// 命令行参数: -x86-mdu-delay-capacity-copy
+// 默认: 1
+static cl::opt<int> DelayCapacityCopy(
+    PASS_KEY "-delay-capacity-copy",
+    cl::desc("Delay Capacity of mov instructions"), cl::init(1),
+    cl::Hidden);
+
+// 访存指令的 delay capacity
+// 命令行参数: -x86-mdu-delay-capacity-memory
+// 默认: 120
+static cl::opt<int> DelayCapacityMemory(
+    PASS_KEY "-delay-capacity-memory",
+    cl::desc("Delay Capacity of loads"), cl::init(20),
+    cl::Hidden);
+
+// 算术指令的 delay capacity
+// 命令行参数: -x86-mdu-delay-capacity-calculation
+// 默认: 90
+static cl::opt<int> DelayCapacityCalculation(
+    PASS_KEY "-delay-capacity-calculation",
+    cl::desc("Delay Capacity of calculations"), cl::init(3),
+    cl::Hidden);
+
+// 当 MF 的基本块数量大于上限进行退化，不计算 CFG 最短路径，采用简化的启发式算法
+// 命令行参数: -x86-mdu-opt-mf-size
+// 默认: 1000
+static cl::opt<int> MFOptSize(
+    PASS_KEY "-opt-mf-size",
+    cl::desc("Optimized size of MachineFunction"), cl::init(1000),
+    cl::Hidden);
+
+// 是否 dump 存储分析结果的数据结构
+// 命令行参数: -x86-mdu-dump-for-debug
+// 默认: false
+static cl::opt<bool> DumpInfo(
+    PASS_KEY "-dump-for-debug",
+    cl::desc("Dump Internal Data Structure for Debugging"), cl::init(false),
+    cl::Hidden);
+
+namespace {
+
+/**
+ * ====================================== 
+ *  Pass 声明
+ * ======================================
+ */
+
+// SLH Pass 继承自 MachineFunctionPass，属于后端 Pass
+class X86MDUMitigationPass : public MachineFunctionPass {
+public:
+
+  /**
+   *  构造函数，传入 Pass ID
+   */
+  X86MDUMitigationPass() : MachineFunctionPass(ID) { }
+
+  /**
+   *  Pass 名称
+   */
+  StringRef getPassName() const override {
+    return "X86 mdu mitigation";
+  }
+
+  /**
+   *  实现功能的核心函数，对每个 Function 的机器码进行分析
+   */
+  bool runOnMachineFunction(MachineFunction &MF) override;
+
+  void getAnalysisUsage(AnalysisUsage &AU) const override;
+
+  // Pass identification, replacement for typeid.
+  static char ID;
+
+private:
+
+    const int INF = std::numeric_limits<int>::max();
+
+    bool Optmized = false;
+
+    /** 存放某条 store 指令，以及该 store 与待分析指令或基本块的距离。
+     *  该结构体主要用于结构体 StoreLoadInfo 内。
+     */ 
+    struct StorePredInfo {
+      MachineInstr* storeInst;
+      int distance;
+    };
+
+  /** 
+   *  记录一个基本块内所有的 store 和 load 指令。
+   *  同时，围绕这些 store 和 load 指令，记录：
+   *  1. 基本块内最后一条 store 指令。
+   *  2. 基本块内最后一条 store 指令，与 Terminator 的距离。如果没有 Terminator，
+   *     则计算 store 到最后一条指令的距离。如果没有 store，则计算基本块内的指令条数。
+   *  3. 基本块内每条 load 与最近一条 store 的距离，如果没有 store，则计算 load
+   *     与基本块入口第一条指令的距离。
+   *  4. 基本块前驱路径中所有可能的最后一条 store 指令，以及 store 与基本块的最近距离。
+   */ 
+  struct StoreLoadInfo {
+    // 当前记录所对应的基本块
+    // 只要是在 pass 中能访问的基本块，都会建立一个对应的 StoreLoadInfo
+    MachineBasicBlock *MBB;
+
+    // 按顺序记录基本块内的所有 store 指令和 load 指令
+    SmallVector<MachineInstr *, 4> StLdInsts;
+
+    // 存放基本块 MBB 所有前驱路径上最后一条 store 信息
+    DenseMap<MachineInstr *, StorePredInfo> PredStoreInfosForMBB;
+
+    // 存放每条 load 在基本块内的最近前驱 store 信息
+    // 如果 load 没有同一基本块内的前驱，则列表为空
+    DenseMap<MachineInstr *, StorePredInfo> PredStoreInfoForLoad;
+
+    // 基本块中最后一条 store 指令
+    MachineInstr* LastStoreInst;
+
+    // 基本块中最后一条 store 指令距离基本块最后一个终止符的距离
+    int LastStoreDistance;    
+  };
+
+  /**
+   *  记录基本块的距离信息，包括自身距离，以及基本块彼此的最短距离。
+   *  我们定义一个基本块自身的距离，为其内部有效指令跳数；
+   *  定义两个基本块的距离，为一个基本块入口到另一基本块入口的一条路径上的指令条数。
+   */
+  struct DistanceInfo {
+    // 当前记录所对应的基本块
+    MachineBasicBlock *MBB;
+
+    // 一个 map，key 为一个基本块，value 为 MBB 与这一基本块的最短距离
+    DenseMap<MachineBasicBlock *, int> ShortestDistance;
+
+    int selfSize;
+  };
+
+  /** 
+   *  记录一条 store 指令的地址生成指令，回溯到操作数来自 global 数据，或者函数参数，
+   *  或者立即数赋值指令时停止。如果回溯超过 4 层，也停止回溯。
+   *  估计这些地址生成指令与 store 指令的距离。
+   *  这些信息将作为 Whitelist 的主要依据。
+   */ 
+  struct StoreDefInfo {
+    // 第一层定义指令
+    SmallSet<MachineInstr *, 8> OneLevelDefs;
+
+    // 第二层定义指令
+    SmallSet<MachineInstr *, 16> TwoLevelDefs;
+    
+    // 第三层定义指令
+    SmallSet<MachineInstr *, 32> ThreeLevelDefs;
+    
+    // 第四层定义指令
+    SmallSet<MachineInstr *, 32> FourLevelDefs;
+  };
+
+  /**
+   *  维护一个 CFG 全局可见的寄存器，这个寄存器用于存放前驱地址。
+   *  我们使用 SSAUpdater 维护这个寄存器，SSAUpdater 负责一个变量 (虚拟寄存器) 
+   *  在 CFG 间的传递，能够在一个基本块内部更新这个变量，
+   *  并且会自动生成 PHI 指令来维护这个变量在前驱和后继间的传递。
+   */
+  struct StoreAddrState {
+    const TargetRegisterClass *RC;
+    MachineSSAUpdater SSA;
+
+    StoreAddrState(MachineFunction &MF, const TargetRegisterClass *RC)
+        : RC(RC), SSA(MF) {}
+  };
+
+  void hardenStorewithFENCE(MachineFunction &MF,
+    DenseMap<MachineBasicBlock*, StoreLoadInfo> StldInfos,
+    DenseMap<MachineInstr*, int> DelayedStoreMap);
+  void hardenLoadwithFENCE(MachineFunction &MF,
+    DenseMap<MachineBasicBlock*, StoreLoadInfo> StldInfos,
+    DenseMap<MachineInstr*, int> DelayedStoreMap);
+  void hardenLoadwithAlign(MachineFunction &MF,
+    DenseMap<MachineBasicBlock*, StoreLoadInfo> StldInfos,
+    DenseMap<MachineInstr*, int> DelayedStoreMap);    
+  void hardenLoadwithCoupling(MachineFunction &MF,
+    DenseMap<MachineBasicBlock*, StoreLoadInfo> StldInfos,
+    DenseMap<MachineInstr*, int> DelayedStoreMap);  
+
+  DenseMap<MachineBasicBlock*, DistanceInfo> collectDistanceInfo(MachineFunction &MF);
+  DenseMap<MachineBasicBlock*, StoreLoadInfo> collectBlockStldInfo(MachineFunction &MF, 
+    DenseMap<MachineBasicBlock*, DistanceInfo> DistanceInfos);
+  DenseMap<MachineInstr*, StoreDefInfo> collectStoreDefInfo(MachineFunction &MF,
+    DenseMap<MachineBasicBlock*, StoreLoadInfo> StoreLoadInfos);
+  DenseMap<MachineInstr*, int> analyseDelayedStore(MachineFunction &MF,
+    DenseMap<MachineBasicBlock*, DistanceInfo> DistanceInfos,
+    DenseMap<MachineInstr*, StoreDefInfo> StoreDefInfos);
+  void generateStoreAddr(MachineFunction &MF,
+    DenseMap<MachineBasicBlock*, StoreLoadInfo> StldInfos,
+    DenseMap<MachineInstr*, int> DelayedStoreMap);    
+
+  MachineBasicBlock &splitBlockFromInstr(MachineInstr* Instr);
+  bool loadNeedHardened(MachineInstr* LoadInst, 
+    DenseMap<MachineBasicBlock*, StoreLoadInfo> StoreLoadInfos,
+    DenseMap<MachineInstr*, int> DelayedStoreMap
+    );
+  int countInstBefore(MachineBasicBlock *MBB, MachineInstr *MI);
+  int countInstAfter(MachineBasicBlock *MBB, MachineInstr *MI);
+  int countInstBetween(MachineInstr *MI1, MachineInstr *MI2, 
+    DenseMap<MachineBasicBlock*, DistanceInfo> DistanceInfos);
+  int getDelayCapacity(MachineInstr* Instr);
+  int getSpecialArithmeticFactor(MachineInstr* Instr);
+  bool isLazyStoreorLazyLoad(MachineInstr* Instr);
+  SmallSet<MachineInstr *, 8> getDefInstrList (MachineInstr *Instr);
+  bool isEFLAGSLive(MachineBasicBlock &MBB, MachineBasicBlock::iterator I,
+    const TargetRegisterInfo &TRI);
+  unsigned saveEFLAGS(MachineBasicBlock &MBB,
+                      MachineBasicBlock::iterator InsertPt, DebugLoc Loc);
+  void restoreEFLAGS(MachineBasicBlock &MBB,
+                     MachineBasicBlock::iterator InsertPt, DebugLoc Loc,
+                     unsigned OFReg);
+
+  void dumpDistanceInfo(DenseMap<MachineBasicBlock*, DistanceInfo> Infos);
+  void dumpStoreLoadInfo(DenseMap<MachineBasicBlock*, StoreLoadInfo> Infos);
+  void dumpStoreDefInfo(DenseMap<MachineInstr*, StoreDefInfo> Infos);
+  void dumpDelayedStoreMap(DenseMap<MachineInstr*, int> Map);
+  void dumpLoadsToBeHardened(MachineFunction &MF,
+    DenseMap<MachineBasicBlock*, StoreLoadInfo> StldInfos,
+    DenseMap<MachineInstr*, int> DelayedStoreMap);
+
+  const X86Subtarget *Subtarget = nullptr;
+  MachineRegisterInfo *MRI = nullptr;
+  const X86InstrInfo *TII = nullptr;
+  const TargetRegisterInfo *TRI = nullptr;
+  Optional<StoreAddrState> SAS;
+
+};
+
+} // end anonymous namespace
+
+/**
+ * ====================================== 
+ *  Pass 实现
+ * ======================================
+ */
+
+char X86MDUMitigationPass::ID = 0;
+
+void X86MDUMitigationPass::getAnalysisUsage(
+    AnalysisUsage &AU) const {
+  MachineFunctionPass::getAnalysisUsage(AU);
+}
+
+bool X86MDUMitigationPass::runOnMachineFunction(
+    MachineFunction &MF) {
+  LLVM_DEBUG(dbgs() << "********** " << getPassName() << " : " << MF.getName()
+                    << " **********\n");
+
+  LLVM_DEBUG(dbgs() << "Hello World!\n";
+             dbgs() << "\n"; MF.verify(this));
+
+  if (!EnableMDUMitigation &&
+      !MF.getFunction().hasFnAttribute(Attribute::MDUMitigation))
+    return false;
+
+  if (MF.begin() == MF.end())
+    // 如果 MF 是一个空函数，无需加固，直接退出
+    return false;
+
+  // 初始化架构配置相关对象
+  Subtarget = &MF.getSubtarget<X86Subtarget>();
+  MRI = &MF.getRegInfo();
+  TII = Subtarget->getInstrInfo();
+  TRI = Subtarget->getRegisterInfo();
+
+  // 初始化 StoreAddrState
+  SAS.emplace(MF, &X86::GR64_NOSPRegClass);
+
+  // 初始化 SSAUpdater
+  unsigned AddrRegInit = MRI->createVirtualRegister(&X86::GR64_NOSPRegClass);
+
+  // 初始化地址寄存器的值
+  MachineBasicBlock &Entry = *MF.begin();
+  auto EntryInsertPt = Entry.SkipPHIsLabelsAndDebug(Entry.begin());
+  DebugLoc Loc;
+  BuildMI(Entry, EntryInsertPt, Loc, TII->get(X86::MOV64ri32), AddrRegInit)
+      .addImm(-1);
+  ++NumInstsInserted;
+  SAS->SSA.Initialize(AddrRegInit);
+
+
+  // 如果 MF 是一个空函数，无需加固，直接退出
+  if (MF.begin() == MF.end())
+    return false;
+  
+  // 如果，那么放弃精细分析，优化性能
+  if (MF.size() > (unsigned)MFOptSize) {
+    Optmized = true;
+  }
+
+  DenseMap<MachineBasicBlock*, DistanceInfo> DistanceInfos = collectDistanceInfo(MF);
+
+  if (DumpInfo) {
+    dumpDistanceInfo(DistanceInfos);
+  }
+
+  DenseMap<MachineBasicBlock*, StoreLoadInfo> StldInfos = 
+    collectBlockStldInfo(MF, DistanceInfos);
+  
+  if (DumpInfo) {
+    dumpStoreLoadInfo(StldInfos);
+  }
+  DenseMap<MachineInstr*, StoreDefInfo> StoreDefInfos = 
+    collectStoreDefInfo(MF, StldInfos);
+  
+  if (DumpInfo) {
+    dumpStoreDefInfo(StoreDefInfos);
+  }
+
+  DenseMap<MachineInstr*, int> DelayedStoreMap = 
+    analyseDelayedStore(MF, DistanceInfos, StoreDefInfos);
+  
+  if (DumpInfo) {
+    dumpDelayedStoreMap(DelayedStoreMap);
+  }
+
+  if (DumpInfo) {
+   dumpLoadsToBeHardened(MF, StldInfos, DelayedStoreMap); 
+  }
+
+  if (EnableCoupling) {
+    generateStoreAddr(MF, StldInfos, DelayedStoreMap);
+    hardenLoadwithCoupling(MF, StldInfos, DelayedStoreMap);
+    LLVM_DEBUG(dbgs() << "Exit hardenLoadwithCoupling\n");
+  }
+  else if (FenceLoad) {
+    hardenLoadwithFENCE(MF, StldInfos, DelayedStoreMap);
+  }
+  else if (FenceStore) {
+    hardenStorewithFENCE(MF, StldInfos, DelayedStoreMap);
+  }
+  else if (AlignLoad) {
+    hardenLoadwithAlign(MF, StldInfos, DelayedStoreMap);
+  }
+  return true;
+}
+
+DenseMap<MachineBasicBlock*, X86MDUMitigationPass::DistanceInfo>
+X86MDUMitigationPass::collectDistanceInfo(MachineFunction &MF) {
+
+  // 新建一个存放各个基本块 DistanceInfo 的列表
+  DenseMap<MachineBasicBlock*, DistanceInfo> Infos;
+
+  // 基本块数量过多时算法退化
+  if (Optmized) {
+    return Infos;
+  }
+
+  // 第一轮基本块遍历，收集每个基本块自身长度，初始化 DistanceInfo
+  for (MachineBasicBlock &MBB : MF) {
+    LLVM_DEBUG(dbgs() << MBB.getName() << ":\n");
+    // for (MachineInstr& MI : MBB) {
+    //   LLVM_DEBUG({
+    //     MI.dump();
+    //   });
+    // }
+    DenseMap<MachineBasicBlock *, int> ShortestDistanceInint;
+    int selfDistance = countInstAfter(&MBB, nullptr);
+    DistanceInfo Info = {&MBB, ShortestDistanceInint, selfDistance};
+    // 初始化基本块间彼此距离为 INF
+    for (MachineBasicBlock &MBBJ : MF) {
+      Info.ShortestDistance[&MBBJ] = INF;
+    }
+    // 初始化每个基本块 MBB 到其直接后继 SuccBB 的距离
+    // 由于我们定义的距离为基本块入口间的距离，所以对于直接后继，距离为 MBB 自身的长度
+    for (MachineBasicBlock *SuccBB : MBB.successors()) {
+      Info.ShortestDistance[SuccBB] = selfDistance;
+    }
+    Infos[&MBB] = Info;
+  }
+
+  
+  // 第二轮遍历，我们使用 Floyd-Warshall 算法，算法复杂度 O(n^3)
+  for (MachineBasicBlock &MBBI : MF) {
+    for (MachineBasicBlock &MBBJ : MF) {
+      for (MachineBasicBlock &MBBK : MF) {
+        if (Infos[&MBBI].ShortestDistance[&MBBK] != INF && 
+            Infos[&MBBK].ShortestDistance[&MBBJ] != INF) {
+              Infos[&MBBI].ShortestDistance[&MBBJ] = 
+                std::min(Infos[&MBBI].ShortestDistance[&MBBJ], 
+                  Infos[&MBBI].ShortestDistance[&MBBK] + 
+                  Infos[&MBBK].ShortestDistance[&MBBJ]);
+            }
+      }
+    }
+  }
+
+  return Infos;
+}
+
+DenseMap<MachineBasicBlock*, X86MDUMitigationPass::StoreLoadInfo> 
+X86MDUMitigationPass::collectBlockStldInfo(MachineFunction &MF, 
+DenseMap<MachineBasicBlock*, DistanceInfo> DistanceInfos) {
+
+  // 新建一个存放各个基本块 StoreLoadInfo 的列表
+  // StoreLoadInfo 中的 MBB 顺序就是默认的 CFG 遍历顺序
+  DenseMap<MachineBasicBlock*, StoreLoadInfo> Infos;
+
+  // 第一轮基本块遍历，收集每个基本块内部的 store 和 load 信息
+  for (MachineBasicBlock &MBB : MF) {
+
+    // 初始化一个空的 StoreLoadInfo，并与 MBB 建立链接
+    DenseMap<MachineInstr *, StorePredInfo> PredStoreInfosForMBBInit;
+    DenseMap<MachineInstr *, StorePredInfo> PredStoreInfoForLoadInit;
+    StoreLoadInfo Info = {&MBB, {}, PredStoreInfosForMBBInit, 
+                          PredStoreInfoForLoadInit, nullptr, 0};
+
+    // 遍历 MBB 中的所有指令
+    for (MachineInstr &MI : MBB) {
+      // 如果不是 store 和 load 指令，且不是 ret 指令，则跳过
+      // 注意 ret 指令不是 Terminator
+      if (!MI.mayLoadOrStore() && !MI.isReturn()) {
+        continue;
+      }
+
+      // 如果是 store，那么根据指令访问顺序，这条 store 是基本块中目前最后一条 store
+      if (MI.mayStore()) {
+        Info.LastStoreInst = &MI;
+      }
+
+      if (MI.mayLoad() || MI.isReturn()) {
+        Info.PredStoreInfoForLoad[&MI] = {nullptr, countInstBefore(&MBB, &MI)};
+        if (Info.LastStoreInst) {
+          Info.PredStoreInfoForLoad[&MI].storeInst = Info.LastStoreInst;
+          if (Optmized) {
+            // do nothing
+          }
+          else {
+            Info.PredStoreInfoForLoad[&MI].distance = countInstBetween(&MI, 
+              Info.LastStoreInst, DistanceInfos);
+          }
+        }
+      }
+
+      // 将这个 store 或 load 加入 Info
+      Info.StLdInsts.push_back(&MI);
+    }
+
+    // 计算最后一条 store 距离基本块最后一条指令的距离
+    // 如果不存在 store，则返回基本块的指令数量
+    Info.LastStoreDistance = countInstAfter(&MBB, Info.LastStoreInst);
+
+    // 将 Info 加入 Infos
+    Infos[&MBB] = Info;
+  }
+
+  // 第二轮基本块遍历，收集基本块之间的 store 和 load 信息
+  SmallDenseMap<MachineBasicBlock *, bool> collectComplete;
+  // 初始化 collectComplete，对于有前驱的 MBB，将标记置为 false
+  for (MachineBasicBlock &MBB : MF) {
+    collectComplete[&MBB] = !(MBB.pred_size() > 0);
+  }
+  bool allMBBComplete = false;
+  int loopCnt = 0;
+  while (!allMBBComplete) {
+    // avoid some corner cases with complex loops
+    if (loopCnt++ >= 3) {
+      break;
+    }
+    // LLVM_DEBUG(dbgs() << "    Stuck Here \n");
+    for (MachineBasicBlock &MBB : MF) {
+      // 当前 MBB 已经分析完毕
+      if (collectComplete[&MBB]) {
+        continue;
+      }
+
+      // 遍历所有前驱 PredMBB，算法复杂度 O(n^2)
+      // 1. 如果 PredMBB 包含 store，将 store 加入 MBB 的 PredStoreInfosForMBB 列表
+      // 2. 如果 PredMBB 不包含 store，将其 PredStoreInfosForMBB 的 store 加入 MBB
+      // 3. 如果满足 1，或者 PredMBB 的 collectComplete 标记为 true，
+      // 则将 MBB 的 collectComplete 标记置为 true
+      bool predComplete = true;
+      for (MachineBasicBlock *PredMBB : MBB.predecessors()) {
+        StoreLoadInfo& StoreLoadInfoPredMBB = Infos[PredMBB];
+        // 如果 PredMBB 包含 store，将其加入
+        if (StoreLoadInfoPredMBB.LastStoreInst) {
+          MachineInstr* LastStorePredMBB = StoreLoadInfoPredMBB.LastStoreInst;
+          int LastStoreDistanceMBB = StoreLoadInfoPredMBB.LastStoreDistance;
+          StorePredInfo newStoreInfo = {LastStorePredMBB, LastStoreDistanceMBB};
+          Infos[&MBB].PredStoreInfosForMBB.insert({LastStorePredMBB, newStoreInfo});
+        }
+        else {
+          // 只要有一个无 store 前驱尚未分析完毕，predComplete 标记就不能为 true
+          if (!collectComplete[PredMBB]) {
+            predComplete = false;
+            continue;
+          }
+          // 对于已分析完毕的无 store 前驱，将 store 信息并入 MBB
+          else {
+            for (auto entry: Infos[PredMBB].PredStoreInfosForMBB) {
+              StorePredInfo StoreInfo = {entry.second.storeInst, 0};
+              if (MBB.instr_begin() != MBB.end()) {
+                if (Optmized) {
+                  // do nothing
+                }
+                else {
+                  StoreInfo.distance = countInstBetween(entry.second.storeInst, 
+                    &MBB.instr_front(), DistanceInfos);
+                }
+              }
+              else {
+                StoreInfo.distance = countInstAfter(PredMBB, entry.second.storeInst);
+              }
+              Infos[&MBB].PredStoreInfosForMBB.insert({entry.first, StoreInfo});
+            }
+          }
+        }
+      }
+
+      // 如果所有前驱的 store 都分析完毕，那么标记该基本块的 collectComplete 为 true
+      // 特别的，如果前驱包含自身，那么自身需要排除在外，否则会死锁
+      if (predComplete) {
+        collectComplete[&MBB] = true;
+      }
+      else {
+        bool onlySelfIncomplete = true;
+        for (MachineBasicBlock *PredMBB : MBB.predecessors()) {
+          if (!collectComplete[PredMBB] && PredMBB != &MBB) {
+            onlySelfIncomplete = false;
+          }
+        }
+        if (onlySelfIncomplete) {
+          collectComplete[&MBB] = true;
+        }
+      }
+    }
+
+    // 检查是否所有 MBB 的前驱 store 信息收集完毕
+    allMBBComplete = true;
+    for (MachineBasicBlock &MBB : MF) {
+      if(!collectComplete[&MBB]) {
+        allMBBComplete = false;
+        break;
+      }
+    }
+  }
+
+  // 返回分析结果
+  return Infos;
+}
+
+DenseMap<MachineInstr*, X86MDUMitigationPass::StoreDefInfo> 
+X86MDUMitigationPass::collectStoreDefInfo(MachineFunction &MF, 
+  DenseMap<MachineBasicBlock*, StoreLoadInfo> StoreLoadInfos) {
+  // 存放需要分析地址生成指令的 Store
+  SmallSet<MachineInstr*, 24> StoresToBeAnalyzed;
+  // 新建一个存放各个 Store 指令的 Def 指令的列表
+  DenseMap<MachineInstr*, StoreDefInfo> Infos;
+
+  if (Optmized) { 
+    return Infos;
+  }
+
+  // 遍历基本块，筛选需要分析地址生成过程的 store
+  // 1. 如果基本块中包含 store，且这个 store 后面有 load 指令，且二者之间无其他 store，
+  // 那么需要分析这个 store.
+  // 2. 如果基本块不是以 store 开头，且包含 load，那么还需研究它的前驱 Store 的 Pred
+  for (MachineBasicBlock &MBB : MF) {
+    StoreLoadInfo &StldInfo = StoreLoadInfos[&MBB];
+    MachineInstr *LastStore = nullptr;
+    bool PredStoreNeedAnalyze = false;
+    for (MachineInstr *StLdInst : StldInfo.StLdInsts) {
+      if (StLdInst->mayLoad() || StLdInst->isReturn()) {
+        // 如果基本块第一条 load 之前没有 store
+        // 那么将基本块前驱 store 加入待分析 store
+        // 特别的，如果是自身同时包含 store 和 load 的指令，同样视为 load 
+        if (LastStore == nullptr) {
+          PredStoreNeedAnalyze = true;
+        }
+        // 否则，将上一条 store 加入待分析 store
+        else {
+          StoresToBeAnalyzed.insert(LastStore);
+        }
+      }
+      if (StLdInst->mayStore()) {
+        LastStore = StLdInst;
+      }
+    }
+    // 将前驱 store 加入待分析基本块
+    if (PredStoreNeedAnalyze) {
+      for (auto entry : StldInfo.PredStoreInfosForMBB) {
+        MachineInstr *InstStore = entry.first;
+        StoresToBeAnalyzed.insert(InstStore);
+      }
+    }
+  }
+  
+  // 对于每个待分析 Store，依次回溯前三个计算指令，PHI 指令视为一个 mov 指令
+  // 直到指令源操作数来自全局变量、函数参数，或者一个立即数为止
+  for (MachineInstr *StoreInst : StoresToBeAnalyzed) {
+    // 初始化 StoreDefInfo
+    StoreDefInfo Info = {{}, {}, {}};
+    // 获取 Store 指令的两个操作数的定义指令
+    SmallSet<MachineInstr *, 8> DefInsts = getDefInstrList(StoreInst);
+    // 将 Store 指令的直接定义指令插入 Info.OneLevelDefs
+    for (MachineInstr * Inst: DefInsts) {
+      Info.OneLevelDefs.insert(Inst);
+    }
+    // 获取 Info.TwoLevelDefs
+    for (MachineInstr * Inst: Info.OneLevelDefs) {
+      DefInsts = getDefInstrList(Inst);
+      for (MachineInstr * DefInst: DefInsts) {
+        if (Info.OneLevelDefs.find(DefInst) == Info.OneLevelDefs.end()) {
+          Info.TwoLevelDefs.insert(DefInst);
+        }
+      }
+    }
+    // 获取 Info.ThreeLevelDefs
+    for (MachineInstr * Inst: Info.TwoLevelDefs) {
+      DefInsts = getDefInstrList(Inst);
+      for (MachineInstr * DefInst: DefInsts) {
+        if (Info.TwoLevelDefs.find(DefInst) == Info.TwoLevelDefs.end()) {
+          Info.ThreeLevelDefs.insert(DefInst);
+        }
+      }
+    }
+    // 获取 Info.FourLevelDefs
+    for (MachineInstr * Inst: Info.ThreeLevelDefs) {
+      DefInsts = getDefInstrList(Inst);
+      for (MachineInstr * DefInst: DefInsts) {
+        if (Info.ThreeLevelDefs.find(DefInst) == Info.ThreeLevelDefs.end()) {
+          Info.FourLevelDefs.insert(DefInst);
+        }
+      }
+    }
+    Infos.insert({StoreInst, Info});
+  }
+
+  return Infos;
+}
+
+/**
+ *  设 op@d 表示 store 的地址生成指令，
+ *  我们定义 op@d 对 store 的影响距离 (distance of effect) 如下：
+ *                   ...
+ *                   op@d
+ * ----------------  ...    ---------------------------
+ *                   ...    distance of op@d and store
+ * capacity of op@d  store  ---------------------------
+ *                   ...    distance of effect by op@d
+ * ----------------- ...    ---------------------------
+ *                   
+ *  特别的，如果 op@d 与 store 的距离大于 op@d 的 delay capacity，
+ *  那么 op@d 对 store 的影响距离为 0。
+ *  我们定义 store 的影响距离，为所有 op@d 对 store 的影响范围中，使得
+ *  store 的影响范围最大的那个距离。
+ * 
+ *  @return 一个 map，key 为一个 store 指令，value 为 store 指令的影响距离。
+ */
+DenseMap<MachineInstr*, int> X86MDUMitigationPass::analyseDelayedStore(
+    MachineFunction &MF,
+    DenseMap<MachineBasicBlock*, DistanceInfo> DistanceInfos,
+    DenseMap<MachineInstr*, StoreDefInfo> StoreDefInfos) {
+  DenseMap<MachineInstr*, int> DelayedStoreMap;
+
+  if (Optmized) {
+    return DelayedStoreMap;
+  }
+
+  // 遍历 StoreDefInfos，如果开启了 Whitelist，访问 Store 的 Def 指令
+  // 如果 Def 至多三层，那么叠加它们的 delay
+  // 否则，将 delay 拉至最大值
+  for (auto StoreDefEntry : StoreDefInfos) {
+    MachineInstr* StoreInst = StoreDefEntry.first;
+    const StoreDefInfo& StoreDef = StoreDefEntry.second;
+    // 记录 Store 的每条前驱指令的 delay capacity
+    DenseMap<MachineInstr*, int> DelayInstMap;
+    // 如果使用 WhiteList 优化
+    if (EnableWhiteList) {
+      // 如果 Def 指令链小于 3 条 Def 指令
+      // 那么对于每一级 Level，计算其中所有指令与 Store 的距离 Distance
+      // 然后计算这些指令的 distance of effect
+      // 记录结果最大的那个
+      // 将每一级的最大结果求和，作为最终 store 的 distance of effect
+      int LevelOneDelayCapacity = 0;
+      int LevelTwoDelayCapacity = 0;
+      int LevelThreeDelayCapacity = 0;
+      if (StoreDef.FourLevelDefs.empty()) {
+        // OneLevelDefs
+        for (MachineInstr* Instr: StoreDef.OneLevelDefs) {
+          int Distance = countInstBetween(Instr, StoreInst, DistanceInfos);
+          int InstDelayCapacity = getDelayCapacity(Instr);
+          Distance = std::max(InstDelayCapacity - Distance, 0);
+          if (Distance > LevelOneDelayCapacity) {
+            LevelOneDelayCapacity = Distance;
+          }
+        }
+        // TwoLevelDefs
+        for (MachineInstr* Instr: StoreDef.TwoLevelDefs) {
+          int Distance = countInstBetween(Instr, StoreInst, DistanceInfos);
+          int InstDelayCapacity = getDelayCapacity(Instr);
+          Distance = std::max(InstDelayCapacity - Distance, 0);
+          if (Distance > LevelTwoDelayCapacity) {
+            LevelTwoDelayCapacity = Distance;
+          }
+        }
+        // ThreeLevelDefs
+        for (MachineInstr* Instr: StoreDef.ThreeLevelDefs) {
+          int Distance = countInstBetween(Instr, StoreInst, DistanceInfos);
+          int InstDelayCapacity = getDelayCapacity(Instr);
+          Distance = std::max(InstDelayCapacity - Distance, 0);
+          if (Distance > LevelThreeDelayCapacity) {
+            LevelThreeDelayCapacity = Distance;
+          }
+        }
+        DelayedStoreMap[StoreInst] = LevelOneDelayCapacity
+          + LevelTwoDelayCapacity + LevelThreeDelayCapacity;
+      }
+      // 如果 Def 指令链大于 3 条指令，
+      // 依次计算所有 OneLevelDefs 指令与 Store 的距离 Distance
+      // 取最小的 Distance，distance of effect 设为 max(DelayCapacityMax - Distance, 0)
+      else {
+        int DelayCapacity = 0;
+        for (MachineInstr* Instr: StoreDef.OneLevelDefs) {
+          int Distance = countInstBetween(Instr, StoreInst, DistanceInfos);
+          Distance = std::max(DelayCapacityMax - Distance, 0);
+          if (Distance > DelayCapacity) {
+            DelayCapacity = Distance;
+          }
+        }
+        DelayedStoreMap[StoreInst] = DelayCapacity;
+      }
+    }
+    // 如果不使用 WhiteList 优化
+    // 依次计算所有 OneLevelDefs 指令与 Store 的距离 Distance
+    // 取最小的 Distance，distance of effect 设为 max(DelayCapacityMax - Distance, 0)
+    // 如果没有 Def 指令，distance of effect 设为 0
+    else {
+      if (StoreDef.OneLevelDefs.empty()) {
+        DelayedStoreMap[StoreInst] = 0;
+      }
+      else {
+        int DelayCapacity = 0;
+        for (MachineInstr* Instr: StoreDef.OneLevelDefs) {
+          int Distance = countInstBetween(Instr, StoreInst, DistanceInfos);
+          Distance = std::max(DelayCapacityMax - Distance, 0);
+          if (Distance > DelayCapacity) {
+            DelayCapacity = Distance;
+          }
+        }
+        DelayedStoreMap[StoreInst] = DelayCapacity;
+      }
+    }
+  }
+
+  return DelayedStoreMap;
+}
+
+/**
+ *  fence 加固方案：一种简单的加固策略，在 load 前面增加 mfence/lfence/cpuid 等序列化指令。
+ *  特别地，考虑跨函数的防御，我们在 call 之前也增加序列化指令。
+ *  在序列化策略的基础上，实现了以下优化策略：
+ *  1. 连续多个 load 中间无 store，只需在第一个 load 前插入 fence。
+ *  2. 如果一个 load 与之前所有 store 的距离均大于这些 store 的 distance of effect，
+ *     则不对 load 加 fence。
+ * 
+ *  @param MF: 待加固的函数
+ *  @param StldInfos: 一个 map，记录每个基本块自身 store 和 load 信息，
+ *                    以及前驱 store 信息
+ *  @param DelayedStoreMap: 一个 map，记录每个 store 指令的 distance of effect
+ */
+void X86MDUMitigationPass::hardenLoadwithFENCE(MachineFunction &MF, 
+  DenseMap<MachineBasicBlock*, StoreLoadInfo> StldInfos,
+  DenseMap<MachineInstr*, int> DelayedStoreMap) {
+  for (MachineBasicBlock &MBB : MF) {
+    // 优化策略：如果一个 load 前面的另一个 load 已被加固，且两个 load 间无 store
+    // 那么这个 load 无需被加固
+    bool PredLoadisHardened = false;
+    for (MachineInstr& MI : MBB) {
+      if (MI.mayStore()) {
+        PredLoadisHardened = false;
+      }
+      if (!MI.mayLoad() && !MI.isReturn()) {
+        continue;
+      }
+      if (loadNeedHardened(&MI, StldInfos, DelayedStoreMap) && 
+          !PredLoadisHardened) {
+        auto InsertPt = MI.getIterator();
+        // 加固 load
+        switch(FenceLoad) {
+          default: {
+            // 跳过
+            break;
+          }
+          case 1: {
+            // 使用 lfence
+            BuildMI(MBB, InsertPt, DebugLoc(), TII->get(X86::LFENCE));
+            ++NumInstsInserted;
+            ++NumFENCEsInserted;
+            PredLoadisHardened = true;
+            break;
+          }
+          case 2: {
+            // 使用 mfence
+            BuildMI(MBB, InsertPt, DebugLoc(), TII->get(X86::MFENCE));
+            PredLoadisHardened = true;
+            break;
+          }
+          case 3: {
+            // 使用 push 和 pop
+            if (MI.isReturn() || MI.getNumOperands() <= 1) {
+              BuildMI(MBB, InsertPt, DebugLoc(), TII->get(X86::MFENCE));
+              ++NumInstsInserted;
+              ++NumFENCEsInserted;
+              PredLoadisHardened = true;
+            }
+            else {
+              unsigned BaseReg = 0;
+              // 首先获取基址操作数
+              const MCInstrDesc &Desc = MI.getDesc();
+              int MemRefBeginIdx = X86II::getMemoryOperandNo(Desc.TSFlags);
+              if (MemRefBeginIdx < 0) {
+                BuildMI(MBB, InsertPt, DebugLoc(), TII->get(X86::MFENCE));
+                ++NumInstsInserted;
+                ++NumFENCEsInserted;
+                PredLoadisHardened = true;
+                break;               
+              }
+              assert(MemRefBeginIdx >= 0 && "Cannot have an invalid index here!");
+              MemRefBeginIdx += X86II::getOperandBias(Desc);
+              MachineOperand &BaseMO =
+                  MI.getOperand(MemRefBeginIdx + X86::AddrBaseReg);
+              if (!BaseMO.isFI()) {
+                BaseReg = BaseMO.getReg();
+              }
+              // 选择一个地址对应的寄存器，如果存在，那么进行加固
+              if (BaseReg != 0 && Register::isVirtualRegister(BaseReg)) {
+                Register NewReg = MRI->createVirtualRegister(MRI->getRegClass(BaseReg));
+                // 插入 push 指令
+                BuildMI(MBB, InsertPt, DebugLoc(), TII->get(X86::PUSH64r))
+                      .addReg(BaseReg)
+                      .setMIFlag(MachineInstr::FrameDestroy);
+                // 插入 pop 指令
+                BuildMI(MBB, InsertPt, DebugLoc(), TII->get(X86::POP64r))
+                      .addReg(NewReg, RegState::Define)
+                      .setMIFlag(MachineInstr::FrameDestroy);
+                // 将 load 操作数映射到新的寄存器
+                BaseMO.setReg(NewReg);
+                NumInstsInserted += 2;
+              }
+              else {
+                BuildMI(MBB, InsertPt, DebugLoc(), TII->get(X86::MFENCE));
+                ++NumInstsInserted;
+                ++NumFENCEsInserted;
+                PredLoadisHardened = true;
+              }
+            }
+            break;
+          }
+        }
+      }
+    }
+  }
+}
+
+/**
+ *  fence 加固方案：一种简单的加固策略，在 store 后面增加 mfence/lfence/cpuid 等序列化指令。
+ *  特别地，考虑跨函数的防御，我们在 call 之前也增加序列化指令。
+ *  在序列化策略的基础上，实现了以下优化策略：
+ *  1. 对于连续出现的 store，只在最后一个 store 之后加入 fence；
+ *  2. 如果一个 store 和距离最近的 load/call 距离多于 distance of effect，则不对 store 加 fence。
+ * 
+ *  @param MF: 待加固的函数
+ *  @param StldInfos: 一个 map，记录每个基本块自身 store 和 load 信息，
+ *                    以及前驱 store 信息
+ *  @param DelayedStoreMap: 一个 map，记录每个 store 指令的 distance of effect
+ */
+void X86MDUMitigationPass::hardenStorewithFENCE(MachineFunction &MF, 
+  DenseMap<MachineBasicBlock*, StoreLoadInfo> StldInfos,
+  DenseMap<MachineInstr*, int> DelayedStoreMap) {
+  // 记录已被加固的 store，避免重复加固
+  DenseSet<MachineInstr*> HasHardenedStore;
+  for (MachineBasicBlock &MBB : MF) {
+    StoreLoadInfo& StldInfo = StldInfos[&MBB];
+    for (MachineInstr* MI : StldInfo.StLdInsts) {
+      if (!MI->mayLoad() && !MI->isReturn()) {
+        continue;
+      }
+      if (EnableWhiteList && !loadNeedHardened(MI, StldInfos, DelayedStoreMap)) {
+        continue;
+      }
+      assert(StldInfo.PredStoreInfoForLoad.find(MI) != 
+        StldInfo.PredStoreInfoForLoad.end() && "Load must have been recorded.");
+      StorePredInfo& PredStoreInfo = StldInfo.PredStoreInfoForLoad[MI];
+      // 如果 store 和 load 在同一基本块内
+      if (PredStoreInfo.storeInst) {
+        // 获取 store
+        MachineInstr* StoreInst = PredStoreInfo.storeInst;
+        // 如果 store 还未加固，那么加固 store
+        if (HasHardenedStore.find(StoreInst) == HasHardenedStore.end()) {
+          auto InsertPt = StoreInst->getIterator();
+          MachineBasicBlock* StoreMBB = StoreInst->getParent();
+          DebugLoc Loc = StoreInst->getDebugLoc();
+          switch(FenceStore) {
+            default: {
+              // 跳过
+              break;
+            }
+            case 1: {
+              // 使用 lfence，插在 store 之前
+              BuildMI(*StoreMBB, InsertPt, Loc, TII->get(X86::LFENCE));
+              break;
+            }
+            case 2: {
+              // 使用 mfence，插在 store 之前
+              BuildMI(*StoreMBB, InsertPt, Loc, TII->get(X86::MFENCE));
+              break;
+            }
+            case 3: {
+              // 使用 lfence，插在 store 之后
+              BuildMI(*StoreMBB, std::next(InsertPt), Loc, TII->get(X86::LFENCE));
+              break;
+            }
+            case 4: {
+              // 使用 mfence，插在 store 之后
+              BuildMI(*StoreMBB, std::next(InsertPt), Loc, TII->get(X86::MFENCE));
+              break;
+            }
+          }
+          ++NumInstsInserted;
+          ++NumFENCEsInserted;
+          HasHardenedStore.insert(StoreInst);
+        }
+      }
+      // 否则，搜索 MBB 的前驱 store，依次加固这些 store
+      else {
+        for (auto entry : StldInfo.PredStoreInfosForMBB) {
+          MachineInstr* StoreInst = entry.first;
+          if (HasHardenedStore.find(StoreInst) == HasHardenedStore.end()) {
+            auto InsertPt = StoreInst->getIterator();
+            MachineBasicBlock* StoreMBB = StoreInst->getParent();
+            DebugLoc Loc = StoreInst->getDebugLoc();
+            switch(FenceStore) {
+              default: {
+                // 跳过
+                break;
+              }
+              case 1: {
+                // 使用 lfence，插在 store 之前
+                BuildMI(*StoreMBB, InsertPt, Loc, TII->get(X86::LFENCE));
+                break;
+              }
+              case 2: {
+                // 使用 mfence，插在 store 之前
+                BuildMI(*StoreMBB, InsertPt, Loc, TII->get(X86::MFENCE));
+                break;
+              }
+              case 3: {
+                // 使用 lfence，插在 store 之后
+                BuildMI(*StoreMBB, std::next(InsertPt), Loc, TII->get(X86::LFENCE));
+                break;
+              }
+              case 4: {
+                // 使用 mfence，插在 store 之后
+                BuildMI(*StoreMBB, std::next(InsertPt), Loc, TII->get(X86::MFENCE));
+                break;
+              }
+            }
+            ++NumInstsInserted;
+            ++NumFENCEsInserted;
+            HasHardenedStore.insert(StoreInst);
+          }
+        }
+      }  
+    }
+  }
+}
+
+void X86MDUMitigationPass::hardenLoadwithAlign(MachineFunction &MF,
+    DenseMap<MachineBasicBlock*, StoreLoadInfo> StldInfos,
+    DenseMap<MachineInstr*, int> DelayedStoreMap) {
+
+  // 已加固的 MBB，避免 MBB 在 split 之后被重新搜索
+  SmallSet<MachineBasicBlock*, 16> CompletedMBB;
+  for (MachineBasicBlock &MBB : MF) {
+    CompletedMBB.insert(&MBB);
+  }
+  
+  for (MachineBasicBlock &MBB : MF) {
+    if (!CompletedMBB.erase(&MBB)) {
+      continue;
+    }
+    StoreLoadInfo& StldInfo = StldInfos[&MBB];
+    // 首先，收集 MBB 中所有需要加固的 load
+    // 接下来，MBB 将根据 load 数量被 split，无法再遍历 MBB
+    SmallSet<MachineInstr *, 4> loadInstrNeedHardened;
+    for (MachineInstr * Instr : StldInfo.StLdInsts) {
+      if (Instr->mayLoad()) {
+        // 如果 load 之前存在 delay store，且 load 不是 MBB 第一条指令
+        // 那么加固 load
+        if (MBB.succ_size() == 0) {
+          BuildMI(MBB, Instr->getIterator(), DebugLoc(), TII->get(X86::LFENCE));
+          ++NumInstsInserted;
+          ++NumFENCEsInserted;
+        }
+        else if (loadNeedHardened(Instr, StldInfos, DelayedStoreMap)) {
+          loadInstrNeedHardened.insert(Instr);
+        }
+      }
+      else if (Instr->isReturn()) {
+        if (loadNeedHardened(Instr, StldInfos, DelayedStoreMap)) {
+          BuildMI(MBB, Instr->getIterator(), DebugLoc(), TII->get(X86::LFENCE));
+          ++NumInstsInserted;
+          ++NumFENCEsInserted;
+        }
+      }
+      else {
+        continue;
+      }
+    }
+    MachineInstr * loadTobeHardened = nullptr;
+    for (MachineInstr& Instr : MBB) {
+      // 发现一个待加固 load
+      if (loadInstrNeedHardened.erase(&Instr)) {
+        loadTobeHardened = &Instr;
+        break;
+      }
+    }
+    while(loadTobeHardened) {
+      // LLVM_DEBUG(dbgs() << "    Stuck Here \n");
+      auto &NewMBB = splitBlockFromInstr(loadTobeHardened);
+      loadTobeHardened = nullptr;
+      for (MachineInstr& Instr : NewMBB) {
+        // 发现一个待加固 load
+        if (loadInstrNeedHardened.erase(&Instr)) {
+          loadTobeHardened = &Instr;
+          break;
+        }
+      }
+    }
+  }
+
+  // 将所有基本块按 256 字节对齐
+  for (MachineBasicBlock &MBB : MF) {
+    MBB.setAlignment(Align(256));
+  }
+}
+
+void X86MDUMitigationPass::hardenLoadwithCoupling(MachineFunction &MF,
+    DenseMap<MachineBasicBlock*, StoreLoadInfo> StldInfos,
+    DenseMap<MachineInstr*, int> DelayedStoreMap) {
+  for (MachineBasicBlock & MBB : MF) {
+    StoreLoadInfo& StldInfo = StldInfos[&MBB];
+    for (MachineInstr* MI : StldInfo.StLdInsts) {
+
+      if (!MI->mayLoad() && !MI->isReturn()) {
+        continue;
+      }
+      if (!loadNeedHardened(MI, StldInfos, DelayedStoreMap)) {
+        continue;
+      }
+     
+      LLVM_DEBUG(dbgs() << "hardening MI: " << MI->getParent()->getName(); MI->dump());
+      // MI 是一条待 coupling 的 load 指令，获取它的位置
+      auto InsertPt = MI->getIterator();
+      DebugLoc Loc = MI->getDebugLoc();
+
+      if (MI->isReturn()) {
+        // 对于 return 指令，我们插入 fence，而不去显式修改 RSP 寄存器
+        BuildMI(MBB, InsertPt, Loc, TII->get(X86::MFENCE));
+        ++NumInstsInserted;
+        ++NumFENCEsInserted;
+        continue;       
+      } 
+
+      // 获取 load 的地址操作数，以及对应的寄存器
+      unsigned LoadRegister = 0;
+      const MCInstrDesc &Desc_Load = MI->getDesc();
+      int MemRefBeginIdx = X86II::getMemoryOperandNo(Desc_Load.TSFlags);
+      // 无操作数的 load，一般不是侧信道攻击的目标
+      if (MemRefBeginIdx < 0) {
+        continue;        
+      }
+
+      MemRefBeginIdx += X86II::getOperandBias(Desc_Load);
+      MachineOperand &BaseMO_Load =
+          MI->getOperand(MemRefBeginIdx + X86::AddrBaseReg);
+      bool loadFromRBP = false;
+      if (!BaseMO_Load.isFI()) {
+        LoadRegister = BaseMO_Load.getReg();
+      }
+      if (LoadRegister == 0
+        || !Register::isVirtualRegister(LoadRegister)) {
+          continue;
+      }      
+      assert(BaseMO_Load.isReg() && "BaseMO_Load must be a register now");
+      
+      // 接下来，我们找到前驱 store 的地址操作数，以及对应的寄存器，进行 coupling
+      unsigned StoreRegister = 0;
+      assert(StldInfo.PredStoreInfoForLoad.find(MI) != 
+        StldInfo.PredStoreInfoForLoad.end() && "Load must have been recorded.");
+      StorePredInfo& PredStoreInfo = StldInfo.PredStoreInfoForLoad[MI];
+      MachineInstr* PredStoreInst = PredStoreInfo.storeInst;
+      // 如果在 MBB 内，load 之前没有 store，那么需要尝试获取 load 的前驱 store
+      if (!PredStoreInst) {
+        StoreRegister = SAS->SSA.GetValueInMiddleOfBlock(&MBB);
+        LLVM_DEBUG(dbgs() << "SSA->StoreRegister = " << StoreRegister << "\n");
+      }
+      else {
+        const MCInstrDesc &Desc_Store = PredStoreInst->getDesc();
+        MemRefBeginIdx = X86II::getMemoryOperandNo(Desc_Store.TSFlags);
+        if (MemRefBeginIdx < 0) {
+          continue;          
+        }
+        assert(MemRefBeginIdx >= 0 && "Cannot have an invalid index here!");
+        MemRefBeginIdx += X86II::getOperandBias(Desc_Store);
+        MachineOperand &BaseMO_Store =
+            PredStoreInst->getOperand(MemRefBeginIdx + X86::AddrBaseReg);
+        if (!BaseMO_Store.isFI() && BaseMO_Store.isReg()) {
+          StoreRegister = BaseMO_Store.getReg();
+        }
+        // 如果找不到 store 的地址寄存器，那么这个 store 一般不被延迟
+        if (StoreRegister == 0 ||
+            !Register::isVirtualRegister(StoreRegister)) {
+            continue;
+        }
+      }
+      LLVM_DEBUG(dbgs() << "Reach Here ***************\n");
+      // 现在我们拿到 LoadRegister 和 StoreRegister，进行 coupling
+      // movq %store_reg, %new_reg
+      // and $0, %new_reg
+      // or %new_reg, %load_reg
+
+      // 先检查 MI 之后，EFLAGS 是否是 live 的，如果是，加固过程会破坏 EFLAGS
+      // 因此需要在加固前储存 EFLAGS，并在加固后恢复 EFLAGS
+      bool EFLAGSLive = isEFLAGSLive(MBB, MI->getIterator(), *TRI);
+      // 如果调用 saveEFLAGS，这个寄存器保存了存放 EFLAGS 的虚拟寄存器编号
+      // 后续通过 restoreEFLAGS 函数，从相应寄存器中恢复 EFLAGS 
+      unsigned FlagsReg = 0;
+      if (EFLAGSLive) {
+        // 存储 EFLAGS 后，可以将 EFLAGSLive 置为 false，后续不必担心破坏 EFLAGS
+        EFLAGSLive = false;
+        // 调用 saveEFLAGS 函数后，返回存放 EFLAGS 的虚拟寄存器编号
+        FlagsReg = saveEFLAGS(MBB, InsertPt, Loc);
+      }
+
+      Register NewRegister1 = MRI->createVirtualRegister(&X86::GR64_NOSPRegClass);
+      Register NewRegister2 = MRI->createVirtualRegister(&X86::GR64_NOSPRegClass);
+      Register NewRegister3 = MRI->createVirtualRegister(&X86::GR64_NOSPRegClass);
+
+      BuildMI(MBB, InsertPt, Loc, TII->get(X86::MOV64rr), NewRegister1)
+                  .addReg(StoreRegister);  // 源寄存器
+      auto InstAND = BuildMI(MBB, InsertPt, Loc, TII->get(X86::AND64ri32), NewRegister2)
+                  .addReg(NewRegister1, RegState::Kill) 
+                  .addImm(0);  // 源寄存器
+      InstAND->addRegisterDead(X86::EFLAGS, TRI);
+      if (LoadRegister > 0 && Register::isVirtualRegister(LoadRegister)) {
+        auto InstOrI = BuildMI(MBB, InsertPt, Loc, TII->get(X86::OR64rr), NewRegister3)
+                        .addReg(LoadRegister)
+                        .addReg(NewRegister2, RegState::Kill);
+        InstOrI->addRegisterDead(X86::EFLAGS, TRI);
+        BaseMO_Load.setReg(NewRegister3);
+      }
+      else if (BaseMO_Load.isFI()) {
+        auto InstOrI = BuildMI(MBB, InsertPt, Loc, TII->get(X86::OR64rr), X86::RBP)
+                        .addReg(X86::RBP)
+                        .addReg(NewRegister2, RegState::Kill);
+        InstOrI->addRegisterDead(X86::EFLAGS, TRI);
+        // BuildMI(MBB, InsertPt, Loc, TII->get(X86::COPY), X86::RBP)
+        //                 .addReg(NewRegister3); 
+      }
+
+
+      NumInstsInserted += 3;
+      // 如果之前调用了 saveEFLAGS，那么对指令 MI 加固结束后
+      // 需要用 restoreEFLAGS 恢复 EFLAGS
+      if (FlagsReg) {
+        restoreEFLAGS(MBB, InsertPt, Loc, FlagsReg);
+      }
+      // LLVM_DEBUG(dbgs() << "in Coupling: "; InstOrI->dump());
+    }
+  }
+}
+
+
+MachineBasicBlock &
+X86MDUMitigationPass::splitBlockFromInstr(MachineInstr* Instr) {
+
+  // 获取原基本块
+  MachineBasicBlock& MBB = *Instr->getParent();
+
+  // 如果 Instr 是 MBB 第一条指令，那么无需更新
+  if (Instr->getIterator() == MBB.SkipPHIsLabelsAndDebug(MBB.begin())) {
+    return MBB;
+  }
+
+  // 特例：如果 MBB 没有后继，进行 split 会报错
+  if (MBB.succ_size() == 0) {
+    return MBB;
+  }
+
+  // 创建新基本块并插入 MF
+  MachineFunction &MF = *MBB.getParent();
+  MachineBasicBlock &NewMBB = *MF.CreateMachineBasicBlock(MBB.getBasicBlock());
+  MF.insert(std::next(MachineFunction::iterator(&MBB)), &NewMBB);
+
+  bool isEFLAGSLive = false;
+  // Scan forward through BB for a use/def of EFLAGS.
+  for (MachineBasicBlock::iterator miI = Instr->getIterator(), miE = MBB.end();
+         miI != miE; ++miI) {
+    const MachineInstr& mi = *miI;
+    if (mi.readsRegister(X86::EFLAGS)) {
+      isEFLAGSLive = true;
+      break;
+    }
+  }
+  // If we hit the end of the block, check whether EFLAGS is live into a
+  // successor.
+  for (MachineBasicBlock::succ_iterator sItr = MBB.succ_begin(),
+                                        sEnd = MBB.succ_end();
+       sItr != sEnd; ++sItr) {
+    MachineBasicBlock* succ = *sItr;
+    if (succ->isLiveIn(X86::EFLAGS)) {
+      isEFLAGSLive = true;
+      break;
+    }
+  }
+
+  // 获取指令 Instr 的位置
+  auto SplitPoint = Instr->getIterator();
+
+  // 使用 splice 函数，将 MBB 从 SplitPoint 到结尾的所有指令，移入 NewMBB
+  NewMBB.splice(NewMBB.begin(), &MBB, SplitPoint, MBB.end());
+
+  // 在 MBB 末尾插入无条件跳转指令，跳到 NewMBB
+  BuildMI(&MBB, DebugLoc(), TII->get(X86::JMP_1)).addMBB(&NewMBB);
+  ++NumInstsInserted;
+
+  if (isEFLAGSLive) {
+    NewMBB.addLiveIn(X86::EFLAGS);
+  }
+
+  // 在 CFG 上更新基本块信息
+  // MBB 的后继更新为唯一的 NewMBB
+  // 将 MBB 原后继全部移到 NewMBB
+  NewMBB.transferSuccessorsAndUpdatePHIs(&MBB);
+  MBB.addSuccessor(&NewMBB);
+
+  recomputeLiveIns(NewMBB);
+  recomputeLiveIns(MBB);
+  return NewMBB;
+}
+
+/**
+ *  判断一个 load 指令是否要被加固。
+ *  
+ *  @param LoadInst: 待分析 load 指令
+ *  @param DistanceInfos: 一个 map，记录两个基本块间的最短距离
+ *  @param StoreLoadInfos: 一个 map，记录每个基本块自身 store 和 load 信息，
+ *                         以及前驱 store 信息
+ *  @param DelayedStorInfos: 一个 map，记录每个 store 的 delay 信息。
+ *                           具体而言，key 是一个 store，value 是这个 store 
+ *                           存在影响的距离范围。如果一个 load 与 store 的距离
+ *                           小于 value，那么 load 会被 store 影响，需要加固。
+ * 
+ *  @return 一个布尔值，判断 LoadInst 是否需要加固
+ */
+bool X86MDUMitigationPass::loadNeedHardened(MachineInstr* LoadInst, 
+DenseMap<MachineBasicBlock*, StoreLoadInfo> StoreLoadInfos,
+DenseMap<MachineInstr*, int> DelayedStorInfos
+) {
+
+  if (Optmized) {
+    return true;
+  }
+
+  // 如果是 lazy load，无需加固
+  if (isLazyStoreorLazyLoad(LoadInst)) {
+    return false;
+  }
+
+  // 获取基本信息
+  MachineBasicBlock* MBB = LoadInst->getParent();
+  StoreLoadInfo& StldInfo = StoreLoadInfos[MBB];
+  assert(StldInfo.PredStoreInfoForLoad.find(LoadInst) != 
+    StldInfo.PredStoreInfoForLoad.end() && "Load must have been recorded.");
+  StorePredInfo& PredStoreInfo = StldInfo.PredStoreInfoForLoad[LoadInst];
+
+  // 如果 store 和 load 在同一基本块内
+  if (PredStoreInfo.storeInst) {
+    MachineInstr* StoreInst = PredStoreInfo.storeInst;
+    // 如果 store 未被记录，可能是因为 store 的地址操作数是隐式的，这时默认加固后续 load
+    if (DelayedStorInfos.find(StoreInst) == DelayedStorInfos.end()) {
+      return true;
+    }
+    // assert(DelayedStorInfos.find(StoreInst) != DelayedStorInfos.end()
+    //        && "Store's delay info must have been recorded.");
+    
+    // 比较 load 与 store 的 distance，以及 store 的 distance of effect
+    return DelayedStorInfos[StoreInst] > PredStoreInfo.distance;
+  }
+  // 否则，搜索 MBB 的前驱 store
+  else {
+    for (auto entry : StldInfo.PredStoreInfosForMBB) {
+      MachineInstr* StoreInst = entry.first;
+      int StoreMBBDistance = entry.second.distance;
+      int LoadMBBDistance = PredStoreInfo.distance;
+      // 如果 store 信息没有延迟记录，可能触发了某些 edge cases
+      // 直接跳过 store
+      if (DelayedStorInfos.find(StoreInst) == DelayedStorInfos.end()) {
+        continue;
+      }
+      // 如果 load 在某个前驱 store 的 distance of effect 范围内
+      // 那么 load 需要被加固
+      if (DelayedStorInfos[StoreInst] > StoreMBBDistance + LoadMBBDistance) {
+        return true;
+      }
+    }
+
+  }
+  return false;
+}
+
+/**
+ *  用每个基本块的最后一个 Store (如果存在) 更新 StoreAddrState。
+ */
+void X86MDUMitigationPass::generateStoreAddr(MachineFunction &MF,
+    DenseMap<MachineBasicBlock*, StoreLoadInfo> StldInfos,
+    DenseMap<MachineInstr*, int> DelayedStoreMap) {
+  for (MachineBasicBlock & MBB : MF) {
+    StoreLoadInfo& StldInfo = StldInfos[&MBB];
+    
+    // 如果 MBB 包含 store，获得其最后一个 store
+    if (StldInfo.LastStoreInst) {
+      MachineInstr* Laststore = StldInfo.LastStoreInst;
+      // 获取 store 地址操作数 (如果有显式操作数)
+      // 对于 push 这种 store，隐式操作数 rsp 是安全的，无需加入 SAS
+      // if (Laststore->getNumExplicitOperands() >= 2) {
+      const MCInstrDesc &Desc = Laststore->getDesc();
+      int MemRefBeginIdx = X86II::getMemoryOperandNo(Desc.TSFlags);
+      if (MemRefBeginIdx < 0) {
+        continue;
+      }
+      assert(MemRefBeginIdx >= 0 && "Cannot have an invalid index here!");
+      MemRefBeginIdx += X86II::getOperandBias(Desc);
+      MachineOperand &BaseMO =
+          Laststore->getOperand(MemRefBeginIdx + X86::AddrBaseReg);
+      unsigned BaseReg = 0;
+      if (!BaseMO.isFI() && BaseMO.isReg()) {
+        BaseReg = BaseMO.getReg();
+      }
+      // 如果 store 的地址操作数存在
+      // 那么将地址寄存器更新到 SAS 中
+      if (BaseReg > 0 && Register::isVirtualRegister(BaseReg)) {
+        SAS->SSA.AddAvailableValue(&MBB, BaseReg);
+      }
+      // }
+    }
+  }
+}
+
+
+
+/**
+ *  统计一个指令在基本块的相邻前驱指令数量。由于目前是 MC 层，还不是最终指令，
+ *  因此存在一些误差，例如存在 PHI 指令和一些后续被合并的指令。
+ *  这里将删除对 MetaInstruction 和 Label 的统计，这些 MC 指令最终不会产生实际指令。
+ * 
+ *  @param MI: 目标指令
+ *  @param MBB: 待统计指令数量的基本块
+ *  @return 如果 MI 在 MBB 中，返回 MI 之前的指令数量，否则返回 MBB 总的指令数量
+ */
+int X86MDUMitigationPass::countInstBefore(MachineBasicBlock* MBB, MachineInstr *MI) {
+    int count = 0;
+    auto MII = MBB->instr_begin();
+    while (MII != MBB->instr_end()) {
+        MachineInstr &I = *MII++;
+        if (&I == MI) {
+          break;
+        }
+        // 跳过最终有可能不会转化成实际机器指令的 MC
+        if (I.isMetaInstruction() || I.isLabel() || I.isTransient())
+            continue;
+        count++;
+    }
+    return count;
+}
+
+/**
+ *  统计一个指令在基本块的相邻后继指令数量。由于目前是 MC 层，还不是最终指令，
+ *  因此存在一些误差，例如存在 PHI 指令和一些后续被合并的指令。
+ *  这里将删除对 MetaInstruction 和 Label 的统计，这些 MC 指令最终不会产生实际指令。
+ * 
+ *  @param MI: 目标指令
+ *  @param MBB: 待统计指令数量的基本块
+ *  @return 如果 MI 在 MBB 中，返回 MI 之后的指令数量，否则返回 MBB 总的指令数量
+ */
+int X86MDUMitigationPass::countInstAfter(MachineBasicBlock* MBB, MachineInstr *MI) {
+    int count = 0;
+    auto MII = MBB->instr_begin();
+    if (MI && MI->getParent() == MBB) {
+      MII = MI->getIterator(); 
+      // 不包括指令自身
+      count -= 1;
+    }
+    while (MII != MBB->instr_end()) {
+        MachineInstr &I = *MII++;
+        // 跳过最终有可能不会转化成实际机器指令的 MC
+        if (I.isMetaInstruction() || I.isLabel() || I.isTransient())
+            continue;
+        count++;
+    }
+    return count;
+}
+
+/**
+ *  统计两条指令间的指令数量。
+ *  如果两个指令在同一基本块，返回它们之间的指令数量。
+ *  如果两个指令在不同基本块，那么返回两个基本块的最短距离，减去第一个基本块指令数量，
+ *  加上第一条指令与第一个基本块结尾的距离，再加上第二条指令与第二个基本块入口的距离。
+ *  这里将删除对 MetaInstruction 和 Label 的统计，这些 MC 指令最终不会产生实际指令。
+ * 
+ *  @param MI: 目标指令
+ *  @param MBB: 待统计指令数量的基本块
+ *  @return 如果 MI 在 MBB 中，返回 MI 之后的指令数量，否则返回 MBB 总的指令数量。
+ */
+int X86MDUMitigationPass::countInstBetween(MachineInstr *MI1, MachineInstr *MI2, 
+  DenseMap<MachineBasicBlock*, DistanceInfo> DistanceInfos) {
+    int count = 0;
+    if (MI1 == MI2) {
+      return count;
+    }
+
+    // 两条指令在同一个基本块内的情况
+    if (MI1->getParent() == MI2->getParent()) {
+      bool startCount = false;
+      MachineBasicBlock* MBB = MI1->getParent();
+      auto MII = MBB->instr_begin();
+      while (MII != MBB->instr_end()) {
+          MachineInstr &I = *MII++;
+          if (!startCount && (&I == MI1 || &I == MI2)) {
+            startCount = true;
+            continue;
+          }
+          else if (startCount) {
+            if (&I == MI1 || &I == MI2) {
+              break;
+            }
+            if (!(I.isMetaInstruction() || I.isLabel() || I.isTransient()))
+                count++;
+          }
+      }
+    }
+    else {
+      MachineBasicBlock *MMB1 = MI1->getParent();
+      MachineBasicBlock *MMB2 = MI2->getParent();
+      int shortestDistance = DistanceInfos[MMB1].ShortestDistance[MMB2];
+      if (shortestDistance == INF) {
+        count = -1;
+      }
+      else {
+        count = shortestDistance - DistanceInfos[MMB1].selfSize;
+        count += countInstAfter(MMB1, MI1);
+        count += countInstBefore(MMB2, MI2);
+      }
+    }
+
+    return count;
+}
+
+SmallSet<MachineInstr *, 8> 
+X86MDUMitigationPass::getDefInstrList(MachineInstr *Instr) {
+  SmallSet<MachineInstr *, 8> Result;
+  // 对 Instr 的操作数进行 BFS
+  // 跳过 PHI 指令和 COPY 指令
+  SmallVector<MachineOperand *, 8> BFSList;
+  SmallSet<MachineOperand *, 8> VisitedList;
+
+  if (Optmized) {
+    return Result;
+  }
+
+  while(true) {
+    if (Instr && Instr->getNumExplicitOperands() > 0) {
+      // LLVM_DEBUG({
+      //   dbgs() << "getDefInstrList Element (Instr->getNumOperands()="
+      //          << Instr->getNumExplicitOperands() << "):"; Instr->dump();
+
+      // });
+      // 对于访存指令，可能包含基址寄存器 (BaseMO) 和索引寄存器 (IndexMO) 
+      // 例如，地址 (%rax,%rdx,1) 的基址寄存器为 %rax，索引寄存器为 %rdx
+      if (Instr->mayLoadOrStore() && Instr->getOpcode() != X86::LFENCE
+        && Instr->getOpcode() != X86::MFENCE) {
+        // 首先，获取目的寄存器描述符 Desc
+        const MCInstrDesc &Desc = Instr->getDesc();
+        // 根据描述符 Desc 获取目的操作数的 index
+        int MemRefBeginIdx = X86II::getMemoryOperandNo(Desc.TSFlags);
+        if (!(MemRefBeginIdx < 0)) {
+        // 如果目的寄存器也是源寄存器之一，那么用 getOperandBias 跳过重复的寄存器
+        // 例如，一条指令将 %rax 的值加上 %rbx 再存入 %rax
+        // 这时 MemRefBeginIdx 一开始为 0 (X86II::getMemoryOperandNo)
+        // 加上 X86II::getOperandBias 后被更新为 1
+        // 这样才能正确访问其他操作数，比如 %rbx 是第 2 个操作数而非第 1 个
+        MemRefBeginIdx += X86II::getOperandBias(Desc);
+
+        // 目的寄存器编号，加上 AddrBaseReg 得到 BaseMO 的 index
+        // 加上 AddrIndexReg 得到 IndexMO 的 index
+        // 然后使用 getOperand 从 index 得到操作数对象
+        // if ((Instr->mayLoad() && Instr->getNumExplicitOperands() >= 3 && 
+        //      Instr->getDesc().getNumDefs() == 1) ||
+        //     (Instr->mayStore() && Instr->getNumExplicitOperands() >= 2)) {
+          MachineOperand &BaseMO =
+            Instr->getOperand(MemRefBeginIdx + X86::AddrBaseReg);
+          if (!BaseMO.isFI() && Register::isVirtualRegister(BaseMO.getReg())) {
+            if (VisitedList.find(&BaseMO) == VisitedList.end()) {
+              BFSList.insert(BFSList.begin(), &BaseMO);
+            }
+          }
+        // }
+        // if ((Instr->mayLoad() && Instr->getNumExplicitOperands() >= 4) || 
+            // (Instr->mayStore() && Instr->getNumExplicitOperands() >= 3)) {
+          MachineOperand &IndexMO =
+            Instr->getOperand(MemRefBeginIdx + X86::AddrIndexReg);
+          if (!IndexMO.isFI() && Register::isVirtualRegister(IndexMO.getReg())) {
+            if (VisitedList.find(&IndexMO) == VisitedList.end()) {
+              BFSList.insert(BFSList.begin(), &IndexMO);
+            }
+          }
+        // }
+        }
+      }
+      // 对于非访存指令，我们获取所有非目标的寄存器操作数列表
+      else {
+        for ( MachineOperand &MO : Instr->operands()) {
+          if(!MO.isFI() && !MO.isGlobal() && MO.isReg() && MO.isUse()) {
+            if (Register::isVirtualRegister(MO.getReg())) {
+              if (VisitedList.find(&MO) == VisitedList.end()) {
+                BFSList.insert(BFSList.begin(), &MO);
+              }
+            }
+          }
+        }
+      }
+    }
+    if (BFSList.empty()) {
+      break;
+    }
+    // LLVM_DEBUG(dbgs() << BFSList.size() << "\n");
+    MachineOperand* MO = BFSList.pop_back_val(); 
+    VisitedList.insert(MO);
+    unsigned reg = MO->getReg();
+    if (reg != X86::RIP && reg != X86::RSP && reg != X86::RBP &&
+        reg != X86::NoRegister) {
+      Instr = MRI->getVRegDef(reg);
+      if (Instr) {
+        // 如果 Instr 是有效指令，我们将其记录后，不再继续搜索它的操作数
+        if (!Instr->isTransient()) {
+          Result.insert(Instr);
+          Instr = nullptr;
+        }
+      }
+    }
+  }
+  return Result;
+}
+
+/**
+ *  计算一条指令的 Delay Capacity。
+ *  如果指令是 mov 指令，使用 DelayCapacityCopy;
+ *  如果指令是 cmov 指令，使用 DelayCapacityCopy * 10;
+ *  如果指令是 load 指令，使用 DelayCapacityMemory;
+ *  如果是算术指令，使用 DelayCapacityCalculation;
+ *  如果是乘法指令，使用 DelayCapacityCalculation * 5;
+ *  如果是除法指令，使用 DelayCapacityCalculation * 30;
+ *  如果是 RCR, ROR, SBB, ADC 指令，使用 DelayCapacityCalculation * 20；
+ *  其他指令，使用默认 Delay Capacity。
+ */
+int X86MDUMitigationPass::getDelayCapacity(MachineInstr* Instr) {
+  if (Instr->mayLoad()) {
+    return DelayCapacityMemory;
+  }
+  else if (Instr->isMoveReg()) {
+    return DelayCapacityCopy;
+  }
+  else if (Instr->isMoveImmediate()) {
+    return 5 * DelayCapacityCopy;
+  }
+  else if (Instr->isMoveImmediate()) {
+    return 5 * DelayCapacityCopy;
+  }
+  else if (getSpecialArithmeticFactor(Instr)) {
+    int ArithmeticID = getSpecialArithmeticFactor(Instr);
+    return ArithmeticID * DelayCapacityCalculation;
+  }
+  else if (TII->isDataInvariant(*Instr)) {
+    return DelayCapacityCalculation;
+  }
+  else {
+    return DelayCapacityMax;
+  }
+}
+
+int X86MDUMitigationPass::getSpecialArithmeticFactor(MachineInstr* Instr) {
+  // 指令信息来自：build/lib/Target/X86/X86GenInstrInfo.inc
+  switch (Instr->getOpcode()) {
+    default:
+      return 0;
+    // 乘法指令
+    case X86::IMUL16r:
+    case X86::IMUL16rr:
+    case X86::IMUL16rri8:
+    case X86::IMUL16rri:
+    case X86::IMUL32r:
+    case X86::IMUL32rr:
+    case X86::IMUL32rri8:
+    case X86::IMUL32rri:
+    case X86::IMUL64r:
+    case X86::IMUL64rr:
+    case X86::IMUL64rri32:
+    case X86::IMUL64rri8:
+    case X86::IMUL8r:
+      return 5;
+    // 除法指令
+    case X86::IDIV16r:
+    case X86::IDIV32r:
+    case X86::IDIV64r:
+    case X86::IDIV8r:
+    case X86::DIV16r:
+    case X86::DIV32r:
+    case X86::DIV64r:
+    case X86::DIV8r:
+      return 30;
+    // RCR 和 RCL 指令
+    case X86::RCR16r1:
+    case X86::RCR16rCL:
+    case X86::RCR16ri:
+    case X86::RCR32r1:
+    case X86::RCR32rCL:
+    case X86::RCR32ri:
+    case X86::RCR64r1:
+    case X86::RCR64rCL:
+    case X86::RCR64ri:
+    case X86::RCR8r1:
+    case X86::RCR8rCL:
+    case X86::RCR8ri:
+    case X86::RCL16r1:
+    case X86::RCL16rCL:
+    case X86::RCL16ri:
+    case X86::RCL32r1:
+    case X86::RCL32rCL:
+    case X86::RCL32ri:
+    case X86::RCL64r1:
+    case X86::RCL64rCL:
+    case X86::RCL64ri:
+    case X86::RCL8r1:
+    case X86::RCL8rCL:
+    case X86::RCL8ri:
+      return 20;
+    // ADC 和 SBB 指令
+    case X86::ADC16i16:
+    case X86::ADC16ri:
+    case X86::ADC16ri8:
+    case X86::ADC16rr:
+    case X86::ADC16rr_REV:
+    case X86::ADC32i32:
+    case X86::ADC32ri:
+    case X86::ADC32ri8:
+    case X86::ADC32rr:
+    case X86::ADC32rr_REV:
+    case X86::ADC64i32:
+    case X86::ADC64ri8:
+    case X86::ADC64rr:
+    case X86::ADC64rr_REV:
+    case X86::ADC8i8:
+    case X86::ADC8ri:
+    case X86::ADC8rr:
+    case X86::ADC8rr_REV:
+    case X86::ADCX32rr:
+    case X86::ADCX64rr:
+    case X86::SBB16i16:
+    case X86::SBB16ri:
+    case X86::SBB16ri8:
+    case X86::SBB16rr:
+    case X86::SBB16rr_REV:
+    case X86::SBB32i32:
+    case X86::SBB32ri:
+    case X86::SBB32ri8:
+    case X86::SBB32rr:
+    case X86::SBB32rr_REV:
+    case X86::SBB64i32:
+    case X86::SBB64ri8:
+    case X86::SBB64rr:
+    case X86::SBB64rr_REV:
+    case X86::SBB8i8:
+    case X86::SBB8ri:
+    case X86::SBB8rr:
+    case X86::SBB8rr_REV:
+      return 20;
+  }
+}
+
+bool X86MDUMitigationPass::isLazyStoreorLazyLoad(MachineInstr* Instr) {
+  if (Instr->mayLoad()) {
+    switch (Instr->getOpcode()) {
+      default:
+        return false;
+      case X86::LEAVE:
+      case X86::LEAVE64:
+      case X86::BT16mr:
+      case X86::BT32mr:
+      case X86::BT64mr:
+      case X86::BTC16mr:
+      case X86::BTC32mr:
+      case X86::BTC64mr:
+      case X86::BTR16mr:
+      case X86::BTR32mr:
+      case X86::BTR64mr:
+      case X86::BTS16mr:
+      case X86::BTS32mr:
+      case X86::BTS64mr:
+        return true;
+    }
+  }
+  else if (Instr->mayStore()) {
+    switch (Instr->getOpcode()) {
+      default:
+        return false;
+      case X86::ENTER:
+        return true;
+    }
+  }
+  else {
+    return false;
+  }
+}
+
+
+/**
+ *  判断一个基本块从一个特定位置 I 往后，EFLAGS 是否是 live 的
+ *  live 指的是 EFLAGS 在这个区域内被使用到了。
+ *  
+ *  @param MBB: 待测试的基本块
+ *  @param I: 基本块内的某条指令所在位置
+ *  @param TRI: X86 架构的寄存器信息，由 td 文件定义
+ *  @return 一个布尔值，表示 EFLAGS 是否在待测范围内是 live 的
+ */
+bool X86MDUMitigationPass::isEFLAGSLive(MachineBasicBlock &MBB, 
+  MachineBasicBlock::iterator I, const TargetRegisterInfo &TRI) {
+  // Check if EFLAGS are alive by seeing if there is a def of them or they
+  // live-in, and then seeing if that def is in turn used.
+  // 从 MBB 内的位置 I 处，倒序遍历每条指令 MI
+  for (MachineInstr &MI : llvm::reverse(llvm::make_range(MBB.begin(), I))) {
+    // 首先，判断 MI 是否更新了 EFLAGS
+    if (MachineOperand *DefOp = MI.findRegisterDefOperand(X86::EFLAGS)) {
+      // 如果更新了 EFLAGS，但是后续 EFLAGS 状态为 dead 
+      // 说明后续不会再用到 EFLAGS，返回 false
+      if (DefOp->isDead())
+        return false;
+
+      // 否则，如果 EFLAGS 后续是 live 的，返回 true
+      return true;
+    }
+    // 如果 MI 将 EFLAGS 标记为 Kill，说明 MI 阻止了后续指令使用 EFLAGS
+    // 并且到达这里，说明从 MI 到 I 并未更新 (def) EFLAGS
+    // 那么 I 之后 EFLAGS 是 dead 的，因此返回 false
+    if (MI.killsRegister(X86::EFLAGS, &TRI))
+      return false;
+  }
+
+  // 如果从 MBB 入口到 I，都没有更新或 kill EFLAGS
+  // 那么我们读取 MBB 输入的 live-in 寄存器，看是否有 EFLAGS
+  // 如果在，那么 EFLAGS 后续仍然可用，返回 true，否则返回 false
+  return MBB.isLiveIn(X86::EFLAGS);
+}
+
+/**
+ *  将 EFLAGS 寄存器的值存放在一个通用寄存器中，
+ *  之后可以通过 restoreEFLAGS 函数从通用寄存器中恢复。
+ *  
+ *  注意 LLVM 只能处理简单的 EFLAGS 保存和回复，它们需要在一个基本块中，
+ *  否则生成的代码复杂且效率低。
+ * 
+ *  @param MBB: 需要保存 EFLAGS 的基本块
+ *  @param InsertPt: 需要保存 EFLAGS 的位置
+ *  @param Loc: 一个封装了源代码行号、列号和相关调试元数据的对象，
+ *              主要用于在生成的机器指令中保留和传递调试信息
+ *              对于指令 MI，使用指令接口 MI.getDebugLoc 获取
+ *  @return 装有 EFLAGS 的寄存器
+ */
+unsigned X86MDUMitigationPass::saveEFLAGS(
+    MachineBasicBlock &MBB, MachineBasicBlock::iterator InsertPt,
+    DebugLoc Loc) {
+  // 新建一个 32 为寄存器，因为 EFLAGS 是 32 位的
+  Register Reg = MRI->createVirtualRegister(&X86::GR32RegClass);
+  // 使用 COPY 指令，将 EFLAGS 复制到 Reg 寄存器
+  BuildMI(MBB, InsertPt, Loc, TII->get(X86::COPY), Reg).addReg(X86::EFLAGS);
+  ++NumInstsInserted;
+  // 返回寄存器 Reg，现在 Reg 装入了 EFLAGS
+  return Reg;
+}
+
+/**
+ *  将 EFLAGS 从通用寄存器重新载入 EFLAGS 寄存器。
+ *  这个指令必须与 saveEFLAGS 所创建的指令在同一基本块中。
+ * 
+ *  @param MBB: 需要保存 EFLAGS 的基本块
+ *  @param InsertPt: 需要保存 EFLAGS 的位置
+ *  @param Loc: 一个封装了源代码行号、列号和相关调试元数据的对象，
+ *              主要用于在生成的机器指令中保留和传递调试信息
+ *              对于指令 MI，使用指令接口 MI.getDebugLoc 获取
+ *  @param Reg: 存放 EFLAGS 的通用寄存器编号
+ * 
+ */
+void X86MDUMitigationPass::restoreEFLAGS(
+    MachineBasicBlock &MBB, MachineBasicBlock::iterator InsertPt, DebugLoc Loc,
+    unsigned Reg) {
+  // 使用 COPY 伪指令，将 EFLAGS 从 Reg 寄存器载入 EFLAGS 寄存器
+  BuildMI(MBB, InsertPt, Loc, TII->get(X86::COPY), X86::EFLAGS).addReg(Reg);
+  ++NumInstsInserted;
+}
+
+
+void X86MDUMitigationPass::dumpStoreLoadInfo
+  (DenseMap<MachineBasicBlock*, StoreLoadInfo> Infos) {
+  LLVM_DEBUG(dbgs() << "Dump StoreLoadInfo, Size = " << Infos.size()
+                    << ":\n");
+  for (auto &entry : Infos) {
+    StoreLoadInfo &Info = entry.second;
+    LLVM_DEBUG(dbgs() << "   MBB: " << Info.MBB->getName()
+                  << "\n");
+    for (MachineInstr* MI : Info.StLdInsts) {
+      LLVM_DEBUG({
+        dbgs() << "     Inst:";
+        MI->dump();
+      });
+      if (Info.PredStoreInfoForLoad.find(MI) != Info.PredStoreInfoForLoad.end()) {
+        StorePredInfo& storeBefore = Info.PredStoreInfoForLoad[MI];
+        if (storeBefore.storeInst) {
+          LLVM_DEBUG({
+            dbgs() << "            Pred Store for load (distance " << 
+              storeBefore.distance << "): ";
+            storeBefore.storeInst->dump();
+          });        
+        }
+        else {
+          LLVM_DEBUG({
+            dbgs() << "            Pred Store for load (distance " << 
+              storeBefore.distance << "): nullptr\n";
+          });           
+        }
+      }
+    }
+    LLVM_DEBUG(dbgs() << "     Pred Stores for MBB: \n");
+    for (auto entry : Info.PredStoreInfosForMBB) {
+          StorePredInfo& storeBefore = entry.second;
+          LLVM_DEBUG({
+            dbgs() << "            Pred Store for MBB from "
+            << storeBefore.storeInst->getParent()->getName()
+            << "(distance " << 
+              storeBefore.distance << "): ";
+            storeBefore.storeInst->dump();
+          });  
+    }
+    if (Info.LastStoreInst) {
+      LLVM_DEBUG({
+        dbgs() << "     Last Store(distance " << Info.LastStoreDistance
+         << "): ";
+        Info.LastStoreInst->dump();
+      });
+    }
+    else {
+      LLVM_DEBUG(dbgs() << "     Last Store: nullptr\n");
+    }
+  }
+}
+
+void X86MDUMitigationPass::dumpDistanceInfo
+  (DenseMap<MachineBasicBlock*, DistanceInfo> Infos) {
+    LLVM_DEBUG(dbgs() << "Dump DistanceInfo, Size = " << Infos.size()
+                      << ":\n");
+    for (auto entry : Infos) {
+      auto MBB = entry.first;
+      auto DistanceInfo = entry.second;
+      LLVM_DEBUG(dbgs() << "   MBB " << "( size = " << DistanceInfo.selfSize
+                        <<  " )" << MBB->getName() << ":\n");
+      for (auto disMap : DistanceInfo.ShortestDistance) {
+        if (disMap.second != INF) {
+          LLVM_DEBUG(dbgs() << "       Target: " << disMap.first->getName()
+                            << " " << disMap.second << "\n");
+        }
+      }
+    }
+}
+
+void X86MDUMitigationPass::dumpStoreDefInfo
+  (DenseMap<MachineInstr*, StoreDefInfo> Infos)
+{
+  for (auto entry : Infos) {
+    LLVM_DEBUG({
+      dbgs() << "Store to be analyzed (from "
+            << entry.first->getParent()->getName() << "): ";
+      entry.first->dump();
+    });
+    LLVM_DEBUG(dbgs() << "     Dump OneLevelDefs, Size = " 
+                      << entry.second.OneLevelDefs.size()
+                      << ":\n");
+    for (MachineInstr* Inst : entry.second.OneLevelDefs) {
+      LLVM_DEBUG({
+        dbgs() << "          Inst (from "
+              << Inst->getParent()->getName() << "): ";
+              Inst->dump(); 
+      });
+    }
+    LLVM_DEBUG(dbgs() << "     Dump TwoLevelDefs, Size = " 
+                      << entry.second.TwoLevelDefs.size()
+                      << ":\n");
+    for (MachineInstr* Inst : entry.second.TwoLevelDefs) {
+      LLVM_DEBUG({
+        dbgs() << "          Inst (from "
+              << Inst->getParent()->getName() << "): ";
+              Inst->dump(); 
+      });
+    }
+    LLVM_DEBUG(dbgs() << "     Dump ThreeLevelDefs, Size = " 
+                      << entry.second.ThreeLevelDefs.size()
+                      << ":\n");
+    for (MachineInstr* Inst : entry.second.ThreeLevelDefs) {
+      LLVM_DEBUG({
+        dbgs() << "          Inst (from "
+              << Inst->getParent()->getName() << "): ";
+              Inst->dump(); 
+      });
+    }
+  }
+}
+
+void X86MDUMitigationPass::dumpDelayedStoreMap(DenseMap<MachineInstr*, int> Map) {
+  LLVM_DEBUG(dbgs() << "Dump DelayedStoreMap, Size = " << Map.size()
+                    << ":\n");
+  for (auto entry : Map) {
+    auto Instr = entry.first;
+    auto Distance = entry.second;
+    LLVM_DEBUG({dbgs() << "     Instr" << "(from  " 
+                       << Instr->getParent()->getName()
+                       <<  "):\n"; 
+                Instr->dump();
+                dbgs() << "          --> Distance: " << Distance << "\n";
+    });
+  }
+}
+
+void X86MDUMitigationPass::dumpLoadsToBeHardened(MachineFunction &MF,
+  DenseMap<MachineBasicBlock*, StoreLoadInfo> StldInfos,
+  DenseMap<MachineInstr*, int> DelayedStoreMap
+) {
+  LLVM_DEBUG(dbgs() <<"Dumping Loads needed to be hardened");
+  for (MachineBasicBlock &MBB : MF) {
+    LLVM_DEBUG(dbgs() << "     MBB: " << MBB.getName() << ":\n");
+    for (MachineInstr& MI : MBB) {
+      if (!MI.mayLoad() && !MI.isReturn()) {
+        continue;
+      }
+      if (loadNeedHardened(&MI, StldInfos, DelayedStoreMap)) {
+        LLVM_DEBUG({
+          dbgs() << "          Load Inst: ";
+          MI.dump();
+        });
+      }
+    }
+  }
+}
+
+/**
+ * ====================================== 
+ *  X86MDUMitigationPass 注册 
+ * ======================================
+ */
+
+// 声明与初始化 X86MDUMitigationPass
+// 第一个参数是 Pass 的 LLVM 类
+// 第二个参数 PASS_KEY 是 Pass 的唯一标识符（字符串常量），在注册和查找 Pass 时使用
+// 第三个参数是 Pass 的描述
+// 第四个参数表示 Pass 是 Analysis Pass (true) 还是 Transformer Pass (false)
+// 第五个参数表示 Pass 是否修改 CFG，即控制流图 (true / false)
+INITIALIZE_PASS_BEGIN(X86MDUMitigationPass, PASS_KEY,
+                      "X86 mdu mitigation", false, false)
+INITIALIZE_PASS_END(X86MDUMitigationPass, PASS_KEY,
+                    "X86 mdu mitigation", false, false)
+
+// 这个函数用于在 X86TargetMachine.cpp 中给后端添加自动化的 Pass 调用
+// 添加 Pass 代码：addPass(createX86MDUMitigationPass());
+// X86MDUMitigationPass 被加在 X86PassConfig::addPreRegAlloc 中
+// 因此，后端会在寄存器分配前 (虚拟寄存器 -> 物理寄存器) 调用这个 Pass
+FunctionPass *llvm::createX86MDUMitigationPass() {
+  return new X86MDUMitigationPass();
+}
diff --git a/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp b/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
index fe5b9a05f81..414070ce0b2 100644
--- a/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
+++ b/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp
@@ -59,27 +59,59 @@
 #include <iterator>
 #include <utility>
 
-using namespace llvm;
+using namespace llvm;         // 使用 llvm 命名空间
 
-#define PASS_KEY "x86-slh"
-#define DEBUG_TYPE PASS_KEY
+#define PASS_KEY "x86-slh"    // X86 SLH Pass 的唯一标识符
+#define DEBUG_TYPE PASS_KEY   // X86 SLH Pass 的调试标识符
 
+/**
+ * ====================================== 
+ *  调试计数器定义 
+ * ======================================
+ */
+
+// 被分析到的条件分支数量
 STATISTIC(NumCondBranchesTraced, "Number of conditional branches traced");
+// 无法分析的条件分支数量
 STATISTIC(NumBranchesUntraced, "Number of branches unable to trace");
+// 被加固的 load address 数量
 STATISTIC(NumAddrRegsHardened,
           "Number of address mode used registers hardaned");
+// 被加固的 load value 数量
 STATISTIC(NumPostLoadRegsHardened,
           "Number of post-load register values hardened");
+// 被加固的 call 和 jmp 指令数量
 STATISTIC(NumCallsOrJumpsHardened,
           "Number of calls or jumps requiring extra hardening");
+// 由于加固而额外插入的指令数量
 STATISTIC(NumInstsInserted, "Number of instructions inserted");
+// 由于加固而额外插入的 lfence 指令数量
 STATISTIC(NumLFENCEsInserted, "Number of lfence instructions inserted");
 
+/**
+ * ====================================== 
+ *  设置 Pass 的命令行控制参数
+ * ======================================
+ */
+
+// LLVM 支持自定义命令行参数，模板类为 cl::opt
+// 通用格式：static cl::opt<type> OptionName ("option-name", cl::desc("Description", ...)
+// 其中 type 为命令行参数类，OptionName 为命令行参数在 LLVM 对应的变量名
+// 第一个参数为命令行选项的名称，第二个参数为命令行参数的文字说明
+// 后续参数对命令行参数属性进行设置，例如，cl::init(value) 给命令行参数设置默认值
+// cl::Hidden 表示不在 help 信息中显示该命令行参数，但用户仍然可以使用该选项
+
+// 是否启用该 Pass
+// 命令行参数: -x86-speculative-load-hardening
+// 默认: false
 static cl::opt<bool> EnableSpeculativeLoadHardening(
     "x86-speculative-load-hardening",
     cl::desc("Force enable speculative load hardening"), cl::init(false),
     cl::Hidden);
 
+// 是否使用 lfence 加固 load
+// 命令行参数: -x86-slh-lfence
+// 默认: false
 static cl::opt<bool> HardenEdgesWithLFENCE(
     PASS_KEY "-lfence",
     cl::desc(
@@ -87,31 +119,44 @@ static cl::opt<bool> HardenEdgesWithLFENCE(
         "loads rather than conditional movs and poisoned pointers."),
     cl::init(false), cl::Hidden);
 
+// 是否加固 load 的数值，在错误推测路径上将值置为 -1
+// 命令行参数: -x86-slh-post-load
+// 默认: true
 static cl::opt<bool> EnablePostLoadHardening(
     PASS_KEY "-post-load",
     cl::desc("Harden the value loaded *after* it is loaded by "
-             "flushing the loaded bits to 1. This is hard to do "
+             "flushing the loaded bits to 1.  This is hard to do "
              "in general but can be done easily for GPRs."),
     cl::init(true), cl::Hidden);
 
+// 是否使用 fence 阻止 call 和 ret 的推测执行
+// 命令行参数: -x86-slh-fence-call-and-ret
+// 默认: false
 static cl::opt<bool> FenceCallAndRet(
     PASS_KEY "-fence-call-and-ret",
     cl::desc("Use a full speculation fence to harden both call and ret edges "
              "rather than a lighter weight mitigation."),
     cl::init(false), cl::Hidden);
 
+// 是否启用跨函数的 predicate_state 传递
+// 命令行参数: -x86-slh-ip
+// 默认: true
 static cl::opt<bool> HardenInterprocedurally(
     PASS_KEY "-ip",
     cl::desc("Harden interprocedurally by passing our state in and out of "
              "functions in the high bits of the stack pointer."),
     cl::init(true), cl::Hidden);
 
+// 是否加固 load，如果启用 pass 但不加固 load，那么只进行 predicate 的生成
+// 命令行参数：-x86-slh-loads
+// 默认：true
 static cl::opt<bool>
     HardenLoads(PASS_KEY "-loads",
                 cl::desc("Sanitize loads from memory. When disable, no "
                          "significant security is provided."),
                 cl::init(true), cl::Hidden);
 
+// 是否对 Spectre v1.2 进行防御，即避免瞬态对控制流的恶意数据注入
 static cl::opt<bool> HardenIndirectCallsAndJumps(
     PASS_KEY "-indirect",
     cl::desc("Harden indirect calls and jumps against using speculatively "
@@ -121,29 +166,61 @@ static cl::opt<bool> HardenIndirectCallsAndJumps(
 
 namespace {
 
+/**
+ * ====================================== 
+ *  Pass 声明
+ * ======================================
+ */
+
+// SLH Pass 继承自 MachineFunctionPass，属于后端 Pass
 class X86SpeculativeLoadHardeningPass : public MachineFunctionPass {
 public:
+
+  /**
+   *  构造函数，传入 Pass ID
+   */
   X86SpeculativeLoadHardeningPass() : MachineFunctionPass(ID) { }
 
+  /**
+   *  Pass 名称
+   */
   StringRef getPassName() const override {
     return "X86 speculative load hardening";
   }
+
+  /**
+   *  实现功能的核心函数，对每个 Function 的机器码进行分析
+   */
   bool runOnMachineFunction(MachineFunction &MF) override;
+
   void getAnalysisUsage(AnalysisUsage &AU) const override;
 
-  /// Pass identification, replacement for typeid.
+  // Pass identification, replacement for typeid.
   static char ID;
 
 private:
-  /// The information about a block's conditional terminators needed to trace
-  /// our predicate state through the exiting edges.
+  // 记录一个基本块 MBB 内包含的所有条件分支和最先被执行的无条件分支
+  // 当然，如果基本块内没有条件分支或无条件分支，则对应字段为空
+  // 对于后端的 CFG，每个基本块可能包含多个分支，这些分支都是 terminator
+  // 例如：
+  // ```
+  //   JG  .Lcond1
+  //   JNE .Lcond2
+  //   JMP .Lfallthrough
+  // ```
+  // 那么，BlockCondInfo 的 CondBrs 会记录条件分支，如例子中的 JG 和 JNE
+  // UncondBr 记录条件分支后最先执行的那个无条件分支，如例子中的 JMP
   struct BlockCondInfo {
+
+    // 当前记录所对应的基本块
+    // 只要是在 pass 中能访问的基本块，都会建立一个对应的 BlockCondInfo
     MachineBasicBlock *MBB;
 
-    // We mostly have one conditional branch, and in extremely rare cases have
-    // two. Three and more are so rare as to be unimportant for compile time.
+    // 记录条件分支，一般情况下，一个基本块内不会超过 2 个条件分支
+    // SmallVector 是经过 LLVM 优化的 vector 数据结构
     SmallVector<MachineInstr *, 2> CondBrs;
 
+    // 记录基本块内的最先执行的无条件分支，实际上，基本块内该分支后的其他分支都不会再被执行到
     MachineInstr *UncondBr;
   };
 
@@ -214,6 +291,12 @@ private:
 
 } // end anonymous namespace
 
+/**
+ * ====================================== 
+ *  Pass 实现
+ * ======================================
+ */
+
 char X86SpeculativeLoadHardeningPass::ID = 0;
 
 void X86SpeculativeLoadHardeningPass::getAnalysisUsage(
@@ -221,49 +304,113 @@ void X86SpeculativeLoadHardeningPass::getAnalysisUsage(
   MachineFunctionPass::getAnalysisUsage(AU);
 }
 
+/**
+ *  在两个基本块中间插入一个新的基本块，从 CFG 看，相当于把一条边拆分成了两条，因此名为 splitEdge。
+ *  原先的控制流： MBB[..., {jcc}, {jmp}] --> Succ
+ *  更新后的控制流：MBB[..., {jcc}, {jmp}] --> NewMBB --> Succ
+ *  虽然逻辑上简单，但实际上需要考虑很多东西，比如 MBB 中分支指令跳转目标的修改，CFG 的修改，
+ *  以及 Succ 中 PHI 指令的更新。
+ * 
+ *  @param MBB: 前驱基本块
+ *  @param Succ: 原本的后继基本块
+ *  @param SuccCount: 从 MBB 连入 Succ 的边数，需要注意的是，不同于 IR CFG，后端 CFG 中，
+ *                    一个基本块可能有多条边连入同一个后继，这是因为后端的基本块中，可能同时
+ *                    存在多个分支指令，例如一组 jcc 指令跟着一个 jmp 指令，而这些分支可能均
+ *                    跳到同一个目标，导致 MBB 和 Succ 多条边
+ *  @param Br: MBB 中跳转到 Succ 的一条条件分支指令
+ *  @param UncondBr: MBB 中跳转到 Succ 的一条无条件分支指令
+ *  @param TII: x86 指令集接口，用来在后端插入新的指令
+ * 
+ *  @return 新插入的基本块，即例子中的 NewMBB
+ */
 static MachineBasicBlock &splitEdge(MachineBasicBlock &MBB,
                                     MachineBasicBlock &Succ, int SuccCount,
                                     MachineInstr *Br, MachineInstr *&UncondBr,
                                     const X86InstrInfo &TII) {
+
+  // 从 MBB 经由条件分支跳转到的 Succ 不能是异常处理基本块 (EHPad)
+  // 实际上，如果 MBB 跳到的 Succ 是 EHPad 基本块，那么不会调用这个函数
   assert(!Succ.isEHPad() && "Shouldn't get edges to EH pads!");
 
+  // 获取 MBB 所在函数 MF，以便在 MF 创建新的基本块
   MachineFunction &MF = *MBB.getParent();
 
+  // 在 MF 中创建一个新的空的基本块 NewMBB
   MachineBasicBlock &NewMBB = *MF.CreateMachineBasicBlock();
 
-  // We have to insert the new block immediately after the current one as we
-  // don't know what layout-successor relationships the successor has and we
-  // may not be able to (and generally don't want to) try to fix those up.
+  // 将 NewMBB 插入 MBB 与它的 layout 后继基本块之间
+  // 所谓 Layout 后继基本块，指的是指令地址相邻的那个后继基本块
+  // 每个基本块有且只有一个 Layout 后继基本块
+  // 例如，假设 MBB 结尾时分支指令，分支跳转时进入后继基本块 A，分支不跳转时进入后继基本块 B
+  // 那么，分支不跳转时，实际上相当于执行了 nop 指令，下一条指令就是典型的 PC+4 (这个4不一定准确)
+  // PC+4 指令所处的基本块，就是 Layout 后继基本块
+  // 插入前：
+  // MBB --> A
+  //     --> B (layout seccessor)
+  // 插入后：
+  // MBB --> A
+  //     --> NewMBB --> B
   MF.insert(std::next(MachineFunction::iterator(&MBB)), &NewMBB);
 
-  // Update the branch instruction if necessary.
+  // 如果 MBB 是由一个条件分支指令跳到的 Succ，那么在中间插入 NewMBB 后需要更新分支目标
   if (Br) {
+    // 已知 MBB 由 Br (一个条件分支 JCC) 跳转到 Succ
+    // 在 MBB 和 Succ 之前插入一个新的基本块 NewMBB 后，Br 应该跳到 NewMBB
+    // 更新前：
+    // MBB[..., ..., jcc(Succ), {jmp}] --> Succ
+    // 更新后：
+    // MBB[..., ..., jcc(NewMBB), {jmp}] --> NewMBB 
+    //                                   --> Succ
     assert(Br->getOperand(0).getMBB() == &Succ &&
            "Didn't start with the right target!");
     Br->getOperand(0).setMBB(&NewMBB);
 
-    // If this successor was reached through a branch rather than fallthrough,
-    // we might have *broken* fallthrough and so need to inject a new
-    // unconditional branch.
+    // 如果 MBB 的结尾指令不是无条件分支，而是条件分支
+    // 那么，当分支不跳转时，会进入原本的唯一后继基本块 (fallthrough)，设为 Old
+    // 而 NewMBB 的插入破坏了原有的 fallthrough 逻辑，导致 fallthrough 到 NewMBB
+    // 因此，为了确保控制流正确性，需要在 MBB 最后新增一个 jmp，跳转到 Old
+    // 更新前（同一行的依次为 layout successor，下同）：
+    // MBB[..., ..., jcc(Succ)] --> OldLayoutSucc
+    // 更新后：
+    // MBB[..., ..., jcc(NewMBB), jmp(OldLayoutSucc)] --> NewMBB[] --> OldLayoutSucc
     if (!UncondBr) {
+      // 获取 NewMBB 在 CFG 上的 Layout 的后继基本块
+      // Layout 后继可以通过 MachineFunction::iterator 即 std::next 访问
       MachineBasicBlock &OldLayoutSucc =
           *std::next(MachineFunction::iterator(&NewMBB));
+      // OldLayoutSucc 后继必然是 MBB 的后继
+      // 否则 MBB 必然存在 jmp 终结符，也就是说 UncondBr 不能为空
       assert(MBB.isSuccessor(&OldLayoutSucc) &&
              "Without an unconditional branch, the old layout successor should "
              "be an actual successor!");
+      // 这个 BuildMI 会在 MBB 的末尾插入一条指令，并且要求这条指令不存在目的寄存器
+      // 这里插入的是 jmp 指令，跳转目标设为 OldLayoutSucc
       auto BrBuilder =
           BuildMI(&MBB, DebugLoc(), TII.get(X86::JMP_1)).addMBB(&OldLayoutSucc);
-      // Update the unconditional branch now that we've added one.
+      // 更新 MBB 所对应的 BlockCondInfo 信息
       UncondBr = &*BrBuilder;
     }
 
-    // Insert unconditional "jump Succ" instruction in the new block if
-    // necessary.
+    // 如果 Succ 不是 NewMBB 的 Layout 后继，说明 Succ 是由 MBB 的分支 Br 跳转到的后继
+    // 在这种情况下，在 NewMBB 基本块中插入 jmp 指令，跳转到 Succ
+    // 更新前（同一行的依次为 layout successor，下同）：
+    // MBB[..., ..., jcc(NewMBB), jmp(OldLayoutSucc)] --> NewMBB[] --> OldLayoutSucc
+    //                                                --> Succ
+    // 更新后：
+    // MBB[..., ..., jcc(NewMBB), jmp(OldLayoutSucc)] --> NewMBB[jmp(Succ)] --> OldLayoutSucc 
+    //                                                                      --> Succ
     if (!NewMBB.isLayoutSuccessor(&Succ)) {
       SmallVector<MachineOperand, 4> Cond;
       TII.insertBranch(NewMBB, &Succ, nullptr, Cond, Br->getDebugLoc());
     }
   } else {
+  // 如果 Br 为空，说明 MBB 不是由条件分支跳到的 Succ
+  // 那么，Succ 应该是 MBB 唯一的后继，并且是 Layout 后继
+  // 这时，使用 MF.insert 的默认方式插入 NewMBB 即可，无需调整分支
+  // 更新前（同一行的依次为 layout successor，下同）：
+  // MBB --> Succ
+  // 更新后：
+  // MBB --> NewMBB --> Succ
     assert(!UncondBr &&
            "Cannot have a branchless successor and an unconditional branch!");
     assert(NewMBB.isLayoutSuccessor(&Succ) &&
@@ -274,41 +421,68 @@ static MachineBasicBlock &splitEdge(MachineBasicBlock &MBB,
   // If this is the only edge to the successor, we can just replace it in the
   // CFG. Otherwise we need to add a new entry in the CFG for the new
   // successor.
+  // 更新 CFG
+  // 这里需要注意的是，CFG 上基本块的关系，和实际基本块在分支路径上的关系，不是一个层面
+  // 因此，前面进行了大量分支的插入和更新，不会反映到 CFG 上
+  // 所以，这里还需要显式地更新 CFG
+  // 具体而言，需要增加 MBB -> NewMBB，以及 BewMBB -> Succ 这两条编边
+  // 如果 SuccCount == 1，说明 MBB 只有一条边连接 Succ，那么使用 replaceSuccessor
+  // 既可以删除原来的 MBB --> Succ 这条边，又能增加新的 MBB --> NewMBB 这条边
+  // 如果 SuccCount > 1，说明 MBB 有多条边连接 Succ，例如 MBB 的多个分支均跳到 Succ
+  // 那么使用 splitSuccessor，在保留 MBB --> Succ 的基础上，增加 MBB --> NewMBB
   if (SuccCount == 1) {
     MBB.replaceSuccessor(&Succ, &NewMBB);
   } else {
     MBB.splitSuccessor(&Succ, &NewMBB);
   }
-
-  // Hook up the edge from the new basic block to the old successor in the CFG.
+  // 在 CFG 增加新的边 NewMBB --> Succ
   NewMBB.addSuccessor(&Succ);
 
-  // Fix PHI nodes in Succ so they refer to NewMBB instead of MBB.
+  // 更新 Succ 基本块开头的 PHI 指令
   for (MachineInstr &MI : Succ) {
+    // 访问到非 PHI 指令，说明后续不存在 PHI 指令，退出循环
     if (!MI.isPHI())
       break;
+
+    // 访问 PHI 指令的所有操作数，每次访问一对（两个）操作数
+    // PHI 指令的操作数是成对出现的，通常是一个值和一个对应的基本块
     for (int OpIdx = 1, NumOps = MI.getNumOperands(); OpIdx < NumOps;
          OpIdx += 2) {
+      // 获取 PHI 指令操作数的数值 OpV
       MachineOperand &OpV = MI.getOperand(OpIdx);
+      // 获取这个数值所来自的基本块 OpMBB
       MachineOperand &OpMBB = MI.getOperand(OpIdx + 1);
       assert(OpMBB.isMBB() && "Block operand to a PHI is not a block!");
+      // 如果 OpMBB 不是 MBB，而是别的前驱基本块，那么这个操作数和 MBB 无关，跳过
       if (OpMBB.getMBB() != &MBB)
         continue;
 
-      // If this is the last edge to the succesor, just replace MBB in the PHI
+      // 如果在更新 CFG 前， MBB 只有一条边连入 Succ
+      // 那么现在这条边被改为由 NewMBB 连入 Succ
+      // 因此，直接把 PHI 指令这个操作数的来源基本块从 MBB 改为 NewMBB，即可退出循环
+      // 例如，原来 Succ 的 PHI 为 phi [MBB, A], [MBB', B]
+      // 更新后变为 phi [NewMBB, A], [MBB', B]
       if (SuccCount == 1) {
         OpMBB.setMBB(&NewMBB);
         break;
       }
 
-      // Otherwise, append a new pair of operands for the new incoming edge.
+      // 如果 MBB 还有其他边连入 Succ（多重条件分支），直接更新操作数来源，可能破坏其它与边的 PHI 输入
+      // 这时只给 PHI 增加一个新的输入，来自 NewMBB，数值为 OpV
+      // 例如，原来 Succ 的 PHI 为 phi [MBB, A], [MBB, B]
+      // 更新后变为 phi [MBB, A], [MBB, B], [NewMBB, A]
+      // 这样没有删除旧的输入，可能会多出来一些重复的 PHI 操作数来源
+      // 在函数 canonicalizePHIOperands 中会进行优化
       MI.addOperand(MF, OpV);
       MI.addOperand(MF, MachineOperand::CreateMBB(&NewMBB));
       break;
     }
   }
 
-  // Inherit live-ins from the successor
+  // 将 Succ 的 livein 寄存器复制给 NewMBB
+  // Live-In 寄存器是指在进入一个基本块时已经被定义并持有有效值的寄存器
+  // 这些寄存器的值会在基本块中使用
+  // 如果 Succ 还有其他输入，这种做法是否可靠？
   for (auto &LI : Succ.liveins())
     NewMBB.addLiveIn(LI);
 
@@ -317,204 +491,244 @@ static MachineBasicBlock &splitEdge(MachineBasicBlock &MBB,
   return NewMBB;
 }
 
-/// Removing duplicate PHI operands to leave the PHI in a canonical and
-/// predictable form.
-///
-/// FIXME: It's really frustrating that we have to do this, but SSA-form in MIR
-/// isn't what you might expect. We may have multiple entries in PHI nodes for
-/// a single predecessor. This makes CFG-updating extremely complex, so here we
-/// simplify all PHI nodes to a model even simpler than the IR's model: exactly
-/// one entry per predecessor, regardless of how many edges there are.
+
+/**
+ *  移除所有 PHI 指令的所有重复条目，使得每个前驱基本块，无论有多少条边连入后继，
+ *  至多只在后继基本块的 PHI 指令中提供一个操作数。
+ *  例如，如果 PHI 指令为 phi = [%V1, %label1], [%V1, %label1], [%V2, %label2]
+ *  那么更新后变为 phi = [%V1, %label1], [%V2, %label2]
+ *  phi 中原本重复条目可能来自以下场景：
+ *  1. 重复的跳转目标：A[...,jcc(B), jcc(B), jmp(B)] --> B
+ *     在这个场景下，B 的 PHI 函数可能有三个来自 A 的同一个操作数，造成 PHI 操作数重复。
+ *  2. 在 splitEdge 函数中，如果 A --> B 有多条边，在插入新的基本块 C 后，即
+ *     A --> C --> B 中，B 的 PHI 节点只是简单地增加了来自 C 的操作数（实际上这些操作数仍来自 A)，
+ *     但仍然保留了原本来自 A 的操作数，造成 PHI 操作数的重复。
+ * 
+ *  @param MF: 函数 MF，对内部所有基本块中的 PHI 进行重复条目删除
+ */
 static void canonicalizePHIOperands(MachineFunction &MF) {
+
+  // 一个集合，用来辅助判断 phi 中的操作数是否重复地来自同一个基本块
   SmallPtrSet<MachineBasicBlock *, 4> Preds;
+  // 一个列表，存放重复操作数在 phi 指令中的 index
   SmallVector<int, 4> DupIndices;
+  
+  // 遍历 MF 中的所有基本块
   for (auto &MBB : MF)
+    // 遍历基本块中的每一条指令
     for (auto &MI : MBB) {
+      // 遇到第一条非 PHI 指令时退出
       if (!MI.isPHI())
         break;
 
-      // First we scan the operands of the PHI looking for duplicate entries
-      // a particular predecessor. We retain the operand index of each duplicate
-      // entry found.
+      // 遍历 PHI 指令 MI 的全部操作数，查找重复 entry
+      // 将这些发生重复的 entry 的 index 存入 DupIndices 列表
       for (int OpIdx = 1, NumOps = MI.getNumOperands(); OpIdx < NumOps;
            OpIdx += 2)
+
+        // 使用一个集合数据结构判断 PHI 操作数的重复情况
+        // insert 函数尝试将一个操作数对应的基本块插入 Preds，并返回一个 pair
+        // 如果 Preds 不存在基本块，则插入，pair.second 为 true
+        // 如果 Preds 已经存在这个基本块，则 pair.second 为 false
+        // 因此，通过检查一个操作数对应的基本块是否已在 Preds 中，判断是否重复
         if (!Preds.insert(MI.getOperand(OpIdx + 1).getMBB()).second)
+          // 如果基本块重复，将操作数对应的 index 加入 DupIndices
           DupIndices.push_back(OpIdx);
 
-      // Now walk the duplicate indices, removing both the block and value. Note
-      // that these are stored as a vector making this element-wise removal
-      // :w
-      // potentially quadratic.
-      //
-      // FIXME: It is really frustrating that we have to use a quadratic
-      // removal algorithm here. There should be a better way, but the use-def
-      // updates required make that impossible using the public API.
-      //
-      // Note that we have to process these backwards so that we don't
-      // invalidate other indices with each removal.
+      // 对于 DupIndices 中的重复 entry，依次使用 RemoveOperand 删除
+      // MI 的 Operand 本质上存放在列表中
+      // RemoveOperand 会将 entry 从 MI 删除，然后对剩下的 entry 进行移位
+      // 因此，RemoveOperand 复杂度为 O(n)
+      // 对于每个重复的操作数，都要执行 RemoveOperand
+      // 因此，这个删除重复 entry 的算法复杂度为 O(n^2)
       while (!DupIndices.empty()) {
+        // 倒序访问 DupIndices 并逐一删除 PHI 中重复的 entry
         int OpIdx = DupIndices.pop_back_val();
-        // Remove both the block and value operand, again in reverse order to
-        // preserve indices.
         MI.RemoveOperand(OpIdx + 1);
         MI.RemoveOperand(OpIdx);
       }
 
+      // 对每个 PHI 指令，需要清空 Preds 并重新维护节点
       Preds.clear();
     }
 }
 
-/// Helper to scan a function for loads vulnerable to misspeculation that we
-/// want to harden.
-///
-/// We use this to avoid making changes to functions where there is nothing we
-/// need to do to harden against misspeculation.
+/**
+ *  分析一个函数内的所有基本块中，是否有可能被推测执行的 load 指令，
+ *  如果有，这些 load 指令将被加固。
+ *  如果没有，函数不需要执行 SLH Pass。
+ * 
+ *  @param MF: 被分析的函数
+ *  @return 如果 MF 中至少存在一条需要加固的 load 指令，返回 true，否则返回 false
+ * 
+ */
 static bool hasVulnerableLoad(MachineFunction &MF) {
+  // 遍历 MF 中每个基本块的每条指令
   for (MachineBasicBlock &MBB : MF) {
     for (MachineInstr &MI : MBB) {
-      // Loads within this basic block after an LFENCE are not at risk of
-      // speculatively executing with invalid predicates from prior control
-      // flow. So break out of this block but continue scanning the function.
+      // 如果遇到 lfence 指令，说明这个基本块的后续 load 都不会被推测执行
+      // 因此，后续 load 都是安全的，退出这个基本块
       if (MI.getOpcode() == X86::LFENCE)
         break;
 
-      // Looking for loads only.
+      // 跳过基本块内的非 load 指令
       if (!MI.mayLoad())
         continue;
 
-      // An MFENCE is modeled as a load but isn't vulnerable to misspeculation.
+      // mfence 指令比较特殊，它维护了访存的顺序性，但不阻止 load 的推测执行，因此不能终止分析
+      // 此外，mfence 指令执行 mayLoad 时也会返回 true，因此需要过滤掉，跳过这条指令
       if (MI.getOpcode() == X86::MFENCE)
         continue;
 
-      // We found a load.
+      // 发现 load，说明 MF 内至少存在一条需要加固的 load 指令，需要执行 SLH Pass
       return true;
     }
   }
 
-  // No loads found.
+  // 没发现 load 指令，说明 MF 不需要执行 SLH Pass
   return false;
 }
 
+/**
+ *  核心函数，对一个函数实现 SLH 加固。
+ * 
+ *  @param MF: 代加固函数。
+ */
 bool X86SpeculativeLoadHardeningPass::runOnMachineFunction(
     MachineFunction &MF) {
   LLVM_DEBUG(dbgs() << "********** " << getPassName() << " : " << MF.getName()
                     << " **********\n");
 
-  // Only run if this pass is forced enabled or we detect the relevant function
-  // attribute requesting SLH.
+  // 如果 SLH 命令行总开关 EnableSpeculativeLoadHardening 没打开
+  // 或者函数 MF 不支持 SLH
+  // 那么直接退出函数
   if (!EnableSpeculativeLoadHardening &&
       !MF.getFunction().hasFnAttribute(Attribute::SpeculativeLoadHardening))
     return false;
 
+  // 初始化架构配置相关对象
   Subtarget = &MF.getSubtarget<X86Subtarget>();
   MRI = &MF.getRegInfo();
   TII = Subtarget->getInstrInfo();
   TRI = Subtarget->getRegisterInfo();
 
-  // FIXME: Support for 32-bit.
+  // 初始化 PS，使用 MF 和 64 位 TargetRegisterClass 初始化一个 PredState 对象
   PS.emplace(MF, &X86::GR64_NOSPRegClass);
 
   if (MF.begin() == MF.end())
-    // Nothing to do for a degenerate empty function...
+    // 如果 MF 是一个空函数，无需加固，直接退出
     return false;
 
-  // We support an alternative hardening technique based on a debug flag.
+  // 如果在命令行开启 HardenEdgesWithLFENCE 选项，那么使用 lfence 方案加固
+  // 直接在各个分支可达的基本块的入口处插入 lfence 指令
   if (HardenEdgesWithLFENCE) {
     hardenEdgesWithLFENCE(MF);
     return true;
   }
 
-  // Create a dummy debug loc to use for all the generated code here.
+  // 创建一个 dummy 的 DebugLoc，用于在该函数中增加指令
   DebugLoc Loc;
 
+  // 获取 MF 入口基本块 Entry
   MachineBasicBlock &Entry = *MF.begin();
+  // 获取 Entry 的第一条非 PHI 指令
   auto EntryInsertPt = Entry.SkipPHIsLabelsAndDebug(Entry.begin());
 
-  // Do a quick scan to see if we have any checkable loads.
+  // 先做一个预扫描，判断 MF 中是否有 load 指令，如果没有，那么返回 false
+  // 否则返回 true
+  // 注意这个 load 可能是被折叠 (folded) 的，也就是嵌入其他指令中的
+  // 例如 cmpl %eax, (%edx)
   bool HasVulnerableLoad = hasVulnerableLoad(MF);
 
-  // See if we have any conditional branching blocks that we will need to trace
-  // predicate state through.
+  // 收集每个基本块中包含的条件分支和无条件分支信息
+  // Infos 列表的每个元素是一个 BlockCondInfo 结构体，存放一个基本块的分支信息
   SmallVector<BlockCondInfo, 16> Infos = collectBlockCondInfo(MF);
 
-  // If we have no interesting conditions or loads, nothing to do here.
+  // 如果 MF 中没有 load，或者 MF 所有基本块都没有分支指令，那么无需加固，直接退出
   if (!HasVulnerableLoad && Infos.empty())
     return true;
 
-  // The poison value is required to be an all-ones value for many aspects of
-  // this mitigation.
+  // 在 MF 入口处插入一个指令，将 secure mask 移入一个虚拟寄存器
+  // 这个虚拟寄存器对应的 LLVM 对象存放在 PS->PoisonReg
+  // 虚拟寄存器存放的是 secure mask，即 -1
   const int PoisonVal = -1;
   PS->PoisonReg = MRI->createVirtualRegister(PS->RC);
+  // MOV64ri32 指令将一个 32 位立即数 PoisonVal 移入目标寄存器 PS->PoisonReg
   BuildMI(Entry, EntryInsertPt, Loc, TII->get(X86::MOV64ri32), PS->PoisonReg)
       .addImm(PoisonVal);
   ++NumInstsInserted;
 
-  // If we have loads being hardened and we've asked for call and ret edges to
-  // get a full fence-based mitigation, inject that fence.
+  // 如果 MF 中有 load，且命令行开启 FenceCallAndRet 开关
+  // 那么在 MF 入口处插入 fence 指令
   if (HasVulnerableLoad && FenceCallAndRet) {
-    // We need to insert an LFENCE at the start of the function to suspend any
-    // incoming misspeculation from the caller. This helps two-fold: the caller
-    // may not have been protected as this code has been, and this code gets to
-    // not take any specific action to protect across calls.
-    // FIXME: We could skip this for functions which unconditionally return
-    // a constant.
+    // 在 Entry 第一个非 PHI 指令处插入 lfence 指令
     BuildMI(Entry, EntryInsertPt, Loc, TII->get(X86::LFENCE));
     ++NumInstsInserted;
     ++NumLFENCEsInserted;
   }
 
-  // If we guarded the entry with an LFENCE and have no conditionals to protect
-  // in blocks, then we're done.
+  // 如果我们已经在 MF 的 entry 插入 lfence，且 MF 不包含其他分支指令
   if (FenceCallAndRet && Infos.empty())
-    // We may have changed the function's code at this point to insert fences.
+    // 那么可以退出
     return true;
 
-  // For every basic block in the function which can b
+  // 如果开启了 HardenInterprocedurally 开关，并且未在 MF 入口插 lfence
   if (HardenInterprocedurally && !FenceCallAndRet) {
-    // Set up the predicate state by extracting it from the incoming stack
-    // pointer so we pick up any misspeculation in our caller.
+    // 那么我们需要处理跨函数的 predicate state 传递问题
+    // 具体而言，对于每个 call 函数的目标地址（函数入口）
+    // 都要从 RSP 解码 predicate state，并存放在 PS->InitialReg 寄存器中
     PS->InitialReg = extractPredStateFromSP(Entry, EntryInsertPt, Loc);
   } else {
-    // Otherwise, just build the predicate state itself by zeroing a register
-    // as we don't need any initial state.
+  // 如果函数入口已有 lfence，或者不支持跨函数的 predicate state 传递
+  // 那么我们初始化 predicate state 为 0，并存放在 PS->InitialReg 中
+
+    // 初始化 PS->InitialReg 寄存器为一个虚拟寄存器
     PS->InitialReg = MRI->createVirtualRegister(PS->RC);
+    // 创建另一个 32 位的虚拟寄存器 PredStateSubReg
     Register PredStateSubReg = MRI->createVirtualRegister(&X86::GR32RegClass);
+    // 使用指令 MOV32r0 将立即数 0 移动到 32 位寄存器 PredStateSubReg
     auto ZeroI = BuildMI(Entry, EntryInsertPt, Loc, TII->get(X86::MOV32r0),
                          PredStateSubReg);
     ++NumInstsInserted;
+
+    // MOV32r0 指令隐式地修改了 EFLAGS 寄存器，这里用 assert 进行了确认
     MachineOperand *ZeroEFLAGSDefOp =
         ZeroI->findRegisterDefOperand(X86::EFLAGS);
     assert(ZeroEFLAGSDefOp && ZeroEFLAGSDefOp->isImplicit() &&
            "Must have an implicit def of EFLAGS!");
+    // 标记 EFLAGS 为 dead，因为这条指令是额外插入的
+    // 它对 EFLAGS 的更新不应该被原程序的其他指令使用
     ZeroEFLAGSDefOp->setIsDead(true);
+    // 使用指令 SUBREG_TO_REG 将一个 PredStateSubReg 数据移入 PS->InitialReg 
+    // SUBREG_TO_REG 能将小位宽的子寄存器 (如 32 位) 移入大位宽寄存器 (如 64 位)
     BuildMI(Entry, EntryInsertPt, Loc, TII->get(X86::SUBREG_TO_REG),
             PS->InitialReg)
-        .addImm(0)
-        .addReg(PredStateSubReg)
-        .addImm(X86::sub_32bit);
+        .addImm(0)    // 目标寄存器中的起始位置
+        .addReg(PredStateSubReg)  // 子寄存器
+        .addImm(X86::sub_32bit);  // 子寄存器的宽度
   }
 
-  // We're going to need to trace predicate state throughout the function's
-  // CFG. Prepare for this by setting up our initial state of PHIs with unique
-  // predecessor entries and all the initial predicate state.
+  // 移除所有 PHI 指令的所有重复条目，使得每个前驱基本块，无论有多少条边连入后继，
+  // 至多只在后继基本块的 PHI 指令中提供一个操作数。
   canonicalizePHIOperands(MF);
 
-  // Track the updated values in an SSA updater to rewrite into SSA form at the
-  // end.
+  // 为了让 MF 中所有基本块都能使用 predicate state，这里初始化一个 SSAUpdater
+  // 并将存放 predicate state 的寄存器 PS->InitialReg 加入 SSAUpdater
   PS->SSA.Initialize(PS->InitialReg);
   PS->SSA.AddAvailableValue(&Entry, PS->InitialReg);
 
-  // Trace through the CFG.
+  // 沿着 CFG 将 predicate state 在 MF 的所有基本块入口处传播与更新
+  // 将新插入的 cmov 指令存入 CMovs
   auto CMovs = tracePredStateThroughCFG(MF, Infos);
 
-  // We may also enter basic blocks in this function via exception handling
-  // control flow. Here, if we are hardening interprocedurally, we need to
-  // re-capture the predicate state from the throwing code. In the Itanium ABI,
-  // the throw will always look like a call to __cxa_throw and will have the
-  // predicate state in the stack pointer, so extract fresh predicate state from
-  // the stack pointer and make it available in SSA.
-  // FIXME: Handle non-itanium ABI EH models.
+  // 如果 HardenInterprocedurally 开启，那么需要支持异常处理相关的基本块
+  // 异常处理的控制流也可能进入函数的基本块，如果要实现跨函数加固，
+  // 我们需要从抛出异常的代码中重新捕获 predicate state。在 Itanium ABI 中，
+  // 异常抛出总是表现为对 __cxa_throw 的调用，并且 predicate state 会保存在栈指针中，
+  // 因此我们需要从栈指针中提取出新的 predicate state，并使其在 SSAUpdater 中可用。
   if (HardenInterprocedurally) {
+    // 遍历 MF 的所有基本块，对于异常处理相关的基本块且目标机器使用 Itanium ABI
+    // 那么就从 RSP 中解码 predicate state 并加入 PS->SSA 这个 SSAUpdater 实例
     for (MachineBasicBlock &MBB : MF) {
       assert(!MBB.isEHScopeEntry() && "Only Itanium ABI EH supported!");
       assert(!MBB.isEHFuncletEntry() && "Only Itanium ABI EH supported!");
@@ -527,146 +741,198 @@ bool X86SpeculativeLoadHardeningPass::runOnMachineFunction(
     }
   }
 
+  // 如果开启 HardenIndirectCallsAndJumps，那么不仅防御条件分支，还防御固定目标的间接分支
+  // 固定目标的间接分支，指的是间接分支的目标是编译时已知的，例如 switch 语句的分支 
   if (HardenIndirectCallsAndJumps) {
-    // If we are going to harden calls and jumps we need to unfold their memory
-    // operands.
+    // 如果要加固间接分支，那么需要对间接分支中的 load 操作进行展开
+    // 也就是说，如果一个分支指令的跳转目标需要通过访存获得
+    // 那么就显式地将访存数据存放在一个虚拟寄存器中，以便加固这个寄存器
     unfoldCallAndJumpLoads(MF);
 
-    // Then we trace predicate state through the indirect branches.
+    // 这里实现对间接分支的 predicate state 更新
+    // 从而支持防御间接分支触发的类似 Spectre v1 类型的攻击
     auto IndirectBrCMovs = tracePredStateThroughIndirectBranches(MF);
+    // 将新插入的 cmov 指令存入 CMovs
     CMovs.append(IndirectBrCMovs.begin(), IndirectBrCMovs.end());
   }
 
-  // Now that we have the predicate state available at the start of each block
-  // in the CFG, trace it through each block, hardening vulnerable instructions
-  // as we go.
+  // 根据 predicate state，加固每个基本块中的每个 load 指令
   tracePredStateThroughBlocksAndHarden(MF);
 
-  // Now rewrite all the uses of the pred state using the SSA updater to insert
-  // PHIs connecting the state between blocks along the CFG edges.
+  // 对于新加入的 cmov 指令，它们会使用和更新 predicate state
+  // 但我们还没有在 SSAUpdater 中更新它们，因此它们可能没有遵循 SSA 规范
+  // 也就是说，cmov 可能直接以 PS->InitialReg 作为源寄存器和目的寄存器
+  // 这里对这些 cmov 的所有寄存器进行 SSA 规范的更新
   for (MachineInstr *CMovI : CMovs)
+    // 需要考虑 cmov 的所有源操作数和目的操作数
     for (MachineOperand &Op : CMovI->operands()) {
+      // 筛选出以 PS->InitialReg 作为源寄存器和目的寄存器的操作数
       if (!Op.isReg() || Op.getReg() != PS->InitialReg)
         continue;
 
+      // 如果某个操作数的寄存器使用不再符合 SSA 的要求，RewriteUse 会重写这个使用
+      // 可能会涉及到用 PHI 节点结果替换原来的寄存器，或者直接更新使用的寄存器名称
       PS->SSA.RewriteUse(Op);
     }
 
+  // 通过调试接口输出加固后结果
   LLVM_DEBUG(dbgs() << "Final speculative load hardened function:\n"; MF.dump();
              dbgs() << "\n"; MF.verify(this));
   return true;
 }
 
-/// Implements the naive hardening approach of putting an LFENCE after every
-/// potentially mis-predicted control flow construct.
-///
-/// We include this as an alternative mostly for the purpose of comparison. The
-/// performance impact of this is expected to be extremely severe and not
-/// practical for any real-world users.
+/**
+ *  lfence 加固方案：一种最简单的加固策略，在可能发生错误预测的控制流路径上增加 lfence 指令,
+ *  实现这种策略的主要目的是与 SLH 加固策略进行性能分析。
+ *  增加大量 lfence 会对程序性能造成巨大的损失，因此在现实应用中不适合使用该加固方案。
+ * 
+ *  @param MF: 待加固的函数
+ */
 void X86SpeculativeLoadHardeningPass::hardenEdgesWithLFENCE(
     MachineFunction &MF) {
-  // First, we scan the function looking for blocks that are reached along edges
-  // that we might want to harden.
+  // 一个可自动调整大小的集合，初始大小设置为 8，集合元素为基本块
+  // 这个集合存放可能由条件分支指令进入的基本块
+  // 在得到这个集合后，在其中每个基本块的入口插入 lfence 即可实现 lfence 加固方案
   SmallSetVector<MachineBasicBlock *, 8> Blocks;
   for (MachineBasicBlock &MBB : MF) {
-    // If there are no or only one successor, nothing to do here.
+    // 如果一个基本块没有后继或只有一个后继，那么它的终止符不可能触发分支预测，跳过
     if (MBB.succ_size() <= 1)
       continue;
 
-    // Skip blocks unless their terminators start with a branch. Other
-    // terminators don't seem interesting for guarding against misspeculation.
+    // 如果一个基本块没有终止符 (在后端机器码生成时这种情况可能发生)，或者终止符不是分支指令，跳过
+    // isBranch 在遇到直接分支、间接分支、条件分支、call 和 ret 时返回 true
+    // isBranch 在遇到异常处理相关的分支指令时 (如 catchret 和 cleanupret) 返回 true
+    // 其余指令则返回 false
     auto TermIt = MBB.getFirstTerminator();
     if (TermIt == MBB.end() || !TermIt->isBranch())
       continue;
 
-    // Add all the non-EH-pad succossors to the blocks we want to harden. We
-    // skip EH pads because there isn't really a condition of interest on
-    // entering.
+    // 对于以分支结尾、后继不少于两个的基本块，遍历其后继基本块 (successors)
+    // 如果后继基本块是异常处理基本块 (EHPad, Exception Handler Padding)，跳过
+    // 因为 EHPad 不会通过条件分支指令进入
+    // 否则，将后继基本块加入 Blocks 集合中
     for (MachineBasicBlock *SuccMBB : MBB.successors())
       if (!SuccMBB->isEHPad())
         Blocks.insert(SuccMBB);
   }
 
+  // 遍历 Blocks 中的基本块，这些基本块可能由条件分支进入
+  // 在这些基本块的首个非 PHI 指令处，插入 lfence 指令
   for (MachineBasicBlock *MBB : Blocks) {
+    // 获取基本块 MBB 的第一条非 PHI 指令的位置
     auto InsertPt = MBB->SkipPHIsAndLabels(MBB->begin());
+    // 调用 BuildMI 指令在该位置插入 lfence 指令
     BuildMI(*MBB, InsertPt, DebugLoc(), TII->get(X86::LFENCE));
+    // 更新插入指令计数器
     ++NumInstsInserted;
     ++NumLFENCEsInserted;
   }
 }
 
+/**
+ *  分析一个函数中包含的条件分支和首个被执行到的无条件分支，
+ *  以便后续在每个分支所指向的基本块中插入 cmov 指令，生成 predicate state。
+ *  对于每个基本块，都会建立一个 BlockCondInfo 数据结构，存放搜索结果，
+ *  每个 BlockCondInfo 包含 CondBrs 和 UncondBrs 字段，分别记录条件分支和无条件分支。
+ *  
+ *  @param MF: 待分析函数，对 MF 内每个基本块收集分支信息
+ *  @return 一个列表，每个元素为一个基本块所对应的 BlockCondInfo
+ */
 SmallVector<X86SpeculativeLoadHardeningPass::BlockCondInfo, 16>
 X86SpeculativeLoadHardeningPass::collectBlockCondInfo(MachineFunction &MF) {
+
+  // 新建一个存放各个基本块 BlockCondInfo 的列表
   SmallVector<BlockCondInfo, 16> Infos;
 
-  // Walk the function and build up a summary for each block's conditions that
-  // we need to trace through.
+  // 遍历 MF 函数的所有基本块，将每个基本块内的条件和无条件分支记录在对应的 BlockCondInfo 中
+  // 如果基本块内有条件分支，记录 BlockCondInfo.CondBrs 中
+  // 如果基本块内有无条件分支，记录在 BlockCondInfo.UncondBr 中
   for (MachineBasicBlock &MBB : MF) {
-    // If there are no or only one successor, nothing to do here.
+    // 如果一个基本块没有后继或只有一个后继，那么它的终止符不可能触发分支预测，跳过
     if (MBB.succ_size() <= 1)
       continue;
-
-    // We want to reliably handle any conditional branch terminators in the
-    // MBB, so we manually analyze the branch. We can handle all of the
-    // permutations here, including ones that analyze branch cannot.
-    //
-    // The approach is to walk backwards across the terminators, resetting at
-    // any unconditional non-indirect branch, and track all conditional edges
-    // to basic blocks as well as the fallthrough or unconditional successor
-    // edge. For each conditional edge, we track the target and the opposite
-    // condition code in order to inject a "no-op" cmov into that successor
-    // that will harden the predicate. For the fallthrough/unconditional
-    // edge, we inject a separate cmov for each conditional branch with
-    // matching condition codes. This effectively implements an "and" of the
-    // condition flags, even if there isn't a single condition flag that would
-    // directly implement that. We don't bother trying to optimize either of
-    // these cases because if such an optimization is possible, LLVM should
-    // have optimized the conditional *branches* in that way already to reduce
-    // instruction count. This late, we simply assume the minimal number of
-    // branch instructions is being emitted and use that to guide our cmov
-    // insertion.
-
+    
+    // 在每个基本块中收集所有条件分支和无条件分支，包括无法分析的间接分支，如 `jmpq *%rax`
+    // 需要注意的是，不同于 IR，后端 CFG 中，每个基本块可以包含多个分支
+    // 如果有多个分支，如果是有效分支，必然是一组条件分支跟着一组无条件分支
+    // 一个例子为：
+    // ```
+    // ...
+    //   JG  .Lcond1
+    //   JNE .Lcond2
+    //   JMP .Lfallthrough
+    // ```
+    // 该分析能确定基本块在条件分支跳转时的后继 (condition edge) 和不跳转的后继 (fallthrough edge)
+    // 从而在后续的 predicate 分析过程中，给相应的后继基本块增加 cmov
+
+    // 这里也简单介绍增加 cmov 与收集到的条件/无条件分支之间的关系
+    // 对于 condition edge，在后继节点，使用不跳转条件建立 cmov 指令，在跳转时等价于 nop 指令
+    // 对于 fallthrough edge，可能是多个条件分支共享的
+    // 因此，在后继节点，对每个条件分支各自建立 cmov 指令
+    // 这些 cmov 可能可以合并，但考虑到 LLVM 已经对条件分支本身做了优化，减少了条件分支数量
+    // 因此，该 pass 不合并 cmov 
+
+    // 收集 BlockCondInfo 用到的算法如下：
+    // 对一个基本块，建立一个空的 BlockCondInfo，CondBrs 清空，UncondBr 置为 nullptr
+    // 从最后一个 terminator 开始，倒序遍历指令，假设当前访问的指令为 I
+    // 1. 如果 I 不是 terminator，退出遍历
+    // 2. 如果 I 是非分支 terminator，清空 CondBrs 并退出
+    // 3. 如果 I 是无条件分支或间接分支，清空 CondBrs，更新 UncondBr 为 I
+    // 4. 如果 I 是条件分支，将 I 插入 CondBrs
+    // 对于上述例子，运行此算法后，CondBrs = {JG, JNE}, UnconBr = {JMP}
+
+    // 初始化一个空的 BlockCondInfo，并与当前访问到的基本块 MBB 绑定
     BlockCondInfo Info = {&MBB, {}, nullptr};
 
-    // Now walk backwards through the terminators and build up successors they
-    // reach and the conditions.
+    // 倒序遍历基本块的终止符 (terminators)，并收集该基本块的 BlockCondInfo 信息
+    // 需要注意的是，不同于 IR，后端 CFG 中，每个基本块可以包含多个 terminator
+    // 如果有多个 terminator，需要连续出现在基本块结尾
+    // 如果多个 terminator 均为分支指令，那么它们共享 CPU Flag，并且条件分支必须出现在无条件分支之前
+    // 上述例子体现了这一特点
     for (MachineInstr &MI : llvm::reverse(MBB)) {
-      // Once we've handled all the terminators, we're done.
+      // 如果倒序遍历到非终止符，那么遍历结束
       if (!MI.isTerminator())
         break;
 
-      // If we see a non-branch terminator, we can't handle anything so bail.
+      // 如果遍历到非分支终止符，例如 trap 指令和 unreachable 指令，
+      // 那么认为该基本块无条件分支，并且结束遍历
       if (!MI.isBranch()) {
         Info.CondBrs.clear();
         break;
       }
 
-      // If we see an unconditional branch, reset our state, clear any
-      // fallthrough, and set this is the "else" successor.
+      // 如果遇到无条件分支，那么必然出现在所有条件分支之前
+      // 因此，清空 Info.CondBrs
+      // 并且更新 Info.UncondBr 为这个无条件分支
+      // 该无分支的跳转目标为条件分支的 else 路径
       if (MI.getOpcode() == X86::JMP_1) {
         Info.CondBrs.clear();
         Info.UncondBr = &MI;
         continue;
       }
 
-      // If we get an invalid condition, we have an indirect branch or some
-      // other unanalyzable "fallthrough" case. We model this as a nullptr for
-      // the destination so we can still guard any conditional successors.
-      // Consider code sequences like:
+      // 如果遇到一个无效条件，例如一个未知跳转目标的间接分支，那么无法分析分支目标，
+      // 即我们不知道 fallthrough 基本块是哪个
+      // 在指针情况，如果无效条件的分支之前有其他条件分支，我们仍想加固这些条件分支
+      // 一个例子如下：
       // ```
       //   jCC L1
       //   jmpq *%rax
       // ```
-      // We still want to harden the edge to `L1`.
+      // 我们仍然想要加固 L1 基本块中的 load
+      // 因此，清空 Info.CondBrs，更新 Info.UncondBr，然后继续往前遍历
       if (X86::getCondFromBranch(MI) == X86::COND_INVALID) {
         Info.CondBrs.clear();
         Info.UncondBr = &MI;
         continue;
       }
 
-      // We have a vanilla conditional branch, add it to our list.
+      // 因此，将条件分支添加到 Info.CondBrs 以供后续分析
       Info.CondBrs.push_back(&MI);
     }
+
+    // 在遍历完基本块 MBB 的终止符后，如果 Info.CondBrs 为空，说明 MBB 不包含条件分支
+    // 更新相关的调试标志
     if (Info.CondBrs.empty()) {
       ++NumBranchesUntraced;
       LLVM_DEBUG(dbgs() << "WARNING: unable to secure successors of block:\n";
@@ -674,194 +940,312 @@ X86SpeculativeLoadHardeningPass::collectBlockCondInfo(MachineFunction &MF) {
       continue;
     }
 
+    // 无论基本块是否包含条件分支或者无条件分支，即无论 Info 是否为空，最后都加入 Infos
+    // 最终，函数 MF 的每个基本块都在 Infos 中有一个记录
     Infos.push_back(Info);
   }
 
+  // 返回分析结果
   return Infos;
 }
 
-/// Trace the predicate state through the CFG, instrumenting each conditional
-/// branch such that misspeculation through an edge will poison the predicate
-/// state.
-///
-/// Returns the list of inserted CMov instructions so that they can have their
-/// uses of the predicate state rewritten into proper SSA form once it is
-/// complete.
+/**
+ *  为 CFG 的基本块生成 predicate state，
+ *  这时，如果是分支被错误预测而进入基本块，那么 cmov 会将 predicate state 置为掩码值，
+ *  反之，如果分支是正确跳转的，那么 cmov 等价于一个 nop 指令。
+ *  分支信息需要用 collectBlockCondInfo 函数事先收集好并将结果传入该函数。
+ * 
+ *  @param MF: 待分析函数
+ *  @param Infos: 一个列表，每个元素为一个 MF 的一个基本块所对应的 BlockCondInfo，
+ *                BlockCondInfo 记录了这个基本块内的条件分支和无条件分支
+ *  @return 一个列表，每个元素为一个新插入的 cmov 指令，
+ *          这有助于后续将 predicate state 以合适的 SSA 格式用来加固 load 指令
+ */
 SmallVector<MachineInstr *, 16>
 X86SpeculativeLoadHardeningPass::tracePredStateThroughCFG(
     MachineFunction &MF, ArrayRef<BlockCondInfo> Infos) {
-  // Collect the inserted cmov instructions so we can rewrite their uses of the
-  // predicate state into SSA form.
+
+  // 一个列表，记录每个插入的 cmov 指令，以便后续加固 load 使用
   SmallVector<MachineInstr *, 16> CMovs;
 
   // Now walk all of the basic blocks looking for ones that end in conditional
   // jumps where we need to update this register along each edge.
+  // 遍历 Infos，对其中的每个条件分支，在目标基本块插入 cmov 指令
   for (const BlockCondInfo &Info : Infos) {
+    // Info 所对应的基本块
     MachineBasicBlock &MBB = *Info.MBB;
+    // MBB 中的条件分支列表
     const SmallVectorImpl<MachineInstr *> &CondBrs = Info.CondBrs;
+    // MBB 执行到的首个无条件分支
     MachineInstr *UncondBr = Info.UncondBr;
 
+    // 更新调试信息，NumCondBranchesTraced 表示有 BlockCondInfo 记录的基本块数量
     LLVM_DEBUG(dbgs() << "Tracing predicate through block: " << MBB.getName()
                       << "\n");
     ++NumCondBranchesTraced;
 
-    // Compute the non-conditional successor as either the target of any
-    // unconditional branch or the layout successor.
+    // 如果一个基本块存在无条件分支，那么得到它的跳转目标，否则，得到 layout 后继
+    // 得到的基本块 UncondSucc 就是 fallthrough 基本块，即条件分支不跳转时最终落入的基本块
+    // 特别的，如果无条件分支是间接分支且不知道跳转目标，那么认为不存在 fallthrough 基本块
     MachineBasicBlock *UncondSucc =
         UncondBr ? (UncondBr->getOpcode() == X86::JMP_1
                         ? UncondBr->getOperand(0).getMBB()
                         : nullptr)
                  : &*std::next(MachineFunction::iterator(&MBB));
 
-    // Count how many edges there are to any given successor.
+    // SuccCount 是一个 map，键为基本块 K，值为从 MBB 到 K 的边数
     SmallDenseMap<MachineBasicBlock *, int> SuccCounts;
+    // 如果 fallthrough 基本块存在，那么从 MBB 到这个基本块存在一条边
     if (UncondSucc)
       ++SuccCounts[UncondSucc];
+    // 基本块中每包含一个条件分支，那么从 MBB 到跳转目标基本块的边数就加 1
     for (auto *CondBr : CondBrs)
       ++SuccCounts[CondBr->getOperand(0).getMBB()];
 
     // A lambda to insert cmov instructions into a block checking all of the
     // condition codes in a sequence.
+    // 定义一个 lambda 函数 BuildCheckingBlockForSuccAndConds
+    /**
+     *  这个函数会在 MBB[..., JCC(Succ), {JMP}] --> Succ 的中间插入基本块 CheckingMBB，
+     *  然后在 CheckingMBB 插入 cmov 指令，条件与 JCC 条件相反，
+     *  cmov 指令的操作数来源，一个是 predicate_state 的初始值，另一个是掩码值。
+     *  如果 JCC 存在多个跳转条件 Conds，那么对每个跳转条件各插入一个 cmov 指令。
+     *  最终得到 CFG 为：
+     *  MBB[..., JCC(Succ), {JMP}] --> CheckingMBB[cmov, ..., JMP(Succ)] --> Succ
+     *  特别的，如果 MBB 到 Succ 只有一条边，并且 Succ 只有 MBB 这一个前驱，
+     *  那么 CheckingMBB 可以和 Succ 合并，得到：
+     *  MBB[..., JCC(Succ), {JMP}] --> Succ[cmov, ...]
+     * 
+     *  @param MBB: 可能包含条件分支的前驱
+     *  @param Succ: 如果 MBB 包含条件分支，这个条件分支的跳转目标
+     *  @param SuccCount: 从 MBB 到 Succ 的边数
+     *  @param Br: MBB 中跳转到 Succ 的条件分支，将在新基本块中插入相应的 cmov
+     *  @param UncondBr: MBB 中可能存在的无条件分支，指向 Br 的 fallthrough 基本块
+     *  @param Conds: 一个列表，记录了 Br 的跳转条件
+     */
     auto BuildCheckingBlockForSuccAndConds =
         [&](MachineBasicBlock &MBB, MachineBasicBlock &Succ, int SuccCount,
             MachineInstr *Br, MachineInstr *&UncondBr,
             ArrayRef<X86::CondCode> Conds) {
-          // First, we split the edge to insert the checking block into a safe
-          // location.
+          // 如果 MBB 只有一条边到达 Succ，并且 Succ 只有 MBB 一个前驱
+          // 那么无需插入新基本块，只需要在 Succ 插入 cmov
+          // 否则，新增基本块 CheckingMBB，后续在 CheckingMBB 插入 cmov
           auto &CheckingMBB =
               (SuccCount == 1 && Succ.pred_size() == 1)
                   ? Succ
                   : splitEdge(MBB, Succ, SuccCount, Br, UncondBr, *TII);
 
+          // 确保 EFLAGS 在 CheckingMBB 是活跃的，从而避免 MBB 对 EFLAGS 的未知更改
+          // 因为 CheckingMBB 中的 cmov 会用到 EFLAGS
+          // 如果 EFLAGS 在 Succ 是活跃的，那么上一行代码能够确保其在 CheckingMBB 活跃
+          // 否则，需要在 CheckingMBB 中，额外增加 EFLAGS 的活跃标记
           bool LiveEFLAGS = Succ.isLiveIn(X86::EFLAGS);
           if (!LiveEFLAGS)
             CheckingMBB.addLiveIn(X86::EFLAGS);
 
-          // Now insert the cmovs to implement the checks.
+          // 获取 cmov 的插入点，这个插入点需要在 CheckingMBB 的开头
           auto InsertPt = CheckingMBB.begin();
+          // 如果 CheckingMBB 就是 Succ，那么其不可能存在 PHI 指令，因为 Succ 只有一个前驱
+          // 否则，因为 CheckingMBB 是刚加入的基本块，它的内容已知是不包含 PHI 指令的
           assert((InsertPt == CheckingMBB.end() || !InsertPt->isPHI()) &&
                  "Should never have a PHI in the initial checking block as it "
                  "always has a single predecessor!");
 
-          // We will wire each cmov to each other, but need to start with the
-          // incoming pred state.
+          // PS->InitialReg 是在 Pass 初始化时就预设好的
+          // 这个寄存器目前是一个虚拟寄存器，存放的是 predicate_state 初始值
+          // 在后续，如果有连续多条 cmov，那么 CurStateReg 将在插入一个 cmov 后
+          // 被更新为 cmov 的目的寄存器，从而确保 predicate_state 每经过一个 cmov 后的正确更新
           unsigned CurStateReg = PS->InitialReg;
 
+          // 对每个 Conds 中的条件，在 checkingMBB 插入一个 cmov 指令
+          // 对于 Taken 路径，只有一个 Cond
+          // 对于 Not Taken 路径，可能有多个条件分支 fallthrough 到同一个基本块
+          // 这时可能有多个条件
           for (X86::CondCode Cond : Conds) {
+            // cmov 有不同位宽的版本，这里我们选用与 predicate_state 等长的版本
+            // PS->RC 存放了 predicate_state 的寄存器类型，包含了位宽信息
+            // 最终得到我们想要的那个 cmov 指令版本的操作码 CMovOp
             int PredStateSizeInBytes = TRI->getRegSizeInBits(*PS->RC) / 8;
             auto CMovOp = X86::getCMovOpcode(PredStateSizeInBytes);
 
+            // 我们用 MRI 创建一个新的虚拟寄存器，这个寄存器作为 cmov 的目的寄存器
             Register UpdatedStateReg = MRI->createVirtualRegister(PS->RC);
-            // Note that we intentionally use an empty debug location so that
-            // this picks up the preceding location.
+
+            // 现在我们用 BuildMI 创建 cmov 指令
+            // 前两个参数与插入位置有关，第一个表示插入的基本块，第二个表示基本块内插入点
+            // 第三个参数用于调试
+            // 第四个参数为 cmov 指令的操作码
+            // 第五个参数为 cmov 指令的目的寄存器
+            // 得到指令后，我们再用 addReg 和 addImm 给 cmov 指令更新源寄存器和立即数字段
+            // 其中，第一个源寄存器为 cmov 第一个数据来源，来自最新的 predicate_state 寄存器
+            // 第二个源寄存器为 cmov 第二个数据来源，来自掩码值所在寄存器
+            // 立即数字段记录的是 cmov 条件，来自 Cond
             auto CMovI = BuildMI(CheckingMBB, InsertPt, DebugLoc(),
                                  TII->get(CMovOp), UpdatedStateReg)
                              .addReg(CurStateReg)
                              .addReg(PS->PoisonReg)
                              .addImm(Cond);
-            // If this is the last cmov and the EFLAGS weren't originally
-            // live-in, mark them as killed.
+            // 如果这是插入的最后一个 cmov，且 Succ 中 EFLAGS 不活跃
+            // 那么我们可以标记 EFLAGS 为 kill 状态，即在 EFLAGS 下次更新前
+            // 不会再用到 EFLAGS 的结果
             if (!LiveEFLAGS && Cond == Conds.back())
               CMovI->findRegisterUseOperand(X86::EFLAGS)->setIsKill(true);
 
+            // 更新调试信息，新插入指令数量加 1
             ++NumInstsInserted;
             LLVM_DEBUG(dbgs() << "  Inserting cmov: "; CMovI->dump();
                        dbgs() << "\n");
 
-            // The first one of the cmovs will be using the top level
-            // `PredStateReg` and need to get rewritten into SSA form.
+            // 将新增的第一条 cmov 指令保存在 CMovs 列表中
+            // 第一条 cmov 指令的 predicate_state 来自 PS->InitialReg 寄存器
             if (CurStateReg == PS->InitialReg)
               CMovs.push_back(&*CMovI);
 
-            // The next cmov should start from this one's def.
+            // 更新 predicate_state 所在的寄存器为最新插入的 cmov 的目的寄存器
             CurStateReg = UpdatedStateReg;
           }
 
-          // And put the last one into the available values for SSA form of our
-          // predicate state.
+          // 新增寄存器后，在 SSA 管理器中设置最后一个 cmov 的目的寄存器为可用寄存器
+          // 使得后续的 load 指令能够使用 CurStateReg 的数据加固 load
           PS->SSA.AddAvailableValue(&CheckingMBB, CurStateReg);
         };
 
+    // 一个列表，记录了每个条件分支的 fallthrough 条件
+    // 在同一个基本块内的条件分支，都会 fallthrough 到同一个后继基本块
     std::vector<X86::CondCode> UncondCodeSeq;
+
+    // 访问基本块内的每个条件分支，收集分支的跳转和不跳转条件
+    // 对于每个跳转，在目标基本块插入一个 cmov，条件为分支的不跳转条件
+    // 对于每个不跳转，将 fallthrough 的相反条件，即不跳转条件，插入 UncondCodeSeq 中
     for (auto *CondBr : CondBrs) {
+      // 获取条件分支的跳转目标基本块
       MachineBasicBlock &Succ = *CondBr->getOperand(0).getMBB();
+      // SuccCounts 记录了从 MBB 到 Succ 的边数
       int &SuccCount = SuccCounts[&Succ];
 
+      // 跳转条件，用于在 fallthrough 路径建立 cmov
       X86::CondCode Cond = X86::getCondFromBranch(*CondBr);
-      X86::CondCode InvCond = X86::GetOppositeBranchCondition(Cond);
       UncondCodeSeq.push_back(Cond);
 
+      // 不跳转条件，用于在跳转目标路径建立 cmov
+      X86::CondCode InvCond = X86::GetOppositeBranchCondition(Cond);
+      // 在 MBB --> Succ 的边上插入一条 cmov 指令
+      // cmov 的条件为分支的不跳转条件
+      // 如果 MBB 到 Succ 只有一条边，那么将 cmov 插入 Succ 头部
+      // 否则，如果 MBB 到 Succ 有多条边，那么在分支 CondBr 对应的边上插入新基本块
+      // 然后，将 cmov 插入新基本块
       BuildCheckingBlockForSuccAndConds(MBB, Succ, SuccCount, CondBr, UncondBr,
                                         {InvCond});
 
-      // Decrement the successor count now that we've split one of the edges.
-      // We need to keep the count of edges to the successor accurate in order
-      // to know above when to *replace* the successor in the CFG vs. just
-      // adding the new successor.
+      // 插入一个 cmov 后，意味着我们 split 了 MBB --> Succ 的一条边
+      // 如果还有其它边，后续会用 MBB 中的另一个条件分支建立关系，本轮不干预
+      // 因此，我们将 SuccCount 减 1
+      // 最终，SuccCount 将减到 0
       --SuccCount;
     }
 
-    // Since we may have split edges and changed the number of successors,
-    // normalize the probabilities. This avoids doing it each time we split an
-    // edge.
+    // 因为我们修改了 MBB 的后继，所以我们需要更新 MBB 到各个后继的跳转概率值
+    // 具体而言，我们需要重新归一化 MBB 跳转到各个后继的概率值，使得概率值之和为 1
+    // 这个概率值后续将用于优化
     MBB.normalizeSuccProbs();
 
-    // Finally, we need to insert cmovs into the "fallthrough" edge. Here, we
-    // need to intersect the other condition codes. We can do this by just
-    // doing a cmov for each one.
+    // 如果没有 fallthrough 基本块，例如，基本块的最后一个分支是间接分支
+    // 那么，我们无法准确知道哪个基本块是 fallthrough 基本块，也就无法在相应位置插入 cmov
     if (!UncondSucc)
-      // If we have no fallthrough to protect (perhaps it is an indirect jump?)
-      // just skip this and continue.
       continue;
 
+    // 如果存在 fallthrough 基本块，那么 fallthrough 基本块必然唯一
+    // 这是因为不跳转的条件分支等价于 nop，除了 fallthrough 不会产生额外路径
     assert(SuccCounts[UncondSucc] == 1 &&
            "We should never have more than one edge to the unconditional "
            "successor at this point because every other edge must have been "
            "split above!");
 
-    // Sort and unique the codes to minimize them.
+    // 去除 UncondCodeSeq 中相同的 Cond，避免建立相同条件的 cmov
+    // 去重时用到 sotr 和 unique 组合的方法，将相同的元素放在列表末尾
+    // 然后再用 erase 将末尾的重复 Cond 删除
     llvm::sort(UncondCodeSeq);
     UncondCodeSeq.erase(std::unique(UncondCodeSeq.begin(), UncondCodeSeq.end()),
                         UncondCodeSeq.end());
 
-    // Build a checking version of the successor.
+    // 在 MBB 中各个条件分支的共同 fallthrough 基本块 UncondSucc
+    // 用每个分支的跳转条件（不跳转的相反条件）建立 cmov
     BuildCheckingBlockForSuccAndConds(MBB, *UncondSucc, /*SuccCount*/ 1,
                                       UncondBr, UncondBr, UncondCodeSeq);
   }
 
+  // 返回插入的 cmovs 指令列表
   return CMovs;
 }
 
-/// Compute the register class for the unfolded load.
-///
-/// FIXME: This should probably live in X86InstrInfo, potentially by adding
-/// a way to unfold into a newly created vreg rather than requiring a register
-/// input.
+/**
+ *  如果一个操作码为 Opcode 的指令是可以被展开的，那么内存操作数在展开后指令中的寄存器类型。
+ * 
+ *  @param MF: 待分析函数
+ *  @param TII: X86 指令集信息
+ *  @param Opcode: 待展开指令
+ *  @return load 内存操作数在展开后指令中的寄存器类型 
+ */
 static const TargetRegisterClass *
 getRegClassForUnfoldedLoad(MachineFunction &MF, const X86InstrInfo &TII,
                            unsigned Opcode) {
   unsigned Index;
+  // 通过给定的操作码（Opcode）来查找展开后的指令操作码
+  // 第一个参数是待展开指令的操作码
+  // 第二个参数指示是否需要展开 load 操作
+  // 第三个参数指示是否需要展开 store 操作
+  // 第四个参数存放展开后内存操作数在新指令中的位置索引
+  // 函数返回值为展开后的 load 指令的操作码
   unsigned UnfoldedOpc = TII.getOpcodeAfterMemoryUnfold(
       Opcode, /*UnfoldLoad*/ true, /*UnfoldStore*/ false, &Index);
+  // 查询展开后的 Opcode 在指令信息列表中的位置 
   const MCInstrDesc &MCID = TII.get(UnfoldedOpc);
+  // 从指令信息列表中获取展开后 load 指令的操作码
   return TII.getRegClass(MCID, Index, &TII.getRegisterInfo(), MF);
 }
 
+/**
+ *  展开所有带有 load 操作的分支指令。
+ *  需要注意的是，这里的展开是 MC 层面的展开，不是最终汇编代码的展开。
+ *  例如，xxx，但最终生成的汇编代码仍为 xxx
+ *  这有助于后续对这类带有 load 的分支进行 load 加固。
+ * 
+ * @param MF: 待分析函数
+ */
 void X86SpeculativeLoadHardeningPass::unfoldCallAndJumpLoads(
     MachineFunction &MF) {
+
+  // 遍历基本块
   for (MachineBasicBlock &MBB : MF)
+    // 遍历 MBB 中的所有指令，使用 for 循环是因为遍历过程中可能会插入和删除指令
     for (auto MII = MBB.instr_begin(), MIE = MBB.instr_end(); MII != MIE;) {
-      // Grab a reference and increment the iterator so we can remove this
-      // instruction if needed without disturbing the iteration.
+      // 在这里从迭代器获取指令，然后更新迭代器
+      // 避免了插入和删除指令对迭代器的影响
       MachineInstr &MI = *MII++;
 
-      // Must either be a call or a branch.
+      // 只展开带有 load 操作的分支指令，其他指令直接跳过
       if (!MI.isCall() && !MI.isBranch())
         continue;
-      // We only care about loading variants of these instructions.
+
+      LLVM_DEBUG({
+          dbgs() << "Unfold: Find MI with branch\n";
+            MI.dump();
+            dbgs() << "\n";
+        });
+
+
       if (!MI.mayLoad())
         continue;
+      
+      LLVM_DEBUG({
+          dbgs() << "Unfold: Find MI with branch and load\n";
+            MI.dump();
+            dbgs() << "\n";
+        });
 
+      // 根据 MI 指令的操作码，筛选出想要展开的指令
+      // 具体而言，长跳转不展开，因为这类跳转设计段寄存器修改，很难被攻击者利用
+      // 其他类型的带有 load 的分支指令需要展开
       switch (MI.getOpcode()) {
       default: {
         LLVM_DEBUG(
@@ -877,8 +1261,7 @@ void X86SpeculativeLoadHardeningPass::unfoldCallAndJumpLoads(
       case X86::FARJMP16m:
       case X86::FARJMP32m:
       case X86::FARJMP64m:
-        // We cannot mitigate far jumps or calls, but we also don't expect them
-        // to be vulnerable to Spectre v1.2 style attacks.
+        // 长跳转分支不进行展开，也不考虑防御
         continue;
 
       case X86::CALL16m:
@@ -898,9 +1281,7 @@ void X86SpeculativeLoadHardeningPass::unfoldCallAndJumpLoads(
       case X86::TAILJMPm:
       case X86::TCRETURNmi64:
       case X86::TCRETURNmi: {
-        // Use the generic unfold logic now that we know we're dealing with
-        // expected instructions.
-        // FIXME: We don't have test coverage for all of these!
+        // 对于带有 load 的分支，先获取展开后的内存操作数所在的寄存器类型 UnfoldedRC
         auto *UnfoldedRC = getRegClassForUnfoldedLoad(MF, *TII, MI.getOpcode());
         if (!UnfoldedRC) {
           LLVM_DEBUG(dbgs()
@@ -908,25 +1289,32 @@ void X86SpeculativeLoadHardeningPass::unfoldCallAndJumpLoads(
                      MI.dump(); dbgs() << "\n");
           report_fatal_error("Unable to unfold load!");
         }
+        // 接下来，建立一个 UnfoldedRC 类型的虚拟寄存器
         Register Reg = MRI->createVirtualRegister(UnfoldedRC);
+        // NewMIs 存放展开后的新指令流
         SmallVector<MachineInstr *, 2> NewMIs;
-        // If we were able to compute an unfolded reg class, any failure here
-        // is just a programming error so just assert.
+        // unfoldMemoryOperand 函数进行指令展开，并将展开后的指令存放在最后一个参数中
+        // 函数的返回值表示是否成功展开
         bool Unfolded =
             TII->unfoldMemoryOperand(MF, MI, Reg, /*UnfoldLoad*/ true,
                                      /*UnfoldStore*/ false, NewMIs);
         (void)Unfolded;
         assert(Unfolded &&
                "Computed unfolded register class but failed to unfold");
-        // Now stitch the new instructions into place and erase the old one.
+
+        // 展开后，将原本的带 load 的分支指令，转换成展开后指令，一般是两条 MC 指令
+        // 第一条是 load，第二条是不带 load 的分支
+        // 例如，从 JMP64m 转化为 MOV64mr 和 JMP_1
         for (auto *NewMI : NewMIs)
           MBB.insert(MI.getIterator(), NewMI);
 
-        // Update the call site info.
+        // 删除分支指令前，需要删除 call side 信息
         if (MI.isCandidateForCallSiteEntry())
           MF.eraseCallSiteInfo(&MI);
 
+        // 删除分支指令
         MI.eraseFromParent();
+        // 打印被替换的指令
         LLVM_DEBUG({
           dbgs() << "Unfolded load successfully into:\n";
           for (auto *NewMI : NewMIs) {
@@ -941,67 +1329,72 @@ void X86SpeculativeLoadHardeningPass::unfoldCallAndJumpLoads(
     }
 }
 
-/// Trace the predicate state through indirect branches, instrumenting them to
-/// poison the state if a target is reached that does not match the expected
-/// target.
-///
-/// This is designed to mitigate Spectre variant 1 attacks where an indirect
-/// branch is trained to predict a particular target and then mispredicts that
-/// target in a way that can leak data. Despite using an indirect branch, this
-/// is really a variant 1 style attack: it does not steer execution to an
-/// arbitrary or attacker controlled address, and it does not require any
-/// special code executing next to the victim. This attack can also be mitigated
-/// through retpolines, but those require either replacing indirect branches
-/// with conditional direct branches or lowering them through a device that
-/// blocks speculation. This mitigation can replace these retpoline-style
-/// mitigations for jump tables and other indirect branches within a function
-/// when variant 2 isn't a risk while allowing limited speculation. Indirect
-/// calls, however, cannot be mitigated through this technique without changing
-/// the ABI in a fundamental way.
+/**
+ *  防御一类用间接分支（不包括 call）实现的，类似 Spectre v1 的间接分支攻击，
+ *  这类攻击中，间接分支始终跳到一个固定且可以预测的目标，
+ *  在攻击中，间接分支被错误地预测为跳到该错误预测该目标，从而可能导致数据泄漏。
+ *  尽管使用了间接分支，但这实际上是 Spectre v1 攻击：它不会将控制流引导至任意或攻击者控制的地址，
+ *  这种攻击也可以通过 retpolines 进行缓解，但这需要用条件直接分支替换间接分支，
+ *  当不考虑防御 Spectre v2 时，SLH 可以取代 retpolines，因为 SLH 允许有限的推测。
+ *  然而，call 指令无法通过这种技术缓解，因为编译时无法准确知道调用地址。
+ * 
+ *  目前只支持一种情况，即一个基本块以间接分支结尾，且不包含其他分支时，对间接分支进行防御。
+ *  防御方案如下：
+ *  1. 在满足上述要求的基本块中，提取间接分支的跳转地址，放入一个寄存器中
+ *  2. 在间接分支目标的基本块插入 cmov，比较目标基本块地址和上述位寄存器（位于前驱基本块）
+ *  3. 如果地址不同，那么将掩码值赋给 predicate state
+ *  
+ *  @param MF: 待分析函数
+ *  @return 一个列表，存放新加入的 cmov 指令
+ * 
+ */
 SmallVector<MachineInstr *, 16>
 X86SpeculativeLoadHardeningPass::tracePredStateThroughIndirectBranches(
     MachineFunction &MF) {
-  // We use the SSAUpdater to insert PHI nodes for the target addresses of
-  // indirect branches. We don't actually need the full power of the SSA updater
-  // in this particular case as we always have immediately available values, but
-  // this avoids us having to re-implement the PHI construction logic.
+  // 使用 SSA 管理工具 SSAUpdater，在间接分支的跳转目标基本块插入 PHI 指令
+  // 每个 SSAUpdater 管理一组（寄存器）变量，负责维护这组变量在 CFG 的传递
+  // 例如，如果基本块 A 存在两个前驱 B 和 C，我们想在 A 使用 B 和 C 的同一个变量
+  // 我们可以分别在 B 和 C 将这变量加入 SSAUpdater，然后在 A 通过 SSAUpdater 使用共同变量
+  // 这时，SSAUpdater 会计算 A 和 B 和 C 的关系，然后自动生成 PHI 节点
+  // 如果 A 只有前驱 B 并且想用 B 的某个变量，SSAUpdater 则不建立 PHI 指令
+  // 但负责在 A 中获取 B 的变量作为操作数，以供 A 的指令使用
   MachineSSAUpdater TargetAddrSSA(MF);
   TargetAddrSSA.Initialize(MRI->createVirtualRegister(&X86::GR64RegClass));
 
-  // Track which blocks were terminated with an indirect branch.
+  // 这个集合用于存放以间接分支结尾，且不包含其他分支的基本块
+  // 后续只对这种基本块中的间接分支进行防御
   SmallPtrSet<MachineBasicBlock *, 4> IndirectTerminatedMBBs;
 
-  // We need to know what blocks end up reached via indirect branches. We
-  // expect this to be a subset of those whose address is taken and so track it
-  // directly via the CFG.
+  // 这个集合用于存放间接分支跳转目标的基本块
   SmallPtrSet<MachineBasicBlock *, 4> IndirectTargetMBBs;
 
-  // Walk all the blocks which end in an indirect branch and make the
-  // target address available.
+  // 首先，遍历所有基本块，筛选以间接分支结尾且不包含其他分支的基本块
   for (MachineBasicBlock &MBB : MF) {
-    // Find the last terminator.
+    // 倒序搜索 MBB 的指令，找到 MBB 最后一个终止符
     auto MII = MBB.instr_rbegin();
     while (MII != MBB.instr_rend() && MII->isDebugInstr())
       ++MII;
     if (MII == MBB.instr_rend())
       continue;
     MachineInstr &TI = *MII;
+
+    // 如果终止符不是分支指令，跳过当前基本块
     if (!TI.isTerminator() || !TI.isBranch())
-      // No terminator or non-branch terminator.
       continue;
 
     unsigned TargetReg;
 
+    // 只对 JMP 指令做防御，其他类型分支，如条件分支和 call，不做防御
     switch (TI.getOpcode()) {
     default:
-      // Direct branch or conditional branch (leading to fallthrough).
+      // 无法防御条件分支和 call
       continue;
 
     case X86::FARJMP16m:
     case X86::FARJMP32m:
     case X86::FARJMP64m:
-      // We cannot mitigate far jumps or calls, but we also don't expect them
-      // to be vulnerable to Spectre v1.2 or v2 (self trained) style attacks.
+      // 无法防御长跳转和 call，但是攻击者通常也无法使用类似 Spectre v1 的攻击针对这类分支
+      // 类似 Spectre v1 的攻击包括 Spectre v1.2 和 Spectre v2 (self trained) 来攻击
       continue;
 
     case X86::JMP16m:
@@ -1010,22 +1403,24 @@ X86SpeculativeLoadHardeningPass::tracePredStateThroughIndirectBranches(
     case X86::JMP32m_NT:
     case X86::JMP64m:
     case X86::JMP64m_NT:
-      // Mostly as documentation.
+      // 包含 load 的直接分支应该已经被展开，不能出现在这里
       report_fatal_error("Memory operand jumps should have been unfolded!");
 
     case X86::JMP16r:
+      // 64 位架构不应该出现 16 位跳转
       report_fatal_error(
           "Support for 16-bit indirect branches is not implemented.");
     case X86::JMP32r:
+      // 64 位架构不应该出现 32 位跳转
       report_fatal_error(
           "Support for 32-bit indirect branches is not implemented.");
 
     case X86::JMP64r:
+      // 对于 JMP 指令，我们读取存放跳转目标的寄存器 TargetReg
       TargetReg = TI.getOperand(0).getReg();
     }
 
-    // We have definitely found an indirect  branch. Verify that there are no
-    // preceding conditional branches as we don't yet support that.
+    // 再次确保基本块满足条件，即以间接分支结尾，且不包含其他分支 
     if (llvm::any_of(MBB.terminators(), [&](MachineInstr &OtherTI) {
           return !OtherTI.isDebugInstr() && &OtherTI != &TI;
         })) {
@@ -1040,57 +1435,65 @@ X86SpeculativeLoadHardeningPass::tracePredStateThroughIndirectBranches(
       report_fatal_error("Unimplemented terminator sequence!");
     }
 
-    // Make the target register an available value for this block.
+    // 将目标寄存器 TargetReg 的值添加到与基本块 MBB 相关联的 SSAUpdater 中
+    // 这样，这个基本块就会显式地分配 TargetReg 寄存器
+    // 然后把分支目标地址存入 TargetReg 寄存器
+    // 后继基本块也能使用 TargetReg 寄存器
     TargetAddrSSA.AddAvailableValue(&MBB, TargetReg);
+
+    // 因为 MBB 符合条件，因此加入 IndirectTerminatedMBBs 列表
     IndirectTerminatedMBBs.insert(&MBB);
 
-    // Add all the successors to our target candidates.
+    // 因为 MBB 符合条件，所以其后继必然是间接分支的跳转目标
+    // 因此，我们直接用 CFG 信息，将分支目标基本块加入 IndirectTargetMBBs 列表
     for (MachineBasicBlock *Succ : MBB.successors())
       IndirectTargetMBBs.insert(Succ);
   }
 
-  // Keep track of the cmov instructions we insert so we can return them.
+  // 这个列表用于存放之后在间接分支目标基本块新插入的 cmov 指令
   SmallVector<MachineInstr *, 16> CMovs;
 
-  // If we didn't find any indirect branches with targets, nothing to do here.
+  // 如果函数 MF 中没有满足条件的间接分支，那么 IndirectTargetMBBs 为空，直接退出
   if (IndirectTargetMBBs.empty())
     return CMovs;
 
-  // We found indirect branches and targets that need to be instrumented to
-  // harden loads within them. Walk the blocks of the function (to get a stable
-  // ordering) and instrument each target of an indirect branch.
+  // 对于满足要求的间接分支，我们遍历它们的目标基本块
+  // 对于每个目标基本块，我们插入 cmov 以生成 predicate state
+  // 使用内置的遍历顺序，能够确保访问顺序稳定
   for (MachineBasicBlock &MBB : MF) {
-    // Skip the blocks that aren't candidate targets.
+    // 如果 MBB 不在 IndirectTargetMBBs 中
+    // 说明 MBB 不满足加固要求，那么这里无需任何处理
     if (!IndirectTargetMBBs.count(&MBB))
       continue;
 
-    // We don't expect EH pads to ever be reached via an indirect branch. If
-    // this is desired for some reason, we could simply skip them here rather
-    // than asserting.
+    // MBB 是由间接分支跳转得到的，而 EHPad 基本块一般不会由间接分支跳转到
+    // 因此，这里加了一个检查，确保 MBB 不是简介分支
+    // 如果出现意外情况，可以注释掉这个 assert，直接跳过这个 MBB 即可
     assert(!MBB.isEHPad() &&
            "Unexpected EH pad as target of an indirect branch!");
 
-    // We should never end up threading EFLAGS into a block to harden
-    // conditional jumps as there would be an additional successor via the
-    // indirect branch. As a consequence, all such edges would be split before
-    // reaching here, and the inserted block will handle the EFLAGS-based
-    // hardening.
+    // 如果 MBB 内需要用到前驱的 EFLAGS，那么插入 cmp 和 cmov 会导致 EFLAGS 被破坏
+    // 遇到这种情况，这里直接用 assert 报错处理了
+    // 这里敢使用断言，说明编译器会避免 jmp 指令目标基本块使用 EFLAGS 这种情况的发生？
     assert(!MBB.isLiveIn(X86::EFLAGS) &&
            "Cannot check within a block that already has live-in EFLAGS!");
 
-    // We can't handle having non-indirect edges into this block unless this is
-    // the only successor and we can synthesize the necessary target address.
+    // 接下来，我们考虑 MBB 的前驱 Pred，我们需要在 Pred 中显式地用寄存器存放 MBB 地址
+    // 然后把寄存器加入 SSAUpdater，以供 MBB 使用这一寄存器，与自己的实际地址比较
+    // 然后才能将比较结果作为 cmov 条件
     for (MachineBasicBlock *Pred : MBB.predecessors()) {
-      // If we've already handled this by extracting the target directly,
-      // nothing to do.
+      // 如果 Pred 在 IndirectTerminatedMBBs 中、
+      // 说明 Pred 的分支跳转目标寄存器已经生成，并且加入了 SSAUpdater
+      // 那么这里无需任何处理我们已经通过 SSAUpdater 得到目标地址寄存器
       if (IndirectTerminatedMBBs.count(Pred))
         continue;
 
-      // Otherwise, we have to be the only successor. We generally expect this
-      // to be true as conditional branches should have had a critical edge
-      // split already. We don't however need to worry about EH pad successors
-      // as they'll happily ignore the target and their hardening strategy is
-      // resilient to all ways in which they could be reached speculatively.
+      // Pred 有一个关键性质，这个性质使得 SSAUpdater 可以一直复用，无需重置
+      // 性质为：不考虑 EHPad 时，MBB 的任何一个的前驱 Pred，必然有且只有 MBB 这一个后继
+      // 可以用反证法证明：假设 Pred 有多个后继，MBB 只是其中一个
+      // 那么，Pred 必然通过条件分支跳到 MBB，经过之前的 split 处理
+      // Pred 和 MBB 中间应该已经插入一个新基本块，因此 Pred 不可能是 MBB 前驱 
+      // 下面进行性质检查，如果 Pred 不满足这个性质，说明 split 没做对，报错
       if (!llvm::all_of(Pred->successors(), [&](MachineBasicBlock *Succ) {
             return Succ->isEHPad() || Succ == &MBB;
           })) {
@@ -1104,22 +1507,31 @@ X86SpeculativeLoadHardeningPass::tracePredStateThroughIndirectBranches(
                            "an indirect branch!");
       }
 
-      // Now we need to compute the address of this block and install it as a
-      // synthetic target in the predecessor. We do this at the bottom of the
-      // predecessor.
+      // 下面，我们要获取 Pred 中间接分支的跳转目标地址
+      // 将目标地址存放在一个寄存器中，并将寄存器加入 SSAUpdater
+      // 我们在 Pred 的间接分支之前加入用于获取地址的指令
       auto InsertPt = Pred->getFirstTerminator();
+      // 创建一个虚拟寄存器
       Register TargetReg = MRI->createVirtualRegister(&X86::GR64RegClass);
+      // 如果代码模型为 small 且代码不是位置无关 (PIC) 的，那么绝对地址在编译时已知
+      // 这时可以直接将地址 mov 到虚拟寄存器中
       if (MF.getTarget().getCodeModel() == CodeModel::Small &&
           !Subtarget->isPositionIndependent()) {
-        // Directly materialize it into an immediate.
+        // 插入一个 mov 指令，将 MBB 地址移入 TargetReg
         auto AddrI = BuildMI(*Pred, InsertPt, DebugLoc(),
                              TII->get(X86::MOV64ri32), TargetReg)
                          .addMBB(&MBB);
+        // 更新调试信息
         ++NumInstsInserted;
         (void)AddrI;
         LLVM_DEBUG(dbgs() << "  Inserting mov: "; AddrI->dump();
                    dbgs() << "\n");
       } else {
+      // 如果 MBB 绝对地址在编译时不可知，那么使用相对地址来计算
+        // 插入一个 lea 指令，计算 MBB 相对地址
+        // 第一和第三个参数分别为 lea 的第一和第二个寄存器，第二个参数为寄存器放大倍数
+        // 第四个参数为一个地址，编译器会自动计算出 lea 的 offset
+        // 生成指令：lea offset(RIP,,1)
         auto AddrI = BuildMI(*Pred, InsertPt, DebugLoc(), TII->get(X86::LEA64r),
                              TargetReg)
                          .addReg(/*Base*/ X86::RIP)
@@ -1127,30 +1539,33 @@ X86SpeculativeLoadHardeningPass::tracePredStateThroughIndirectBranches(
                          .addReg(/*Index*/ 0)
                          .addMBB(&MBB)
                          .addReg(/*Segment*/ 0);
+        // 更新调试信息
         ++NumInstsInserted;
         (void)AddrI;
         LLVM_DEBUG(dbgs() << "  Inserting lea: "; AddrI->dump();
                    dbgs() << "\n");
       }
-      // And make this available.
+      // 将生成的地址寄存器添加到 SSAUpdater 中，以便后继基本块使用
       TargetAddrSSA.AddAvailableValue(Pred, TargetReg);
     }
 
-    // Materialize the needed SSA value of the target. Note that we need the
-    // middle of the block as this block might at the bottom have an indirect
-    // branch back to itself. We can do this here because at this point, every
-    // predecessor of this block has an available value. This is basically just
-    // automating the construction of a PHI node for this target.
+    // 在 MBB 中使用前驱在 SSAUpdater 中的数据
+    // SSAUpdater 会在 MBB 基本块的中间加入 PHI 指令，获取来自各个前驱基本块的地址寄存器
     unsigned TargetReg = TargetAddrSSA.GetValueInMiddleOfBlock(&MBB);
 
-    // Insert a comparison of the incoming target register with this block's
-    // address. This also requires us to mark the block as having its address
-    // taken explicitly.
+    // 插入 cmp 指令，比较 TargetReg 和 MBB 实际地址是否相同
+    // setHasAddressTaken 函数用于标记 MBB 可能是一个间接分支的跳转目标
     MBB.setHasAddressTaken();
+    // cmp 指令的插入位置为 MBB 头部的 PHI 指令之后
     auto InsertPt = MBB.SkipPHIsLabelsAndDebug(MBB.begin());
+    // 如果代码模型为 small 且代码不是位置无关 (PIC) 的，那么 MBB 绝对地址在编译时已知
+    // 这时可以直接将 MBB 地址用于比较
     if (MF.getTarget().getCodeModel() == CodeModel::Small &&
         !Subtarget->isPositionIndependent()) {
-      // Check directly against a relocated immediate when we can.
+      // 插入 cmp 指令，比较对象为 TargetReg 和 MBB
+      // 比较指令 cmp64ri32，比较一个寄存器和一个立即数
+      // 寄存器 TargetReg 在比较后不需要再使用，因此标记为 RegState::Kill
+      // 后续可以重用寄存器
       auto CheckI = BuildMI(MBB, InsertPt, DebugLoc(), TII->get(X86::CMP64ri32))
                         .addReg(TargetReg, RegState::Kill)
                         .addMBB(&MBB);
@@ -1158,7 +1573,11 @@ X86SpeculativeLoadHardeningPass::tracePredStateThroughIndirectBranches(
       (void)CheckI;
       LLVM_DEBUG(dbgs() << "  Inserting cmp: "; CheckI->dump(); dbgs() << "\n");
     } else {
-      // Otherwise compute the address into a register first.
+      // 如果 MBB 绝对地址在编译时不可知，那么先使用 MBB 的相对地址
+        // 插入一个 lea 指令，计算 MBB 的地址
+        // 第一和第三个参数分别为 lea 的第一和第二个寄存器，第二个参数为寄存器放大倍数
+        // 第四个参数为一个地址，编译器会自动计算出 lea 的 offset
+        // 生成指令：lea offset(RIP,,1)，将地址存放在目标寄存器 AddrReg 中
       Register AddrReg = MRI->createVirtualRegister(&X86::GR64RegClass);
       auto AddrI =
           BuildMI(MBB, InsertPt, DebugLoc(), TII->get(X86::LEA64r), AddrReg)
@@ -1167,180 +1586,240 @@ X86SpeculativeLoadHardeningPass::tracePredStateThroughIndirectBranches(
               .addReg(/*Index*/ 0)
               .addMBB(&MBB)
               .addReg(/*Segment*/ 0);
+      // 更新调试信息
       ++NumInstsInserted;
       (void)AddrI;
       LLVM_DEBUG(dbgs() << "  Inserting lea: "; AddrI->dump(); dbgs() << "\n");
+      // 然后插入比较指令，CMP64rr 比较两个寄存器
+      // AddrReg 和 TargetReg 在比较完后不再使用，因此标记为 RegState::Kill
       auto CheckI = BuildMI(MBB, InsertPt, DebugLoc(), TII->get(X86::CMP64rr))
                         .addReg(TargetReg, RegState::Kill)
                         .addReg(AddrReg, RegState::Kill);
+      // 更新调试信息
       ++NumInstsInserted;
       (void)CheckI;
       LLVM_DEBUG(dbgs() << "  Inserting cmp: "; CheckI->dump(); dbgs() << "\n");
     }
 
-    // Now cmov over the predicate if the comparison wasn't equal.
+    // 紧接着 cmp 后，我们用 cmp 指令更新 predicate state
+    // cmov 有不同位宽的版本，这里我们选用与 predicate_state 等长的版本
+    // PS->RC 存放了 predicate_state 的寄存器类型，包含了位宽信息
+    // 最终得到我们想要的那个 cmov 指令版本的操作码 CMovOp
     int PredStateSizeInBytes = TRI->getRegSizeInBits(*PS->RC) / 8;
     auto CMovOp = X86::getCMovOpcode(PredStateSizeInBytes);
+    // 用虚拟寄存器 UpdatedStateReg 存放 cmov 的结果
     Register UpdatedStateReg = MRI->createVirtualRegister(PS->RC);
+    // 创建 cmov 指令，条件设为 not equal
+    // PS->InitialReg 是存放 predicate state 初始值的虚拟寄存器
+    // PS->PoisonReg 是存放 secure mask 掩码的虚拟寄存器
+    // 更新后的 predicate state 放入 UpdatedStateReg 虚拟寄存器
     auto CMovI =
         BuildMI(MBB, InsertPt, DebugLoc(), TII->get(CMovOp), UpdatedStateReg)
             .addReg(PS->InitialReg)
             .addReg(PS->PoisonReg)
             .addImm(X86::COND_NE);
+    // cmp 是额外插入的，原本程序不应该使用 EFLAGS
+    // 实际上前面也过滤了有 EFLAGS live-in 的情况
+    // 那么我们可以标记 EFLAGS 为 kill 状态，这个基本块内不会再用到 EFLAGS 的结果
     CMovI->findRegisterUseOperand(X86::EFLAGS)->setIsKill(true);
+    // 更新调试状态
     ++NumInstsInserted;
     LLVM_DEBUG(dbgs() << "  Inserting cmov: "; CMovI->dump(); dbgs() << "\n");
+    // 将新插入的 cmov 指令插入 CMovs 列表
     CMovs.push_back(&*CMovI);
 
-    // And put the new value into the available values for SSA form of our
-    // predicate state.
+    // 最后，我们将 UpdatedStateReg 加入 PS->SSA，这是一个 SSAUpdater
+    // SSAUpdater 会将 cmov 的结果寄存器放入 UpdatedStateReg，供后续 load 加固使用
     PS->SSA.AddAvailableValue(&MBB, UpdatedStateReg);
   }
 
-  // Return all the newly inserted cmov instructions of the predicate state.
+  // 返回 CMovs 列表，其中存放了新插入的所有 cmov 指令
   return CMovs;
 }
 
-// Returns true if the MI has EFLAGS as a register def operand and it's live,
-// otherwise it returns false
+/**
+ *  如果一个指令影响了 EFLAGS 寄存器（def)，并且 ELFAGS 在后续被用到了 (live)，
+ *  那么返回 true，否则返回 false。
+ *  
+ *  @param MI: 待测试的指令
+ *  @return 一个布尔值，表示指令是否更新 EFLAGS 并且本次更新被后续指令用到了
+ */
 static bool isEFLAGSDefLive(const MachineInstr &MI) {
+  // 使用 findRegisterDefOperand 判断 X86::EFLAGS 是否被 MI 影响
+  // 如果是，那么 DefOp 非空，否则 DefOp 为 nullptr
   if (const MachineOperand *DefOp = MI.findRegisterDefOperand(X86::EFLAGS)) {
+    // isDead() 表示寄存器在后续指令中不会被使用
     return !DefOp->isDead();
   }
   return false;
 }
 
+/**
+ *  判断一个基本块从一个特定位置 I 往后，EFLAGS 是否是 live 的
+ *  live 指的是 EFLAGS 在这个区域内被使用到了。
+ *  
+ *  @param MBB: 待测试的基本块
+ *  @param I: 基本块内的某条指令所在位置
+ *  @param TRI: X86 架构的寄存器信息，由 td 文件定义
+ *  @return 一个布尔值，表示 EFLAGS 是否在待测范围内是 live 的
+ */
 static bool isEFLAGSLive(MachineBasicBlock &MBB, MachineBasicBlock::iterator I,
                          const TargetRegisterInfo &TRI) {
   // Check if EFLAGS are alive by seeing if there is a def of them or they
   // live-in, and then seeing if that def is in turn used.
+  // 从 MBB 内的位置 I 处，倒序遍历每条指令 MI
   for (MachineInstr &MI : llvm::reverse(llvm::make_range(MBB.begin(), I))) {
+    // 首先，判断 MI 是否更新了 EFLAGS
     if (MachineOperand *DefOp = MI.findRegisterDefOperand(X86::EFLAGS)) {
-      // If the def is dead, then EFLAGS is not live.
+      // 如果更新了 EFLAGS，但是后续 EFLAGS 状态为 dead 
+      // 说明后续不会再用到 EFLAGS，返回 false
       if (DefOp->isDead())
         return false;
 
-      // Otherwise we've def'ed it, and it is live.
+      // 否则，如果 EFLAGS 后续是 live 的，返回 true
       return true;
     }
-    // While at this instruction, also check if we use and kill EFLAGS
-    // which means it isn't live.
+    // 如果 MI 将 EFLAGS 标记为 Kill，说明 MI 阻止了后续指令使用 EFLAGS
+    // 并且到达这里，说明从 MI 到 I 并未更新 (def) EFLAGS
+    // 那么 I 之后 EFLAGS 是 dead 的，因此返回 false
     if (MI.killsRegister(X86::EFLAGS, &TRI))
       return false;
   }
 
-  // If we didn't find anything conclusive (neither definitely alive or
-  // definitely dead) return whether it lives into the block.
+  // 如果从 MBB 入口到 I，都没有更新或 kill EFLAGS
+  // 那么我们读取 MBB 输入的 live-in 寄存器，看是否有 EFLAGS
+  // 如果在，那么 EFLAGS 后续仍然可用，返回 true，否则返回 false
   return MBB.isLiveIn(X86::EFLAGS);
 }
 
-/// Trace the predicate state through each of the blocks in the function,
-/// hardening everything necessary along the way.
-///
-/// We call this routine once the initial predicate state has been established
-/// for each basic block in the function in the SSA updater. This routine traces
-/// it through the instructions within each basic block, and for non-returning
-/// blocks informs the SSA updater about the final state that lives out of the
-/// block. Along the way, it hardens any vulnerable instruction using the
-/// currently valid predicate state. We have to do these two things together
-/// because the SSA updater only works across blocks. Within a block, we track
-/// the current predicate state directly and update it as it changes.
-///
-/// This operates in two passes over each block. First, we analyze the loads in
-/// the block to determine which strategy will be used to harden them: hardening
-/// the address or hardening the loaded value when loaded into a register
-/// amenable to hardening. We have to process these first because the two
-/// strategies may interact -- later hardening may change what strategy we wish
-/// to use. We also will analyze data dependencies between loads and avoid
-/// hardening those loads that are data dependent on a load with a hardened
-/// address. We also skip hardening loads already behind an LFENCE as that is
-/// sufficient to harden them against misspeculation.
-///
-/// Second, we actively trace the predicate state through the block, applying
-/// the hardening steps we determined necessary in the first pass as we go.
-///
-/// These two passes are applied to each basic block. We operate one block at a
-/// time to simplify reasoning about reachability and sequencing.
+/**
+ *  在函数的每个基本块中追踪 predicate state，并用它来加固基本块内的 load 等内容，
+ *  加固内容和加固方式由命令行参数配置，包括：
+ *  EnablePostLoadHardening: 是否加固 load 数据
+ *  HardenInterprocedurally: 是否跨函数加固
+ *  HardenLoads: 是否加固 load
+ *  HardenIndirectCallsAndJumps: 是否加固由间接分支到达的基本块
+ * 
+ *  SLH 在 predicate state 建立好后，调用此函数。
+ *  这遍历指令时，它会使用当前有效的 predicate state 对任何需要加固的指令进行加固。
+ *  在一个基本块内，我们直接追踪当前的 predicate state，并在状态变化时进行更新。
+ *  函数还结合 SSAUpdater，以便其他基本块能获取更新后的 predicate state。
+ *  
+ *  具体而言，这个函数对每个基本块进行两次遍历。
+ *  这两个遍历过程应用于每个基本块，一次处理一个块，以简化对可达性和程序执行顺序的分析。
+ * 
+ *  第一次遍历中，我们分析块中的 load 操作，以确定使用哪种策略对它们进行加固：加固地址还是数据。
+ *  策略需要预先分析，因为两种策略可能会相互影响，后续的加固可能会改变我们希望使用的策略。
+ *  优先使用数据加固策略，对于不能加固数据的 load，再考虑地址加固。
+ *  对于数据加固，采用 sink 分析来优化，具体参见函数 sinkPostLoadHardenedInst。
+ *  对于地址加固，采用数据相关性分析来优化：
+ *    如果一个 load 的结果是另一个 load 的地址，
+ *    并且前一个 load 已经被加固地址，那么就不需要加固后一个 load。
+ *  特别的，如果遇到已经由 lfence 保护的 load，就无需加固这个 load。
+ * 
+ *  第二次遍历中，我们使用 predicate state 和之前分析的策略，对 load 进行加固。
+ *  
+ *  @param MF: 待加固函数
+ */
 void X86SpeculativeLoadHardeningPass::tracePredStateThroughBlocksAndHarden(
     MachineFunction &MF) {
+
+  // 一个列表，存放一个基本块内需要被加固数据的 load 指令
   SmallPtrSet<MachineInstr *, 16> HardenPostLoad;
+  // 一个列表，存放一个基本块内需要被加固地址的 load 指令
   SmallPtrSet<MachineInstr *, 16> HardenLoadAddr;
 
+  // 一个列表，存放一个基本块内目前已被加固的寄存器
+  // 如果对一个指令做数据加固，那么它的目的寄存器会加入这个列表
+  // 如果对一个 load 指令做地址加固，那么它的所有存放地址信息的寄存器会加入这个列表
   SmallSet<unsigned, 16> HardenedAddrRegs;
 
+  // 一个映射，提供了寄存器加固前后和加固后的对应关系
+  // key 为加固前的虚拟寄存器的编号，value 为加固后的虚拟寄存器的编号
   SmallDenseMap<unsigned, unsigned, 32> AddrRegToHardenedReg;
 
-  // Track the set of load-dependent registers through the basic block. Because
-  // the values of these registers have an existing data dependency on a loaded
-  // value which we would have checked, we can omit any checks on them.
+  // 一个 bit 列表，用于支持指令地址加固中的数据相关优化
+  // 如果一个指令被地址加固，那么它的目的寄存器加入这个列表
+  // 如果发现一个 load 使用列表中的寄存器作为源寄存器，
+  // 那么认为这个 load 与已地址加固的 load 数据相关，可以跳过加固
   SparseBitVector<> LoadDepRegs;
 
+  // 遍历 MF 的每个基本块
+  // 对每个基本块进行两轮 Pass
   for (MachineBasicBlock &MBB : MF) {
-    // The first pass over the block: collect all the loads which can have their
-    // loaded value hardened and all the loads that instead need their address
-    // hardened. During this walk we propagate load dependence for address
-    // hardened loads and also look for LFENCE to stop hardening wherever
-    // possible. When deciding whether or not to harden the loaded value or not,
-    // we check to see if any registers used in the address will have been
-    // hardened at this point and if so, harden any remaining address registers
-    // as that often successfully re-uses hardened addresses and minimizes
-    // instructions.
-    //
-    // FIXME: We should consider an aggressive mode where we continue to keep as
-    // many loads value hardened even when some address register hardening would
-    // be free (due to reuse).
-    //
-    // Note that we only need this pass if we are actually hardening loads.
+    // 第一轮 pass 用于判断各个 load 需要采取哪些加固策略
+    // 可行的加固策略包括对 load 得到的数据加固，或者对 load 地址加固
+    // 特别的，如果几个 load 之间存在依赖关系，那么只需加固第一个 load
+    // 如果一个 load 之前存在 lfence，那么无需加固这个 load
+    // 
+    // 在 pass 中，首先筛选出需要加固 load 数据的 load，以及无需加固的 load
+    // 对于剩下的 load，提取它们的地址并对地址进行加固
+
+    // 只有 HardenLoads 开关打开，才加固 load
     if (HardenLoads)
       for (MachineInstr &MI : MBB) {
-        // We naively assume that all def'ed registers of an instruction have
-        // a data dependency on all of their operands.
-        // FIXME: Do a more careful analysis of x86 to build a conservative
-        // model here.
+        // 这里简单地认为每个指令的 def 寄存器和操作数之间存在依赖关系
+        // def 寄存器包括目的寄存器和隐式修改的寄存器，如 EFLAGS
+        // 目前并没有考虑更加精确的数据相关性分析
+
+        // 如果指令 MI 的一个源寄存器在 LoadDepRegs 中
         if (llvm::any_of(MI.uses(), [&](MachineOperand &Op) {
               return Op.isReg() && LoadDepRegs.test(Op.getReg());
             }))
+          // 那么把 MI 的目的寄存器也放入 LoadDepRegs 中
           for (MachineOperand &Def : MI.defs())
             if (Def.isReg())
               LoadDepRegs.set(Def.getReg());
 
-        // Both Intel and AMD are guiding that they will change the semantics of
-        // LFENCE to be a speculation barrier, so if we see an LFENCE, there is
-        // no more need to guard things in this block.
+        // Intel 和 ARM 的 lfence 指令都支持阻止 load 指令的推测执行
+        // 因此，如果 MI 是 fence 指令，那么当前基本块的后续指令无需加固
         if (MI.getOpcode() == X86::LFENCE)
           break;
 
-        // If this instruction cannot load, nothing to do.
+        // 如果 MI 不是 load 指令，或者不执行 load 操作，跳过这条指令
         if (!MI.mayLoad())
           continue;
 
-        // Some instructions which "load" are trivially safe or unimportant.
+        // 如果 MI 是 mfence 指令，那么虽然 MI 被视为一个 load，但不考虑加固 MI
         if (MI.getOpcode() == X86::MFENCE)
           continue;
 
-        // Extract the memory operand information about this instruction.
-        // FIXME: This doesn't handle loading pseudo instructions which we often
-        // could handle with similarly generic logic. We probably need to add an
-        // MI-layer routine similar to the MC-layer one we use here which maps
-        // pseudos much like this maps real instructions.
+        // 以下代码获取 MI 指令的基址寄存器 (BaseMO) 和索引寄存器 (IndexMO)
+        // 例如，地址 (%rax,%rdx,1) 的基址寄存器为 %rax，索引寄存器为 %rdx
+        // 注意这个方式处理不了伪指令 (pseudo instructions)
+        // 可能可行的解决方案为将伪指令映射到一个实际 load 指令，这里并未实现
+
+        // 首先，获取目的寄存器描述符 Desc
         const MCInstrDesc &Desc = MI.getDesc();
+        // 根据描述符 Desc 获取目的操作数的 index
         int MemRefBeginIdx = X86II::getMemoryOperandNo(Desc.TSFlags);
+        // 如果没有目的操作数，不加固这个 load，因为 load 的结果不被用于后续攻击
         if (MemRefBeginIdx < 0) {
           LLVM_DEBUG(dbgs()
                          << "WARNING: unable to harden loading instruction: ";
                      MI.dump());
           continue;
         }
-
+        // 如果目的寄存器也是源寄存器之一，那么用 getOperandBias 跳过重复的寄存器
+        // 例如，一条指令将 %rax 的值加上 %rbx 再存入 %rax
+        // 这时 MemRefBeginIdx 一开始为 0 (X86II::getMemoryOperandNo)
+        // 加上 X86II::getOperandBias 后被更新为 1
+        // 这样才能正确访问其他操作数，比如 %rbx 是第 2 个操作数而非第 1 个
         MemRefBeginIdx += X86II::getOperandBias(Desc);
 
+        // 目的寄存器编号，加上 AddrBaseReg 得到 BaseMO 的 index
+        // 加上 AddrIndexReg 得到 IndexMO 的 index
+        // 然后使用 getOperand 从 index 得到操作数对象
         MachineOperand &BaseMO =
             MI.getOperand(MemRefBeginIdx + X86::AddrBaseReg);
         MachineOperand &IndexMO =
             MI.getOperand(MemRefBeginIdx + X86::AddrIndexReg);
 
-        // If we have at least one (non-frame-index, non-RIP) register operand,
-        // and neither operand is load-dependent, we need to check the load.
+        // 根据操作数对象，得到操作数的寄存器在 x86 架构寄存器组中的编号
+        // 如果都等于 0，后续不考虑加固 load
+        // 但只要有一个非 0，就需要加固 load，但不给等于 0 的那个寄存器加掩码
+        // 同时检查寄存器是否是 RBP 或者 RIP ，如果是，不考虑加固这个寄存器
+        // 因为根据 ABI，攻击者无法直接操控这两个寄存器
         unsigned BaseReg = 0, IndexReg = 0;
         if (!BaseMO.isFI() && BaseMO.getReg() != X86::RIP &&
             BaseMO.getReg() != X86::NoRegister)
@@ -1349,329 +1828,448 @@ void X86SpeculativeLoadHardeningPass::tracePredStateThroughBlocksAndHarden(
           IndexReg = IndexMO.getReg();
 
         if (!BaseReg && !IndexReg)
-          // No register operands!
+          // BaseReg 和 IndexReg 均为 0 时，不加固这个 load
+          // 那么无需加固，因为攻击者利用不了
           continue;
 
-        // If any register operand is dependent, this load is dependent and we
-        // needn't check it.
-        // FIXME: Is this true in the case where we are hardening loads after
-        // they complete? Unclear, need to investigate.
+        // 如果 load 的 BaseReg 或 IndexReg 与一个已被加固的 load 数据相关
+        // 就无需再加固这个 load 了
         if ((BaseReg && LoadDepRegs.test(BaseReg)) ||
             (IndexReg && LoadDepRegs.test(IndexReg)))
           continue;
 
-        // If post-load hardening is enabled, this load is compatible with
-        // post-load hardening, and we aren't already going to harden one of the
-        // address registers, queue it up to be hardened post-load. Notably,
-        // even once hardened this won't introduce a useful dependency that
-        // could prune out subsequent loads.
+        // 同时满足以下条件的 MI (load) 可以加固数据：
+        // 1. 命令行参数 EnablePostLoadHardening 被开启。
+        // 2. isDataInvariantLoad: MI 是数据不变 (data invariant) 的 load
+        //    所谓数据不变的 load，指的是指令行为不随着从内存加载的值的不同，
+        //    也不随着非地址操作数的值不同而不同。
+        //    例如，mov (,%rax,4),%ecx 是数据不变的，因为没有非地址操作数，
+        //    且内存加载的数据不影响指令的行为，指令始终将数据存入 %ecx，
+        //    但 jmp *%rax 不是数据不变的，因为指令跳转目标随加载而来的数据的不同而不同。
+        //    如果对非数据不变的 load 做数据加固，可能破坏后续指令的推测执行。
+        // 3. MI 没有修改 EFLAGS，或者修改的 EFLAGS 没有被后续指令使用。
+        //    如果不满足这个，加固时使用的 ori 等指令会破坏 EFLAGS 导致程序出错。
+        // 4. MI 存在唯一目的寄存器，如果不存在，那么就没有可以加固的 load 数据
+        // 5. MI 的目的寄存器是通用寄存器，不是向量寄存器，且支持 REX 前缀
+        //    关于 REX 前缀的简介参见 canHardenRegister 函数注释。
+        // 6. MI 的两个地址寄存器，BaseReg 和 IndexReg，尚未被加固。
         if (EnablePostLoadHardening && X86InstrInfo::isDataInvariantLoad(MI) &&
             !isEFLAGSDefLive(MI) && MI.getDesc().getNumDefs() == 1 &&
             MI.getOperand(0).isReg() &&
             canHardenRegister(MI.getOperand(0).getReg()) &&
             !HardenedAddrRegs.count(BaseReg) &&
             !HardenedAddrRegs.count(IndexReg)) {
+          LLVM_DEBUG(dbgs()
+                         << "Find load isDataInvariantLoad: ";
+                     MI.dump();
+                     dbgs()
+                         << "isDataInvariant(MI) = " << X86InstrInfo::isDataInvariant(MI);
+                     dbgs()
+                         << "isDataInvariantLoad(MI) = " << X86InstrInfo::isDataInvariantLoad(MI);
+                    );
+          // 将 MI 移入 HardenPostLoad 列表，这个列表存放了需要加固数据的 load 指令
           HardenPostLoad.insert(&MI);
+          // 将 MI 的目的寄存器，即存放 load 数据的寄存器，移入 HardenedAddrRegs 列表
+          // HardenedAddrRegs 列表存放了将被加固的寄存器
           HardenedAddrRegs.insert(MI.getOperand(0).getReg());
+          // 数据加固的 load 不计入数据相关的 load 优化
+          // 因此不将 MI 加入 LoadDepRegs
           continue;
         }
 
-        // Record this instruction for address hardening and record its register
-        // operands as being address-hardened.
+        LLVM_DEBUG(dbgs()
+                        << "Find load should be hardeded address: ";
+                    MI.dump());
+        // 对于不能被数据加固的指令，进行地址加固
+        // 将 MI 移入 HardenLoadAddr 列表，这个列表的指令将进行地址加固
         HardenLoadAddr.insert(&MI);
+        // 如果 load 存在地址基址寄存器，将其加入 HardenedAddrRegs 列表
+        // 标记这个寄存器为需要加固的
         if (BaseReg)
           HardenedAddrRegs.insert(BaseReg);
+        // 如果 load 存在地址索引寄存器，将其加入 HardenedAddrRegs 列表
+        // 标记这个寄存器为需要加固的
         if (IndexReg)
           HardenedAddrRegs.insert(IndexReg);
 
+        // MI 是被确定为要地址加固的指令，因此 MI 的目的寄存器必然会被加固
+        // 因此，将目的寄存器加入 LoadDepRegs 列表
+        // 之后，如果有以这个寄存器作为源寄存器的 load，将被判断为数据相关
+        // 这个数据相关的 load 就不需要再加固
         for (MachineOperand &Def : MI.defs())
           if (Def.isReg())
             LoadDepRegs.set(Def.getReg());
       }
 
-    // Now re-walk the instructions in the basic block, and apply whichever
-    // hardening strategy we have elected. Note that we do this in a second
-    // pass specifically so that we have the complete set of instructions for
-    // which we will do post-load hardening and can defer it in certain
-    // circumstances.
+    // 第二轮 Pass 用于加固 load，加固策略由上一轮 Pass 决定
     for (MachineInstr &MI : MBB) {
+      // 只有 HardenLoads 从命令行开启，我们才能加固 load
       if (HardenLoads) {
-        // We cannot both require hardening the def of a load and its address.
+        // MI 不可能同时采用两个策略加固，否则程序实现逻辑有误
+        // 因此至多出现在 HardenLoadAddr 和 HardenPostLoad 之一
         assert(!(HardenLoadAddr.count(&MI) && HardenPostLoad.count(&MI)) &&
                "Requested to harden both the address and def of a load!");
 
-        // Check if this is a load whose address needs to be hardened.
+        // 如果 MI 使用地址加固策略，那么 HardenLoadAddr.erase(&MI) 非空
         if (HardenLoadAddr.erase(&MI)) {
+          // 获取 MI 的基址寄存器和索引寄存器对应的操作数对象
+          // 这部分代码在第一轮 Pass 也使用过
           const MCInstrDesc &Desc = MI.getDesc();
           int MemRefBeginIdx = X86II::getMemoryOperandNo(Desc.TSFlags);
           assert(MemRefBeginIdx >= 0 && "Cannot have an invalid index here!");
 
           MemRefBeginIdx += X86II::getOperandBias(Desc);
 
+          // 基址寄存器的操作数对象
           MachineOperand &BaseMO =
               MI.getOperand(MemRefBeginIdx + X86::AddrBaseReg);
+          // 索引寄存器的操作数对象
           MachineOperand &IndexMO =
               MI.getOperand(MemRefBeginIdx + X86::AddrIndexReg);
+          // 使用 hardenLoadAddr 函数加固 load 地址
           hardenLoadAddr(MI, BaseMO, IndexMO, AddrRegToHardenedReg);
           continue;
         }
 
-        // Test if this instruction is one of our post load instructions (and
-        // remove it from the set if so).
+        // 如果 MI 使用数据加固策略，那么 HardenPostLoad.erase(&MI) 非空
         if (HardenPostLoad.erase(&MI)) {
+          // MI 不能是 call 指令，否则在第一轮 Pass 会过滤掉这个 load
           assert(!MI.isCall() && "Must not try to post-load harden a call!");
 
-          // If this is a data-invariant load and there is no EFLAGS
-          // interference, we want to try and sink any hardening as far as
-          // possible.
+          // 如果 MI 是数据不变的 load，并且没有新定义后续可用的 EFLAGS
+          // 我们考虑对 MI 进行下沉优化，即将 MI 的数据加固延迟到使用 load 数据的指令
           if (X86InstrInfo::isDataInvariantLoad(MI) && !isEFLAGSDefLive(MI)) {
-            // Sink the instruction we'll need to harden as far as we can down
-            // the graph.
+            // 使用 sinkPostLoadHardenedInst 函数判断 MI 能否下沉
+            // 如果可以，返回下沉到的指令，否则返回 MI 本身
             MachineInstr *SunkMI = sinkPostLoadHardenedInst(MI, HardenPostLoad);
 
-            // If we managed to sink this instruction, update everything so we
-            // harden that instruction when we reach it in the instruction
-            // sequence.
+            // 如果 SunkMI != &MI，说明发现了可以下沉的指令，或者发现 MI 没有使用者
             if (SunkMI != &MI) {
-              // If in sinking there was no instruction needing to be hardened,
-              // we're done.
+              // 如果 MI 没有使用者，那么无需加固 MI
               if (!SunkMI)
                 continue;
 
-              // Otherwise, add this to the set of defs we harden.
+              // 否则，我们改为加固 SunkMI 指令的目的寄存器，将其加入 HardenPostLoad
               HardenPostLoad.insert(SunkMI);
               continue;
             }
           }
 
+          // 使用 hardenPostLoad 函数对 MI 进行数据加固，加固后的寄存器编号为 HardenedReg 
           unsigned HardenedReg = hardenPostLoad(MI);
 
-          // Mark the resulting hardened register as such so we don't re-harden.
+          // 标记 HardenedReg 被加固
           AddrRegToHardenedReg[HardenedReg] = HardenedReg;
 
           continue;
         }
 
-        // Check for an indirect call or branch that may need its input hardened
-        // even if we couldn't find the specific load used, or were able to
-        // avoid hardening it for some reason. Note that here we cannot break
-        // out afterward as we may still need to handle any call aspect of this
-        // instruction.
+        // 如果 HardenIndirectCallsAndJumps 开启，考虑加固 call 和 jmp 的地址
+        // 更确切的说，加固 call 和 jmp 的存放地址的寄存器
         if ((MI.isCall() || MI.isBranch()) && HardenIndirectCallsAndJumps)
           hardenIndirectCallOrJumpInstr(MI, AddrRegToHardenedReg);
       }
 
-      // After we finish hardening loads we handle interprocedural hardening if
-      // enabled and relevant for this instruction.
+      // 如果 HardenInterprocedurally，那么考虑防御 Spectre v1.1
+      // 即，防御推测执行期间攻击者对控制流的恶意注入
       if (!HardenInterprocedurally)
         continue;
       if (!MI.isCall() && !MI.isReturn())
         continue;
 
-      // If this is a direct return (IE, not a tail call) just directly harden
-      // it.
+      // 如果 MI 是 ret 指令，那么可能被攻击者恶意注入以篡改控制流
+      // 调用 hardenReturnInstr 加固
       if (MI.isReturn() && !MI.isCall()) {
         hardenReturnInstr(MI);
         continue;
       }
 
-      // Otherwise we have a call. We need to handle transferring the predicate
-      // state into a call and recovering it after the call returns (unless this
-      // is a tail call).
+      // 如果 MI 是 call 指令，那么需要将 predicate state 传递到被调用函数内
+      // 通过 tracePredStateThroughCall 实现 predicate state 的跨函数传递和恢复
       assert(MI.isCall() && "Should only reach here for calls!");
       tracePredStateThroughCall(MI);
     }
 
+    // 完成一个基本块的加固后，重置这些列表
     HardenPostLoad.clear();
     HardenLoadAddr.clear();
     HardenedAddrRegs.clear();
     AddrRegToHardenedReg.clear();
 
-    // Currently, we only track data-dependent loads within a basic block.
-    // FIXME: We should see if this is necessary or if we could be more
-    // aggressive here without opening up attack avenues.
+    // 目前只支持对同一个基本块内的 load 做数据相关优化
+    // 因此在每个基本块加固结束后也重置 LoadDepRegs 列表
     LoadDepRegs.clear();
   }
 }
 
-/// Save EFLAGS into the returned GPR. This can in turn be restored with
-/// `restoreEFLAGS`.
-///
-/// Note that LLVM can only lower very simple patterns of saved and restored
-/// EFLAGS registers. The restore should always be within the same basic block
-/// as the save so that no PHI nodes are inserted.
+/**
+ *  将 EFLAGS 寄存器的值存放在一个通用寄存器中，
+ *  之后可以通过 restoreEFLAGS 函数从通用寄存器中恢复。
+ *  
+ *  注意 LLVM 只能处理简单的 EFLAGS 保存和回复，它们需要在一个基本块中，
+ *  否则生成的代码复杂且效率低。
+ * 
+ *  @param MBB: 需要保存 EFLAGS 的基本块
+ *  @param InsertPt: 需要保存 EFLAGS 的位置
+ *  @param Loc: 一个封装了源代码行号、列号和相关调试元数据的对象，
+ *              主要用于在生成的机器指令中保留和传递调试信息
+ *              对于指令 MI，使用指令接口 MI.getDebugLoc 获取
+ *  @return 装有 EFLAGS 的寄存器
+ */
 unsigned X86SpeculativeLoadHardeningPass::saveEFLAGS(
     MachineBasicBlock &MBB, MachineBasicBlock::iterator InsertPt,
     DebugLoc Loc) {
-  // FIXME: Hard coding this to a 32-bit register class seems weird, but matches
-  // what instruction selection does.
+  // 新建一个 32 为寄存器，因为 EFLAGS 是 32 位的
   Register Reg = MRI->createVirtualRegister(&X86::GR32RegClass);
-  // We directly copy the FLAGS register and rely on later lowering to clean
-  // this up into the appropriate setCC instructions.
+  // 使用 COPY 指令，将 EFLAGS 复制到 Reg 寄存器
   BuildMI(MBB, InsertPt, Loc, TII->get(X86::COPY), Reg).addReg(X86::EFLAGS);
   ++NumInstsInserted;
+  // 返回寄存器 Reg，现在 Reg 装入了 EFLAGS
   return Reg;
 }
 
-/// Restore EFLAGS from the provided GPR. This should be produced by
-/// `saveEFLAGS`.
-///
-/// This must be done within the same basic block as the save in order to
-/// reliably lower.
+/**
+ *  将 EFLAGS 从通用寄存器重新载入 EFLAGS 寄存器。
+ *  这个指令必须与 saveEFLAGS 所创建的指令在同一基本块中。
+ * 
+ *  @param MBB: 需要保存 EFLAGS 的基本块
+ *  @param InsertPt: 需要保存 EFLAGS 的位置
+ *  @param Loc: 一个封装了源代码行号、列号和相关调试元数据的对象，
+ *              主要用于在生成的机器指令中保留和传递调试信息
+ *              对于指令 MI，使用指令接口 MI.getDebugLoc 获取
+ *  @param Reg: 存放 EFLAGS 的通用寄存器编号
+ * 
+ */
 void X86SpeculativeLoadHardeningPass::restoreEFLAGS(
     MachineBasicBlock &MBB, MachineBasicBlock::iterator InsertPt, DebugLoc Loc,
     unsigned Reg) {
+  // 使用 COPY 伪指令，将 EFLAGS 从 Reg 寄存器载入 EFLAGS 寄存器
   BuildMI(MBB, InsertPt, Loc, TII->get(X86::COPY), X86::EFLAGS).addReg(Reg);
   ++NumInstsInserted;
 }
 
-/// Takes the current predicate state (in a register) and merges it into the
-/// stack pointer. The state is essentially a single bit, but we merge this in
-/// a way that won't form non-canonical pointers and also will be preserved
-/// across normal stack adjustments.
+/**
+ *  将 predicate state 从通用寄存器编码到 RSP 寄存器，
+ *  编码保持 SP 地址的规范性，使得推测执行时仍然可以在一个 “非法” 的栈空间操作局部变量。
+ *  所谓规范性 (cononical)，指的是虚拟地址的最高 16 位为全 0 或者全 1。
+ *  所谓合法性（valid），指的是地址是否是允许程序访问的，不会触发缺页或者权限异常。
+ *  注意 predicate state 的所有 bit 要么为全 0，要么为全 1，
+ *  因此，即使 predicate state 有 64 位，但可以编码成 1 bit。
+ *  综上，如果 RSP 最高 16 位为 0，说明 predicate state 为 initial value，即为 0；
+ *  如果 RSP 最高 16 位为 1，说明 predicate state 为 secure mask，即全部 bit 为 1。
+ *  编码算法如下：
+ *  1. 将 predicate state 先存入一个通用寄存器 TMP；
+ *  2. 将 TMP 左移 47 位；
+ *  3. 将 TMP 和 RSP 进行 OR 运算。
+ *  如果 predicate state 为全 1，那么最终 RSP 最高 16 位为全 1；
+ *  否则 RSP 最高 16 位为全 0。
+ * 
+ *  @param MBB: 需要编码 EFLAGS 的基本块
+ *  @param InsertPt: 需要编码 EFLAGS 的位置
+ *  @param Loc: 一个封装了源代码行号、列号和相关调试元数据的对象，
+ *              主要用于在生成的机器指令中保留和传递调试信息
+ *              对于指令 MI，使用指令接口 MI.getDebugLoc 获取
+ *  @param PredStateReg: 存放 predicate state 的通用寄存器的编号
+ */
 void X86SpeculativeLoadHardeningPass::mergePredStateIntoSP(
     MachineBasicBlock &MBB, MachineBasicBlock::iterator InsertPt, DebugLoc Loc,
     unsigned PredStateReg) {
+
+  // 创建虚拟寄存器，用于存放 PredStateReg 中的 predicate state 并进行移位
   Register TmpReg = MRI->createVirtualRegister(PS->RC);
-  // FIXME: This hard codes a shift distance based on the number of bits needed
-  // to stay canonical on 64-bit. We should compute this somehow and support
-  // 32-bit as part of that.
+  // 使用移位指令，将 TmpReg 左移 47 位，使得 predicate state 存放在最高 16 位
+  // 由此可见，目前 SLH 不支持 32 位模式
+  // 移位后，标记 PredStateReg 为 Kill，在 MBB 内，后续不再使用这一寄存器
   auto ShiftI = BuildMI(MBB, InsertPt, Loc, TII->get(X86::SHL64ri), TmpReg)
                     .addReg(PredStateReg, RegState::Kill)
                     .addImm(47);
+  // 移位后，标记 EFLAGS 不再 live，因为移位是额外加的，不应该被原始程序的指令使用
   ShiftI->addRegisterDead(X86::EFLAGS, TRI);
   ++NumInstsInserted;
+
+  // 将 RSP 和 ShiftI 的目的寄存器 TmpReg 进行或运算，结果写入 RSP
   auto OrI = BuildMI(MBB, InsertPt, Loc, TII->get(X86::OR64rr), X86::RSP)
                  .addReg(X86::RSP)
                  .addReg(TmpReg, RegState::Kill);
+  // 或运算后，标记 EFLAGS 不再 live，因为移位是额外加的，不应该被原始程序的指令使用
   OrI->addRegisterDead(X86::EFLAGS, TRI);
   ++NumInstsInserted;
 }
 
-/// Extracts the predicate state stored in the high bits of the stack pointer.
+/**
+ *  从 RSP 解码 predicate state 并存入一个通用寄存器。
+ *  解码算法如下：
+ *  首先，将 RSP 的值存入一个通用寄存器 TMP；
+ *  然后，将 TMP 的值算术右移 63 位。
+ *  如果 RSP 最高 16 位为 1，那么移位后 TMP 全部 bit 为 1；
+ *  如果 RSP 最高 16 位为 0，那么移位后 TMP 为 0。
+ *  
+ *  @param MBB: 需要解码 EFLAGS 的基本块
+ *  @param InsertPt: 需要解码  EFLAGS 的位置
+ *  @param Loc: 一个封装了源代码行号、列号和相关调试元数据的对象，
+ *              主要用于在生成的机器指令中保留和传递调试信息
+ *              对于指令 MI，使用指令接口 MI.getDebugLoc 获取
+ *  @return 存放 predicate state 解码结果的通用寄存器
+ */
 unsigned X86SpeculativeLoadHardeningPass::extractPredStateFromSP(
     MachineBasicBlock &MBB, MachineBasicBlock::iterator InsertPt,
     DebugLoc Loc) {
+      
+  // 创建两个虚拟寄存器，一个用于存放最终的 predicate state，另一个用于支持中间运算
   Register PredStateReg = MRI->createVirtualRegister(PS->RC);
   Register TmpReg = MRI->createVirtualRegister(PS->RC);
 
-  // We know that the stack pointer will have any preserved predicate state in
-  // its high bit. We just want to smear this across the other bits. Turns out,
-  // this is exactly what an arithmetic right shift does.
+  // 使用 COPY 伪指令，将 RSP 移入 TmpReg
   BuildMI(MBB, InsertPt, Loc, TII->get(TargetOpcode::COPY), TmpReg)
       .addReg(X86::RSP);
+  // 创建右移指令，将 TmpReg 指令算术右移 63 位，结果存入寄存器 PredStateReg
   auto ShiftI =
       BuildMI(MBB, InsertPt, Loc, TII->get(X86::SAR64ri), PredStateReg)
           .addReg(TmpReg, RegState::Kill)
           .addImm(TRI->getRegSizeInBits(*PS->RC) - 1);
+  // 增加移位指令后，标记 EFLAGS 不再 live，因为移位是额外加的，不应该被原始程序的指令使用
   ShiftI->addRegisterDead(X86::EFLAGS, TRI);
   ++NumInstsInserted;
 
+  // 返回存放 predicate state 的通用寄存器
   return PredStateReg;
 }
 
+/**
+ *  加固一个 load 指令的地址。这个地址可能来自它的基址寄存器和索引寄存器。
+ *  例如，一个地址为 0x7f(%rax,%rcx,4)，则 %rax 为基址寄存器，%rcx 为 索引寄存器。
+ *  加固方法非常简单，将地址寄存器和存放 predicate state 的寄存器做一个 OR 运算即可。
+ *  加固地址时，主要需要考虑几个问题：
+ *  1. 这些寄存器是否已经被加固，例如，一些寄存器的数据来自其他 load，
+ *     那么，如果其他 load 已经做了数据加固，这里就无需再加固这个地址。
+ *  2. 如果寄存器是 rsp, rbp 和 rip 这种修改后会破坏程序（推测）执行的，
+ *     不进行加固，因为攻击者本身也难以利用这种寄存器来泄露数据。
+ *  3. 如果寄存器是向量寄存器，如 128 或 256 位的，需要先对 predicate state 扩展。
+ *     如果 CPU 支持 AVX512，能直接从 64 位通用寄存器扩展，否则需要额外的 mov 指令。
+ *  4. 如果 load 之后的指令，或者后继基本块需要用到 EFLAGS，那么要考虑加固对 EFLAGS
+ *     的破坏。如果 CPU 支持 BMI2，那么可以用 SHRX 代替 OR，避免位运算更新 EFLAGS；
+ *     否则，需要在 OR 运算之前，将 EFLAGS 保存，之后恢复。
+ * 
+ *  @param MI: 待加固的 load 指令
+ *  @param BaseMO: 待加固的 load 指令的基址寄存器，对应的操作数对象
+ *  @param IndexMO: 待加固的 load 指令的索引寄存器，对应的操作数对象
+ *  @param AddrRegToHardenedReg: 一个映射表，记录了已加固的寄存器，
+ *                               key 是被加固的原虚拟寄存器编号，
+ *                               value 是加固后的新虚拟寄存器编号
+ */
 void X86SpeculativeLoadHardeningPass::hardenLoadAddr(
     MachineInstr &MI, MachineOperand &BaseMO, MachineOperand &IndexMO,
     SmallDenseMap<unsigned, unsigned, 32> &AddrRegToHardenedReg) {
+
+  // 获取 MI 所属基本块以及调试信息，用于后续增加指令和保存 EFLAGS
   MachineBasicBlock &MBB = *MI.getParent();
   DebugLoc Loc = MI.getDebugLoc();
 
-  // Check if EFLAGS are alive by seeing if there is a def of them or they
-  // live-in, and then seeing if that def is in turn used.
+  // 检查 MI 之后，EFLAGS 是否是 live 的，如果是，加固过程会破坏 EFLAGS
+  // 因此需要在加固前储存 EFLAGS，并在加固后恢复 EFLAGS
   bool EFLAGSLive = isEFLAGSLive(MBB, MI.getIterator(), *TRI);
 
   SmallVector<MachineOperand *, 2> HardenOpRegs;
 
+  // isFI 检查 BaseMO 是否是 RBP 或其他栈帧相关寄存器
   if (BaseMO.isFI()) {
-    // A frame index is never a dynamically controllable load, so only
-    // harden it if we're covering fixed address loads as well.
+    // 如果基址寄存器是 RBP，那么根据 ABI，这个寄存器不会被攻击，无需加固这个寄存器
     LLVM_DEBUG(
         dbgs() << "  Skipping hardening base of explicit stack frame load: ";
         MI.dump(); dbgs() << "\n");
+  // 检查 BaseMO 是否是 RSP
   } else if (BaseMO.getReg() == X86::RSP) {
-    // Some idempotent atomic operations are lowered directly to a locked
-    // OR with 0 to the top of stack(or slightly offset from top) which uses an
-    // explicit RSP register as the base.
+    // 如果 BaseMO 是 RSP，那么不可能存在 IndexMO，也无需加固这个 BaseMO
     assert(IndexMO.getReg() == X86::NoRegister &&
            "Explicit RSP access with dynamic index!");
     LLVM_DEBUG(
         dbgs() << "  Cannot harden base of explicit RSP offset in a load!");
+  // 检查 BaseMO 是否是 RIP 以及是否存在
   } else if (BaseMO.getReg() == X86::RIP ||
              BaseMO.getReg() == X86::NoRegister) {
-    // For both RIP-relative addressed loads or absolute loads, we cannot
-    // meaningfully harden them because the address being loaded has no
-    // dynamic component.
-    //
-    // FIXME: When using a segment base (like TLS does) we end up with the
-    // dynamic address being the base plus -1 because we can't mutate the
-    // segment register here. This allows the signed 32-bit offset to point at
-    // valid segment-relative addresses and load them successfully.
+    // 如果 BaseMO 是 RIP 或者不存在，那么我们无需加固这个寄存器
     LLVM_DEBUG(
         dbgs() << "  Cannot harden base of "
                << (BaseMO.getReg() == X86::RIP ? "RIP-relative" : "no-base")
                << " address in a load!");
   } else {
+    // 不满足上述情况时，我们将 BaseMO 存入 HardenOpRegs 准备加固
     assert(BaseMO.isReg() &&
            "Only allowed to have a frame index or register base.");
     HardenOpRegs.push_back(&BaseMO);
   }
 
+  // 如果 IndexMO 存在，且我们没有加固 BaseMO
+  // 那么我们需要加固 IndexMO
   if (IndexMO.getReg() != X86::NoRegister &&
       (HardenOpRegs.empty() ||
        HardenOpRegs.front()->getReg() != IndexMO.getReg()))
     HardenOpRegs.push_back(&IndexMO);
 
+  // 我们至少需要加固 BaseMO 或 IndexMO 之一，否则这个 load 不会被判定为需要加固
   assert((HardenOpRegs.size() == 1 || HardenOpRegs.size() == 2) &&
          "Should have exactly one or two registers to harden!");
   assert((HardenOpRegs.size() == 1 ||
           HardenOpRegs[0]->getReg() != HardenOpRegs[1]->getReg()) &&
          "Should not have two of the same registers!");
 
-  // Remove any registers that have alreaded been checked.
+  // 如果 HardenOpRegs 中的寄存器已经被数据加固，那么这里无需再加固，把寄存器移除列表
   llvm::erase_if(HardenOpRegs, [&](MachineOperand *Op) {
-    // See if this operand's register has already been checked.
+    // 判断寄存器是否已被加固
     auto It = AddrRegToHardenedReg.find(Op->getReg());
     if (It == AddrRegToHardenedReg.end())
-      // Not checked, so retain this one.
+      // 如果寄存器 Op 还未加固，那么不移出 HardenOpRegs
       return false;
 
-    // Otherwise, we can directly update this operand and remove it.
+    // 否则，无需加固，同时更新它的寄存器编号
     Op->setReg(It->second);
     return true;
   });
-  // If there are none left, we're done.
+  // 如果没有需要加固的寄存器，退出函数
   if (HardenOpRegs.empty())
     return;
 
-  // Compute the current predicate state.
+  // 使用 PS->SSA 获取基本块中的 predicate state
   unsigned StateReg = PS->SSA.GetValueAtEndOfBlock(&MBB);
 
+  // 将插入点选择在 MI 之前
   auto InsertPt = MI.getIterator();
 
-  // If EFLAGS are live and we don't have access to instructions that avoid
-  // clobbering EFLAGS we need to save and restore them. This in turn makes
-  // the EFLAGS no longer live.
+  // 这个变量记录了是否调用 saveEFLAGS
+  // 如果调用，标记保存了存放 EFLAGS 的虚拟寄存器编号
+  // 在加固结束后需要调用 restoreEFLAGS 函数，从相应寄存器中恢复 EFLAGS 
   unsigned FlagsReg = 0;
+  // 如果 EFLAGS 是 live 的，且机器架构不支持 BMI2 指令集
+  // 那么为了避免加固指令更新 EFLAGS，需要在加固前存储旧的 EFLAGS 并在加固后恢复
   if (EFLAGSLive && !Subtarget->hasBMI2()) {
+    // 存储 EFLAGS 后，可以将 EFLAGSLive 置为 false，后续不必担心破坏 EFLAGS
     EFLAGSLive = false;
+    // 调用 saveEFLAGS 函数后，返回存放 EFLAGS 的虚拟寄存器编号
     FlagsReg = saveEFLAGS(MBB, InsertPt, Loc);
   }
 
+  // 依次加固 HardenOpRegs 的寄存器 Op
   for (MachineOperand *Op : HardenOpRegs) {
+    // 获取寄存器编号
     Register OpReg = Op->getReg();
+    // 获取寄存器类型
     auto *OpRC = MRI->getRegClass(OpReg);
+    // 创建一个虚拟寄存器，用于存放加固后的地址
     Register TmpReg = MRI->createVirtualRegister(OpRC);
 
-    // If this is a vector register, we'll need somewhat custom logic to handle
-    // hardening it.
+    // 如果待加固寄存器为向量寄存器，需要将 predicate state 先放入向量寄存器后再加固
+    // hasVLX 表示目标处理器是否支持 AVX-512 VL（Vector Length）扩展指令集
+    // 如果不支持，且待加固寄存器为 128 或 256 位
+    // 那么，为了将 predicate state 扩展到 128 位，需要先把 StateReg 移入向量寄存器
+    // 再扩展 StateReg 到 128 或 256 位
     if (!Subtarget->hasVLX() && (OpRC->hasSuperClassEq(&X86::VR128RegClass) ||
                                  OpRC->hasSuperClassEq(&X86::VR256RegClass))) {
       assert(Subtarget->hasAVX2() && "AVX2-specific register classes!");
       bool Is128Bit = OpRC->hasSuperClassEq(&X86::VR128RegClass);
 
-      // Move our state into a vector register.
-      // FIXME: We could skip this at the cost of longer encodings with AVX-512
-      // but that doesn't seem likely worth it.
+      // 创建一个向量寄存器 VStateReg，长度大于 64 位
+      // 然后创建一个指令 VMOV64toPQIrr，将 64 位寄存器 StateReg 的值移入 VStateReg
+      // StateReg 存放了 64 位的 predicate state
       Register VStateReg = MRI->createVirtualRegister(&X86::VR128RegClass);
       auto MovI =
           BuildMI(MBB, InsertPt, Loc, TII->get(X86::VMOV64toPQIrr), VStateReg)
@@ -1680,7 +2278,12 @@ void X86SpeculativeLoadHardeningPass::hardenLoadAddr(
       ++NumInstsInserted;
       LLVM_DEBUG(dbgs() << "  Inserting mov: "; MovI->dump(); dbgs() << "\n");
 
-      // Broadcast it across the vector register.
+      // 使用指令 VPBROADCASTQrr 或 VPBROADCASTQYrr 扩充 predicate state
+      // 源寄存器为 VStateReg
+      // 如果 VStateReg 为 128 位，使用前者将 predicate state 扩充到 128 位
+      // 如果 VStateReg 为 256 位，使用前者将 predicate state 扩充到 256 位
+      // 扩充后的 predicate state 放入寄存器 VBStateReg 中
+      // 所谓扩充 (broadcast)，是将 64 位数据复制几份移入高位并对齐
       Register VBStateReg = MRI->createVirtualRegister(OpRC);
       auto BroadcastI = BuildMI(MBB, InsertPt, Loc,
                                 TII->get(Is128Bit ? X86::VPBROADCASTQrr
@@ -1692,7 +2295,9 @@ void X86SpeculativeLoadHardeningPass::hardenLoadAddr(
       LLVM_DEBUG(dbgs() << "  Inserting broadcast: "; BroadcastI->dump();
                  dbgs() << "\n");
 
-      // Merge our potential poison state into the value with a vector or.
+      // 创建 OR 指令，将扩充后的 predicate state 与加固前寄存器 OpReg 进行掩码运算
+      // predicate state 存放在源寄存器 VBStateReg
+      // 运算结果写入 TmpReg 寄存器，TmpReg 就是加固后的地址寄存器
       auto OrI =
           BuildMI(MBB, InsertPt, Loc,
                   TII->get(Is128Bit ? X86::VPORrr : X86::VPORYrr), TmpReg)
@@ -1704,17 +2309,25 @@ void X86SpeculativeLoadHardeningPass::hardenLoadAddr(
     } else if (OpRC->hasSuperClassEq(&X86::VR128XRegClass) ||
                OpRC->hasSuperClassEq(&X86::VR256XRegClass) ||
                OpRC->hasSuperClassEq(&X86::VR512RegClass)) {
+    // 如果支持 AVX-512，那么有以下两个区别：
+    // 1. 向量寄存器可能是 128, 256 或 512 位，512 位是 AVX-512 的额外支持
+    // 2. 允许直接将 64 位寄存器自动扩展到向量寄存器，省了一个 mov 操作
       assert(Subtarget->hasAVX512() && "AVX512-specific register classes!");
+      // 判断待加固寄存器是多少位的
       bool Is128Bit = OpRC->hasSuperClassEq(&X86::VR128XRegClass);
       bool Is256Bit = OpRC->hasSuperClassEq(&X86::VR256XRegClass);
       if (Is128Bit || Is256Bit)
         assert(Subtarget->hasVLX() && "AVX512VL-specific register classes!");
+      // AVX-512 支持直接用 VPBROADCASTQrZrr (以及不同位宽变种) 扩展 64 位寄存器
+      // 所谓扩充 (broadcast)，是将 64 位数据复制几份移入高位并对齐
 
-      // Broadcast our state into a vector register.
+      // 创建一个虚拟寄存器 VStateReg，用于存放 predicate state 的扩充后结果
       Register VStateReg = MRI->createVirtualRegister(OpRC);
       unsigned BroadcastOp = Is128Bit ? X86::VPBROADCASTQrZ128rr
                                       : Is256Bit ? X86::VPBROADCASTQrZ256rr
                                                  : X86::VPBROADCASTQrZrr;
+      // 创建一个 broadcast 指令，将 64 位的 predicate state 扩充到相应位数
+      // 目的寄存器为 VStateReg
       auto BroadcastI =
           BuildMI(MBB, InsertPt, Loc, TII->get(BroadcastOp), VStateReg)
               .addReg(StateReg);
@@ -1723,7 +2336,8 @@ void X86SpeculativeLoadHardeningPass::hardenLoadAddr(
       LLVM_DEBUG(dbgs() << "  Inserting broadcast: "; BroadcastI->dump();
                  dbgs() << "\n");
 
-      // Merge our potential poison state into the value with a vector or.
+      // 进行掩码运算，不同位宽需要使用不同的向量 or 运算操作码
+      // 运算结果存入 TmpReg，这就是加固后的地址
       unsigned OrOp = Is128Bit ? X86::VPORQZ128rr
                                : Is256Bit ? X86::VPORQZ256rr : X86::VPORQZrr;
       auto OrI = BuildMI(MBB, InsertPt, Loc, TII->get(OrOp), TmpReg)
@@ -1733,12 +2347,24 @@ void X86SpeculativeLoadHardeningPass::hardenLoadAddr(
       ++NumInstsInserted;
       LLVM_DEBUG(dbgs() << "  Inserting or: "; OrI->dump(); dbgs() << "\n");
     } else {
-      // FIXME: Need to support GR32 here for 32-bit code.
+      // 如果 OpPC 不是向量寄存器，那么就是 64 位通过寄存器
       assert(OpRC->hasSuperClassEq(&X86::GR64RegClass) &&
              "Not a supported register class for address hardening!");
 
+      // 如果 EFLAGS 在 load 之后不被其他指令使用，那么可以安心地用掩码运算加固地址
+      // 否则，由于掩码运算会修改 EFLAGS，可能导致程序出错，因此要花额外精力解决问题
+      // 解决方案有两个：
+      // 1. CPU 支持 hasBMI2 扩展，那么使用 SHRX 指令代替 or 指令进行掩码运算，
+      //    运算效果相同，但 SHRX 不会更新 EFLAGS
+      // 2. CPU 不支持 hasBMI2 扩展，那么需要用 saveEFLAGS 函数保存 EFLAGS，
+      //    在掩码运算后，使用 restoreEFLAGS 恢复 EFLAGS
+      //    如果 CPU 不支持 hasBMI2 扩展，那么在前面就已经调用了 saveEFLAGS，
+      //    并且已经将 EFLAGSLive 置为 false，因此会走创建 or 指令的语句
       if (!EFLAGSLive) {
-        // Merge our potential poison state into the value with an or.
+        // 如果 EFLAGS 不是 live 的，那么可以直接用 or 进行掩码运算
+        // 在 load 之前插入 or 指令，源寄存器为 StateReg 和 OpReg
+        // StateReg 存放 predicate state，OpReg 存放加固前地址
+        // 加固后地址存放在 TmpReg 寄存器
         auto OrI = BuildMI(MBB, InsertPt, Loc, TII->get(X86::OR64rr), TmpReg)
                        .addReg(StateReg)
                        .addReg(OpReg);
@@ -1746,8 +2372,10 @@ void X86SpeculativeLoadHardeningPass::hardenLoadAddr(
         ++NumInstsInserted;
         LLVM_DEBUG(dbgs() << "  Inserting or: "; OrI->dump(); dbgs() << "\n");
       } else {
-        // We need to avoid touching EFLAGS so shift out all but the least
-        // significant bit using the instruction that doesn't update flags.
+        // CPU 支持 hasBMI2 扩展，用 SHRX64rr 代替 OR64rr
+        // 源寄存器为 StateReg 和 OpReg
+        // StateReg 存放 predicate state，OpReg 存放加固前地址
+        // 加固后地址存放在 TmpReg 寄存器
         auto ShiftI =
             BuildMI(MBB, InsertPt, Loc, TII->get(X86::SHRX64rr), TmpReg)
                 .addReg(OpReg)
@@ -1759,7 +2387,11 @@ void X86SpeculativeLoadHardeningPass::hardenLoadAddr(
       }
     }
 
-    // Record this register as checked and update the operand.
+    // 如果对 Op 寄存器进行了加固，那么 Op 之前一定不在 AddrRegToHardenedReg 中
+    // 否则会在前面就会跳过 Op
+    // 加固之后，将 Op 存入 AddrRegToHardenedReg，映射到加固后寄存器 TmpReg
+    // 然后将 Op 操作数对象的寄存器编号直接改为 TmpReg
+    // 这个方法能够直接在虚拟寄存器层面调整指令源操作数，还是很方便的
     assert(!AddrRegToHardenedReg.count(Op->getReg()) &&
            "Should not have checked this register yet!");
     AddrRegToHardenedReg[Op->getReg()] = TmpReg;
@@ -1767,97 +2399,158 @@ void X86SpeculativeLoadHardeningPass::hardenLoadAddr(
     ++NumAddrRegsHardened;
   }
 
-  // And restore the flags if needed.
+  // 如果之前调用了 saveEFLAGS，那么对指令 MI 加固结束后
+  // 需要用 restoreEFLAGS 恢复 EFLAGS
   if (FlagsReg)
     restoreEFLAGS(MBB, InsertPt, Loc, FlagsReg);
 }
 
+/**
+ *  判断一条即将被数据加固的 load 指令 MI，能否 “下沉”(sink) 到另一个指令 UseMI 进行加固。
+ *  所谓下沉，指的是 MI 所 load 的数据不在 load 之后立刻加固，而是在作为源操作数被用到的时候，
+ *  再加固使用这个数据的指令 UseMI 的目的寄存器，从而提升推测执行的性能。
+ *  满足下沉条件的指令是非常严苛的，需要满足以下条件：
+ *  1. 有且只有一个尚未被加固的使用者指令 UseMI，这个指令使用了 load 的数据；
+ *  2. UseMI 必须满足以下条件：
+ *    2.1  是唯一使用 MI 的指令 (除去那些已被加固且不计入 MI 使用者的指令)；
+ *    2.2  与 MI 在同一基本块；
+ *    2.3  是数据不变的，且不影响 EFLAGS；
+ *    2.4  更新且只更新一个寄存器；
+ *    2.5 满足 canHardenRegister 函数的条件，即目的寄存器是通用寄存器。
+ *  只有以上条件全部满足，MI 才能下沉到 UseMI 再进行数据加固。
+ * 
+ *  @param InitialMI: 即将被数据加固的 load 指令
+ *  @param HardenedInstrs: 目前已被加固的指令，用于筛选 UseMI 指令
+ *  @return 如果 InitialMI 能被下沉到一条指令，返回那条指令；
+ *          如果 InitialMI 的数据没有使用者，那么返回 nullptr；
+ *          否则返回 InitialMI 本身
+ */
 MachineInstr *X86SpeculativeLoadHardeningPass::sinkPostLoadHardenedInst(
     MachineInstr &InitialMI, SmallPtrSetImpl<MachineInstr *> &HardenedInstrs) {
+  
+  // 只有满足数据无关且不定义 live EFLAGS 的 load，才会调用这个函数来优化
   assert(X86InstrInfo::isDataInvariantLoad(InitialMI) &&
          "Cannot get here with a non-invariant load!");
   assert(!isEFLAGSDefLive(InitialMI) &&
          "Cannot get here with a data invariant load "
          "that interferes with EFLAGS!");
 
-  // See if we can sink hardening the loaded value.
+  // 这个 lambda 函数用来判断 load 的数据能否延迟加固
   auto SinkCheckToSingleUse =
       [&](MachineInstr &MI) -> Optional<MachineInstr *> {
+
+    // 获取 load 的目的寄存器编号
     Register DefReg = MI.getOperand(0).getReg();
 
-    // We need to find a single use which we can sink the check. We can
-    // primarily do this because many uses may already end up checked on their
-    // own.
+    // 遍历将 load 的目的寄存器（存放 load 数据）作为源寄存器的指令 UseMI
+    // 如果 UseMI 是唯一使用 load 数据的指令，那么将数据加固 到这条指令
+    // 这种 sink 优化能尽可能延后数据加固，从而提升推测执行的性能
+    // 但是如果有多条指令用到 load 数据且它们都尚未加固，则不使用 sink 策略
+
+    // SingleUseMI 用于判断是否只有一个指令用到了 MI 的 load 结果
     MachineInstr *SingleUseMI = nullptr;
+    // 遍历使用 MI 的 load 结果作为源操作数的指令 UseMI。
+    // 如果 UseMI 已被加固，
+    // 1. 如果 UseMI 不是 load 或者与 MI 数据无关，那么不将 UseMI 计入使用 MI 的指令，
+    // 2. 否则，MI 不能下沉。
+    // 如果 UseMI 未被加固，且满足以下全部条件，那么可以将 MI 的加固下沉至 UseMI：
+    // 1. 是唯一使用 MI 的指令 (除去那些已被加固且不计入 MI 使用者的指令)
+    // 2. 与 MI 在同一基本块
+    // 3. 是数据不变的，且不影响 EFLAGS
+    // 4. 更新且只更新一个寄存器
+    // 5. 满足 canHardenRegister 函数的条件，即目的寄存器是通用寄存器
     for (MachineInstr &UseMI : MRI->use_instructions(DefReg)) {
-      // If we're already going to harden this use, it is data invariant, it
-      // does not interfere with EFLAGS, and within our block.
+
+      // 如果 UseMI 已经被决定加固，那么进一步分析能否继续下沉 MI
       if (HardenedInstrs.count(&UseMI)) {
+        // 判断 UseMI 是否是一个被加固的 load
+        // 如果满足下列两个条件之一，则 UseMI 不是被加固的 load，
+        // 而是一条已经被其他 load 下沉的非 load 指令
+        // 那么就可以跳过 UseMI，判断能否继续下沉
         if (!X86InstrInfo::isDataInvariantLoad(UseMI) || isEFLAGSDefLive(UseMI)) {
-          // If we've already decided to harden a non-load, we must have sunk
-          // some other post-load hardened instruction to it and it must itself
-          // be data-invariant.
+          // 如果我们已经决定加固 UseMI，并且它不是数据不变的 load 指令
+          // 那么它必然是数据不变的指令，并且有其他的 load 加固下沉到了这条指令
+          // 这时我们不需要下沉 MI 到这条指令，且这条指令不计入使用 MI 数据的指令
+          // 这里注意区分 isDataInvariant 和 isDataInvariantLoad
+          // 前者约束更强，要求寄存器不能作为指令地址；后者没有这一约束
           assert(X86InstrInfo::isDataInvariant(UseMI) &&
                  "Data variant instruction being hardened!");
           continue;
         }
 
-        // Otherwise, this is a load and the load component can't be data
-        // invariant so check how this register is being used.
+        // 如果 UseMI 已经被决定加固，并且是一个需要被加固的 load，
+        // 那么 MI 不能下沉到这条 load，
+        // 并且 MI 甚至可能不能继续下沉。因为如果 UseMI 使用了 load 的数据作为地址，
+        // 那么将 MI 下沉至 UseMI 将使得攻击者将 MI 的 load 结果编码到 UseMI 地址，
+        // 使得 Spectre v1 防御失效。
+
+        // 获取 UseMI 的基址寄存器和索引寄存器对应的操作数对象
+        // 实现逻辑和 tracePredStateThroughBlocksAndHarden 相同
         const MCInstrDesc &Desc = UseMI.getDesc();
         int MemRefBeginIdx = X86II::getMemoryOperandNo(Desc.TSFlags);
         assert(MemRefBeginIdx >= 0 &&
                "Should always have mem references here!");
         MemRefBeginIdx += X86II::getOperandBias(Desc);
-
+        // 基址寄存器：BaseMO；索引寄存器：IndexMO
         MachineOperand &BaseMO =
             UseMI.getOperand(MemRefBeginIdx + X86::AddrBaseReg);
         MachineOperand &IndexMO =
             UseMI.getOperand(MemRefBeginIdx + X86::AddrIndexReg);
+
+        // 判断 UseMI 这个 load 是否以 MI 的 load 数据作为地址
         if ((BaseMO.isReg() && BaseMO.getReg() == DefReg) ||
             (IndexMO.isReg() && IndexMO.getReg() == DefReg))
-          // The load uses the register as part of its address making it not
-          // invariant.
+          // 如果这两个寄存器中有以 MI 的 load 数据作为地址的
+          // 那么 MI 不能继续下沉，否则会破坏安全性
+          // 返回空集
           return {};
 
+        // 如果 UseMI 和 MI 不存在数据相关性，那么 UseMI 不计入 MI 的使用指令
+        // 继续判断 MI 可否下沉到更后面的指令
         continue;
       }
 
+      // 如果 SingleUseMI 已经存储了一条指令，说明有 2 条以上指令用到 MI 的结果
+      // 且这 2 条指令均尚未加固
       if (SingleUseMI)
-        // We already have a single use, this would make two. Bail.
+        // 取消下沉，返回空集
         return {};
 
-      // If this single use isn't data invariant, isn't in this block, or has
-      // interfering EFLAGS, we can't sink the hardening to it.
+      // 如果 UseMI 不是数据不变的，或者 UseMI 和 MI 不在同一个基本块中，
+      // 或者 UseMI 影响了 EFLAGS，则不下沉，返回空集
       if (!X86InstrInfo::isDataInvariant(UseMI) || UseMI.getParent() != MI.getParent() ||
           isEFLAGSDefLive(UseMI))
         return {};
 
-      // If this instruction defines multiple registers bail as we won't harden
-      // all of them.
+      // 如果 UseMI 修改了多个寄存器的值，那么也不进行下沉，否则要考虑多个寄存器的加固
       if (UseMI.getDesc().getNumDefs() > 1)
         return {};
 
-      // If this register isn't a virtual register we can't walk uses of sanely,
-      // just bail. Also check that its register class is one of the ones we
-      // can harden.
+      // 如果 UseMI 的目的寄存器不是通用寄存器，或者已经是物理寄存器，那么不进行下沉
       Register UseDefReg = UseMI.getOperand(0).getReg();
       if (!Register::isVirtualRegister(UseDefReg) ||
           !canHardenRegister(UseDefReg))
         return {};
 
+      // 上述条件全部满足，那么将 SingleUseMI 更新为 UseMI，继续迭代
       SingleUseMI = &UseMI;
     }
 
-    // If SingleUseMI is still null, there is no use that needs its own
-    // checking. Otherwise, it is the single use that needs checking.
+    // MI 的目的寄存器被唯一一个未加固的指令 SingleUseMI 使用
+    // 那么可以将 MI 的数据加固下沉至 SingleUseMI 指令
     return {SingleUseMI};
   };
 
+  // 使用 SinkCheckToSingleUse 函数判断 MI 指令能否下沉到另一条指令 SingleUse
+  // 如果 MI 没有使用者，SinkCheckToSingleUse 返回 {nullptr}
+  // 如果 MI 有使用者 SingleUse 且可以下沉，那么返回这条使用者指令 {SingleUse}
+  // 如果 MI 有使用者且不可以下沉，返回空集 {}
+  // 这里需要注意 {} 和 {nullptr} 是两种情况
   MachineInstr *MI = &InitialMI;
   while (Optional<MachineInstr *> SingleUse = SinkCheckToSingleUse(*MI)) {
-    // Update which MI we're checking now.
+    // 如果 MI 可以下沉至 SingleUse，更新 MI 为 SingleUse
     MI = *SingleUse;
+    // MI 为 nullptr 说明没有 MI 没有使用者
     if (!MI)
       break;
   }
@@ -1865,23 +2558,42 @@ MachineInstr *X86SpeculativeLoadHardeningPass::sinkPostLoadHardenedInst(
   return MI;
 }
 
+/**
+ *  判断一个寄存器编号为 Reg 的寄存器是否能被加固。
+ *  如果寄存器是向量寄存器，位宽大于 8 字节，那么不能被加固；
+ *  如果寄存器是不支持 REX 前缀的寄存器，那么不能被加固；
+ *  如果寄存器不是通用寄存器，那么不能被架构；
+ *  否则寄存器可以被加固。
+ * 
+ *  简单科普 REX: REX 前缀是 X86 为了将指令集从 32 位扩展到 64 位引入的指令编码，
+ *  x86-64 是在原有的 32 位 x86 指令集基础上扩展的，为了向下兼容，REX 可以区分这两个位宽。
+ *  大多数 64 位操作数指令和涉及扩展寄存器的指令都会使用 REX 前缀。
+ * 
+ *  @param reg: 特定寄存器在后端的唯一编号，通过操作数类型的函数 getOperand(i).getReg 获取
+ *              其中 i 为操作数编号。可以通过 MRI->getRegClass(Reg) 查询寄存器详细信息
+ *  @return 编号为 reg 的寄存器是否可以被加固
+ * 
+ */
 bool X86SpeculativeLoadHardeningPass::canHardenRegister(unsigned Reg) {
+
+  // 获取 Reg 的寄存器类型
   auto *RC = MRI->getRegClass(Reg);
+
+  // 获取 Reg 的位宽
   int RegBytes = TRI->getRegSizeInBits(*RC) / 8;
   if (RegBytes > 8)
-    // We don't support post-load hardening of vectors.
+    // 如果 Reg 位宽大于 8 字节，说明是向量指令，我们不支持加固这类指令
+    // 因为我们预设的 predicate state 是 8 字节的
     return false;
 
+  // 根据位宽 RegBytes 返回比特数：{1:0, 2:1, 4:2, 8:3}
   unsigned RegIdx = Log2_32(RegBytes);
   assert(RegIdx < 4 && "Unsupported register size");
 
-  // If this register class is explicitly constrained to a class that doesn't
-  // require REX prefix, we may not be able to satisfy that constraint when
-  // emitting the hardening instructions, so bail out here.
-  // FIXME: This seems like a pretty lame hack. The way this comes up is when we
-  // end up both with a NOREX and REX-only register as operands to the hardening
-  // instructions. It would be better to fix that code to handle this situation
-  // rather than hack around it in this way.
+  // 如果 RC 不支持 REX 前缀，那么返回 false
+  // 这个方法比较 hack，因为一个 load 可能同时有一个不支持 REX 的操作数和另一个支持 的
+  // 这时我们其实可以加固另一个操作数
+  // 目前的代码并未处理这种情况
   const TargetRegisterClass *NOREXRegClasses[] = {
       &X86::GR8_NOREXRegClass, &X86::GR16_NOREXRegClass,
       &X86::GR32_NOREXRegClass, &X86::GR64_NOREXRegClass};
@@ -1891,245 +2603,280 @@ bool X86SpeculativeLoadHardeningPass::canHardenRegister(unsigned Reg) {
   const TargetRegisterClass *GPRRegClasses[] = {
       &X86::GR8RegClass, &X86::GR16RegClass, &X86::GR32RegClass,
       &X86::GR64RegClass};
+  // 如果 RC 是通用寄存器或其子类，那么返回 true，否则返回 false
   return RC->hasSuperClassEq(GPRRegClasses[RegIdx]);
 }
 
-/// Harden a value in a register.
-///
-/// This is the low-level logic to fully harden a value sitting in a register
-/// against leaking during speculative execution.
-///
-/// Unlike hardening an address that is used by a load, this routine is required
-/// to hide *all* incoming bits in the register.
-///
-/// `Reg` must be a virtual register. Currently, it is required to be a GPR no
-/// larger than the predicate state register. FIXME: We should support vector
-/// registers here by broadcasting the predicate state.
-///
-/// The new, hardened virtual register is returned. It will have the same
-/// register class as `Reg`.
+/**
+ *  对一个虚拟寄存器进行数据加固。
+ *  加固方式非常简单，就是用 OR 指令，对寄存器原有数据和 predicate state 进行掩码运算。
+ *  数据加固和地址加固的几个主要区别：
+ *  1. 存放 load 数据的寄存器不可能是 RIP, RSP 和 RBP，因此无需考虑这些寄存器。
+ *  2. load 数据位宽可能是 8, 16, 32 和 64 位，对应 1, 2, 4, 8 字节，
+ *     而地址始终是 64 位的 (SLH 仅支持 64 位)。因此，不需要考虑 REX 扩展，
+ *     在储存 EFLAGS 时，也不考虑 shrx 指令。
+ *  3. 数据加固寄存器必须满足是虚拟通用寄存器，因此无需考虑向量寄存器的加固。
+ *  加固时主要考虑以下问题：
+ *  1. load 的数据可能是 8, 16, 32 和 64 位，根据不同位宽，需要用不同位宽的
+ *     predicate state 进行掩码运算，因此如果位宽不是 64 位，需要对 predicate state
+ *     进行预先的比特压缩；
+ *  2. 同样的，load 数据的位宽不同，因此，不考虑用 shrx 指令避免对 EFLAGS 的修改，
+ *     如果 EFLAGS 在 load 之后仍然 live，那么需要用 saveEFLAGS 函数保存 EFLAGS。
+ * 
+ *  @param Reg: 存放原始 load 数据的虚拟寄存器编号
+ *  @param MBB: load 指令所处基本块
+ *  @param InsertPt: 需要插入加固指令的位置
+ *  @param Loc: 一个封装了源代码行号、列号和相关调试元数据的对象，
+ *              主要用于在生成的机器指令中保留和传递调试信息
+ *  @return 加固后虚拟寄存器的编号
+ */
 unsigned X86SpeculativeLoadHardeningPass::hardenValueInRegister(
     unsigned Reg, MachineBasicBlock &MBB, MachineBasicBlock::iterator InsertPt,
     DebugLoc Loc) {
+
+  // 待加固的寄存器必须是虚拟通用寄存器，不能是非通用寄存器或物理寄存器
   assert(canHardenRegister(Reg) && "Cannot harden this register!");
   assert(Register::isVirtualRegister(Reg) && "Cannot harden a physical register!");
 
+  // load 的目的寄存器可能是 8, 16, 32 或 64 位的，取决于 load 操作码
+  // 因此，先获取位宽，存在 Bytes 内
   auto *RC = MRI->getRegClass(Reg);
   int Bytes = TRI->getRegSizeInBits(*RC) / 8;
 
+  // 从 PS 中的 SSAUpdater 获取存放 predicate state 的 StateReg
   unsigned StateReg = PS->SSA.GetValueAtEndOfBlock(&MBB);
 
-  // FIXME: Need to teach this about 32-bit mode.
+  // 如果 load 数据为 8, 16, 32 位，那么需要将 predicate state 压缩到相应位数
+  // 然后再进行掩码运算
   if (Bytes != 8) {
+    // 获取对应的寄存器宽度，存在 SubRegImm 内
     unsigned SubRegImms[] = {X86::sub_8bit, X86::sub_16bit, X86::sub_32bit};
     unsigned SubRegImm = SubRegImms[Log2_32(Bytes)];
+    // NarrowStateReg 存放压缩后的 predicate state
     Register NarrowStateReg = MRI->createVirtualRegister(RC);
+    // 使用伪指令 COPY，将 StateReg 压缩到 SubRegImm 位后存入寄存器 NarrowStateReg
     BuildMI(MBB, InsertPt, Loc, TII->get(TargetOpcode::COPY), NarrowStateReg)
         .addReg(StateReg, 0, SubRegImm);
+    // 更新 StateReg
     StateReg = NarrowStateReg;
   }
 
+  // 类似地址加固，如果 load 之后 EFLAGS 仍是 live 的
+  // 由于加固过程会破坏 EFLAGS，因此要先保存好旧的 EFLAGS
+  // 由于 predicate state 可能不是 64 位的，因此这里不考虑 shrx 指令
+  // 直接用 saveEFLAGS 存储 EFLAGS，并返回存储寄存器 FlagsReg
   unsigned FlagsReg = 0;
   if (isEFLAGSLive(MBB, InsertPt, *TRI))
     FlagsReg = saveEFLAGS(MBB, InsertPt, Loc);
 
+  // 创建虚拟寄存器 NewReg 存放加固后的数据
   Register NewReg = MRI->createVirtualRegister(RC);
+  // 根据 load 数据的位宽选择不同的操作码
   unsigned OrOpCodes[] = {X86::OR8rr, X86::OR16rr, X86::OR32rr, X86::OR64rr};
   unsigned OrOpCode = OrOpCodes[Log2_32(Bytes)];
+  // 创建 OR 指令，对存放 load 数据的旧寄存器 Reg 进行掩码运算
+  // 运算结果存放在刚刚创建的 NewReg 中
   auto OrI = BuildMI(MBB, InsertPt, Loc, TII->get(OrOpCode), NewReg)
                  .addReg(StateReg)
                  .addReg(Reg);
+  // 标记 EFLAGS 为 dead，因为 OR 是额外加入的，它对 EFLAGS 的修改不会在原程序使用
   OrI->addRegisterDead(X86::EFLAGS, TRI);
+  // 更新调试信息
   ++NumInstsInserted;
   LLVM_DEBUG(dbgs() << "  Inserting or: "; OrI->dump(); dbgs() << "\n");
 
+  // 如果之前存放了 EFLAGS，那么在这里进行恢复
   if (FlagsReg)
     restoreEFLAGS(MBB, InsertPt, Loc, FlagsReg);
 
+  // 返回存放加固后数据的新寄存器 NewReg
   return NewReg;
 }
 
-/// Harden a load by hardening the loaded value in the defined register.
-///
-/// We can harden a non-leaking load into a register without touching the
-/// address by just hiding all of the loaded bits during misspeculation. We use
-/// an `or` instruction to do this because we set up our poison value as all
-/// ones. And the goal is just for the loaded bits to not be exposed to
-/// execution and coercing them to one is sufficient.
-///
-/// Returns the newly hardened register.
+/**
+ *  加固一个 load 的数据。可以在不修改 load 地址的情况下，直接加固 load 得到的数据。
+ *  通过将 load 的目的寄存器和存放 predicate state 的寄存器进行 OR 运算，
+ *  就能加固这个 load。
+ * 
+ *  @param MI: 待加固的指令，可能是 load，也可能是 load 的下沉指令
+ *             关于下沉的含义参见 sinkPostLoadHardenedInst 函数
+ *  @return 加固后新加的虚拟寄存器编号
+ */
 unsigned X86SpeculativeLoadHardeningPass::hardenPostLoad(MachineInstr &MI) {
+
+  // 获取 MI 所属基本块以及调试信息，用于后续增加指令和保存 EFLAGS
   MachineBasicBlock &MBB = *MI.getParent();
   DebugLoc Loc = MI.getDebugLoc();
 
+  // 获取目标操作数的寄存器类型
   auto &DefOp = MI.getOperand(0);
   Register OldDefReg = DefOp.getReg();
   auto *DefRC = MRI->getRegClass(OldDefReg);
 
-  // Because we want to completely replace the uses of this def'ed value with
-  // the hardened value, create a dedicated new register that will only be used
-  // to communicate the unhardened value to the hardening.
+  // 创建一个虚拟寄存器 UnhardenedReg，然后将 MI 的目的寄存器更新为这个寄存器。
+  // 注意，这里的修改只更新了 MI 本身的寄存器，如果后续有指令用到 MI 的 load 数据，
+  // 那么它们使用的还是 OldDefReg，
+  // 后续会使用 replaceRegWith 将 OldDefReg 修改为加固后寄存器。
+  // UnhardenedReg 存放的是 load 加固前的数据，实际上就是对 OldDefReg 做了一个替换，
+  // 做这个替换的目的是在后续 replaceRegWith 时，不影响加固时插入的新指令。
   Register UnhardenedReg = MRI->createVirtualRegister(DefRC);
   DefOp.setReg(UnhardenedReg);
 
-  // Now harden this register's value, getting a hardened reg that is safe to
-  // use. Note that we insert the instructions to compute this *after* the
-  // defining instruction, not before it.
+  // 使用 hardenValueInRegister 对 UnhardenedReg 进行加固
+  // 加固过程会增加新的 OR 运算指令，目的寄存器即存放了加固后的 load 数据
+  // 加固后的寄存器 HardenedReg 作为返回值返回
   unsigned HardenedReg = hardenValueInRegister(
       UnhardenedReg, MBB, std::next(MI.getIterator()), Loc);
 
-  // Finally, replace the old register (which now only has the uses of the
-  // original def) with the hardened register.
+  // 调用 replaceRegWith 函数，对于所有用到寄存器 OldDefReg 的指令，
+  // 将 OldDefReg 替换为加固后寄存器 HardenedReg
   MRI->replaceRegWith(/*FromReg*/ OldDefReg, /*ToReg*/ HardenedReg);
 
+  // 更新调试信息
   ++NumPostLoadRegsHardened;
+
+  // 返回加固后寄存器
   return HardenedReg;
 }
 
-/// Harden a return instruction.
-///
-/// Returns implicitly perform a load which we need to harden. Without hardening
-/// this load, an attacker my speculatively write over the return address to
-/// steer speculation of the return to an attacker controlled address. This is
-/// called Spectre v1.1 or Bounds Check Bypass Store (BCBS) and is described in
-/// this paper:
-/// https://people.csail.mit.edu/vlk/spectre11.pdf
-///
-/// We can harden this by introducing an LFENCE that will delay any load of the
-/// return address until prior instructions have retired (and thus are not being
-/// speculated), or we can harden the address used by the implicit load: the
-/// stack pointer.
-///
-/// If we are not using an LFENCE, hardening the stack pointer has an additional
-/// benefit: it allows us to pass the predicate state accumulated in this
-/// function back to the caller. In the absence of a BCBS attack on the return,
-/// the caller will typically be resumed and speculatively executed due to the
-/// Return Stack Buffer (RSB) prediction which is very accurate and has a high
-/// priority. It is possible that some code from the caller will be executed
-/// speculatively even during a BCBS-attacked return until the steering takes
-/// effect. Whenever this happens, the caller can recover the (poisoned)
-/// predicate state from the stack pointer and continue to harden loads.
+/**
+ *  加固一个 ret 指令。
+ * 
+ *  ret 指令会执行一个隐式的 load 操作，从栈顶获取返回地址，然后跳转到那个地址。
+ *  如果不加固这个 load，攻击者可能在瞬态执行中，在栈顶注入一个恶意值，从而劫持
+ *  控制流。这个攻击被称为 Spectre v1.1 (又名 Bounds Check Bypass Store, BCBS)。
+ *  相关 paper: https://people.csail.mit.edu/vlk/spectre11.pdf
+ * 
+ *  我们可以选择使用 lfence 指令来加固 ret，通过 fence 阻止 ret 的推测执行。
+ *  我们也可以加固 RSP 来防御 BCBS，如果 RSP 被修改，那么 stack 将在推测执行期间
+ *  不再有效，攻击者也就无法劫持 ret 地址。
+ *  使用加固 RSP 的方式，会带来比防御 BCBS 更大的好处，
+ *  即它允许 predicate state 的跨进程传递。
+ *  得益于 Return Stack Buffer (RSB), ret 指令的地址预测往往是准确的，
+ *  因此，BCBS 攻击往往不会成功，但推测执行能够顺利进入正确的 ret 地址。
+ *  也就是说，RSB 允许推测执行跨函数进行，
+ *  在这种场景下，使用 RSP 加固策略，能够将 predicate state 通过 RSP 传递到别的函数，
+ *  从而支持在推测执行期间的跨函数加固。
+ *  RSP 加固需要该函数和 tracePredStateThroughCall 函数交互，更多实现细节参见后者。
+ *  
+ *  @param MI: 需要加固的 ret 指令。
+ */
 void X86SpeculativeLoadHardeningPass::hardenReturnInstr(MachineInstr &MI) {
+  // 获取 MI 所属基本块、指令位置以及调试信息，用于后续编码和传递 predicate state
   MachineBasicBlock &MBB = *MI.getParent();
   DebugLoc Loc = MI.getDebugLoc();
   auto InsertPt = MI.getIterator();
 
   if (FenceCallAndRet)
-    // No need to fence here as we'll fence at the return site itself. That
-    // handles more cases than we can handle here.
+    // 如果命令行开启 FenceCallAndRet 开关，那么将在 call 之后插入 lfence
+    // 这里无需处理，并且无需跨函数传递 predicate state，直接退出即可
     return;
 
-  // Take our predicate state, shift it to the high 17 bits (so that we keep
-  // pointers canonical) and merge it into RSP. This will allow the caller to
-  // extract it when we return (speculatively).
+  // 将 predicate state 编码到 RSP，以便 predicate state 跨进程传递
+  // 编码方式：将 predicate state 编码到 RSP 最高 17 位
+  // caller 能在 callee 执行 ret 后从 RSP (推测性地) 解码 predicate state
   mergePredStateIntoSP(MBB, InsertPt, Loc, PS->SSA.GetValueAtEndOfBlock(&MBB));
 }
 
-/// Trace the predicate state through a call.
-///
-/// There are several layers of this needed to handle the full complexity of
-/// calls.
-///
-/// First, we need to send the predicate state into the called function. We do
-/// this by merging it into the high bits of the stack pointer.
-///
-/// For tail calls, this is all we need to do.
-///
-/// For calls where we might return and resume the control flow, we need to
-/// extract the predicate state from the high bits of the stack pointer after
-/// control returns from the called function.
-///
-/// We also need to verify that we intended to return to this location in the
-/// code. An attacker might arrange for the processor to mispredict the return
-/// to this valid but incorrect return address in the program rather than the
-/// correct one. See the paper on this attack, called "ret2spec" by the
-/// researchers, here:
-/// https://christian-rossow.de/publications/ret2spec-ccs2018.pdf
-///
-/// The way we verify that we returned to the correct location is by preserving
-/// the expected return address across the call. One technique involves taking
-/// advantage of the red-zone to load the return address from `8(%rsp)` where it
-/// was left by the RET instruction when it popped `%rsp`. Alternatively, we can
-/// directly save the address into a register that will be preserved across the
-/// call. We compare this intended return address against the address
-/// immediately following the call (the observed return address). If these
-/// mismatch, we have detected misspeculation and can poison our predicate
-/// state.
+/**
+ *  跨函数传递 predicate state，从而支持跨函数的 load 加固。
+ *  同时，这个函数也对 ret 的错误预测进行了检测，从而能够防御 Spectre-RSB。
+ *  关于 ret 的错误预测，参见论文 ret2spec (又名 Spectre-RSB)：
+ *  https://christian-rossow.de/publications/ret2spec-ccs2018.pdf
+ *  
+ *  对于跨函数的 predicate state 传递，该函数在执行 call 之前，
+ *  将 predicate state 编码到 RSP 的最高 17 位，参加 mergePredStateIntoSP 函数。
+ *  对于尾调用函数，即 `return f(x);` 这类将函数调用作为完整返回值的情景，
+ *  编码完毕后就完成了跨函数传递；但是，对于非尾调用函数，我们还要考虑函数返回，
+ *  因为函数返回前也会进行 predicate state 编码，因此，我们需要从 RSP 解码。
+ * 
+ *  对于 ret 错误预测时的 predicate state 生成，我们可以利用 X86 的 ABI，
+ *  比较 `-8(%rsp)` 这个地址是否是 ret 指令跳转到的地址。
+ *  这是因为在 ret 指令执行时，返回地址存在 (%rsp)，然后，CPU 会将隐式执行 `pop RSP`，
+ *  因此，ret 执行之后，正确的返回地址停留在 -8(%rsp)。
+ *  因此，在 ret 后，插入 cmp，比较 -8(%rsp) 和 call 之后那条指令的地址，
+ *  再以 NE 作为条件插入 cmov 指令，就能实现 ret 指令错误推测的检测。
+ *  因此，在开启开关 HardenIndirectCallsAndJumps 后，也能防御 Spectre-RSB。
+ * 
+ *  @param MI: 一条 call 指令，即将在这个指令所跳转的函数传递 predicate state，
+ *             同时检测这个函数的 ret 是否错误预测
+ */
 void X86SpeculativeLoadHardeningPass::tracePredStateThroughCall(
     MachineInstr &MI) {
+  // 获取 MI 所属基本块、指令位置以及调试信息，用于后续编码和传递 predicate state
   MachineBasicBlock &MBB = *MI.getParent();
   MachineFunction &MF = *MBB.getParent();
   auto InsertPt = MI.getIterator();
   DebugLoc Loc = MI.getDebugLoc();
 
+  // 如果开启 FenceCallAndRet 开关，那么在 call 之前插入 fence 指令
+  // 然后就可以退出
   if (FenceCallAndRet) {
     if (MI.isReturn())
-      // Tail call, we don't return to this function.
-      // FIXME: We should also handle noreturn calls.
+      // 如果 MI 是 ret 指令，无需处理，我们只要在 call 之前插 fence
       return;
 
-    // We don't need to fence before the call because the function should fence
-    // in its entry. However, we do need to fence after the call returns.
-    // Fencing before the return doesn't correctly handle cases where the return
-    // itself is mispredicted.
+    // 在 MI (call 指令) 之后插入 lfence 指令
+    // 虽然 FenceCallAndRet 开关会在每个函数 MF 的入口处插入 fence
+    // 但在 call 之后仍然需要插 fence，从而能够阻止 ret 指令的推测执行
     BuildMI(MBB, std::next(InsertPt), Loc, TII->get(X86::LFENCE));
     ++NumInstsInserted;
     ++NumLFENCEsInserted;
     return;
   }
 
-  // First, we transfer the predicate state into the called function by merging
-  // it into the stack pointer. This will kill the current def of the state.
+  // 获得进入基本块时的 predicate state
   unsigned StateReg = PS->SSA.GetValueAtEndOfBlock(&MBB);
+  // 在 call 之前，将 predicate state 编码到 RSP 最高 17 位
   mergePredStateIntoSP(MBB, InsertPt, Loc, StateReg);
 
-  // If this call is also a return, it is a tail call and we don't need anything
-  // else to handle it so just return. Also, if there are no further
-  // instructions and no successors, this call does not return so we can also
-  // bail.
+  // 如果 MI 既是 call 又是 ret，说明 MI 是一个尾调用
+  // 我们无需处理返回后的场景，因此直接退出
   if (MI.isReturn() || (std::next(InsertPt) == MBB.end() && MBB.succ_empty()))
     return;
 
-  // Create a symbol to track the return address and attach it to the call
-  // machine instruction. We will lower extra symbols attached to call
-  // instructions as label immediately following the call.
+  // 创建一个 label，名为 slh_ret_addr，并且加上一个唯一前缀，确保 label 唯一性
+  // 这个 label 记录了正确的返回地址，用于和后续可能错误推测的地址进行比较
   MCSymbol *RetSymbol =
       MF.getContext().createTempSymbol("slh_ret_addr",
                                        /*AlwaysAddSuffix*/ true);
+  // 将创建的 label 附加到机器指令 MI 上
+  // 当这条指令在汇编代码中被实际输出时，label 将出现在调用指令的后面
+  // label 的地址就是 call 之后那条指令的地址
   MI.setPostInstrSymbol(MF, RetSymbol);
 
+  // AddrRC 指向 64 位通用寄存器类型，用于后续插入指令
   const TargetRegisterClass *AddrRC = &X86::GR64RegClass;
+
+  // 如果 return address 是否能通过 -8(%rsp) 访问，
+  // 那么存放的是 -8(%rsp) 中存放的返回地址
+  // 否则 ExpectedRetAddrReg 存放 RetSymbol 对应的 label 地址
   unsigned ExpectedRetAddrReg = 0;
 
-  // If we have no red zones or if the function returns twice (possibly without
-  // using the `ret` instruction) like setjmp, we need to save the expected
-  // return address prior to the call.
+  // 如果 CPU 不支持 redzone，或者使用了 setjmp 这种 checkpoint
+  // 那么当 ret 返回后，返回地址可能不在 -8(%rsp) 这个位置
+  // 这时，需要借助 RetSymbol 显式加载 return address
+  // 红区 (red zone) 是栈指针（stack pointer）下方的一段内存区域，
+  // 可以在不修改栈指针的情况下存放临时数据。
+  // 对于有红区的目标平台，
+  // 函数调用时可以临时使用栈指针下方的一段空间，而无需显式地为此调整栈指针。
   if (!Subtarget->getFrameLowering()->has128ByteRedZone(MF) ||
       MF.exposesReturnsTwice()) {
-    // If we don't have red zones, we need to compute the expected return
-    // address prior to the call and store it in a register that lives across
-    // the call.
-    //
-    // In some ways, this is doubly satisfying as a mitigation because it will
-    // also successfully detect stack smashing bugs in some cases (typically,
-    // when a callee-saved register is used and the callee doesn't push it onto
-    // the stack). But that isn't our primary goal, so we only use it as
-    // a fallback.
-    //
-    // FIXME: It isn't clear that this is reliable in the face of
-    // rematerialization in the register allocator. We somehow need to force
-    // that to not occur for this particular instruction, and instead to spill
-    // or otherwise preserve the value computed *prior* to the call.
-    //
-    // FIXME: It is even less clear why MachineCSE can't just fold this when we
-    // end up having to use identical instructions both before and after the
-    // call to feed the comparison.
+    // 如果不支持 red zone，或者使用了 setjmp，那么无法通过 -8(%rsp) 得到返回地址
+    // 这时，SLH 采用了在 call 之前将 RetSymbol 的 label 先存放到一个寄存器的方案
+    // 这样其实起不到更新 predicate state 的效果 (只是一个 fallback，即备用方案)
+    // 但仍然能一定程度上检测 stack smashing
+
+    // 如果代码模型为 small 且代码不是位置无关 (PIC) 的，那么绝对地址在编译时已知
+    // 这时可以直接将 RetSymbol 对应的 label 地址 mov 到 ExpectedRetAddrReg 寄存器中
     ExpectedRetAddrReg = MRI->createVirtualRegister(AddrRC);
     if (MF.getTarget().getCodeModel() == CodeModel::Small &&
         !Subtarget->isPositionIndependent()) {
       BuildMI(MBB, InsertPt, Loc, TII->get(X86::MOV64ri32), ExpectedRetAddrReg)
           .addSym(RetSymbol);
     } else {
+    // 如果 MBB 绝对地址在编译时不可知，那么使用相对地址来计算
+      // 插入一个 lea 指令，计算 RetSymbol 对应的 label 地址
       BuildMI(MBB, InsertPt, Loc, TII->get(X86::LEA64r), ExpectedRetAddrReg)
           .addReg(/*Base*/ X86::RIP)
           .addImm(/*Scale*/ 1)
@@ -2139,38 +2886,38 @@ void X86SpeculativeLoadHardeningPass::tracePredStateThroughCall(
     }
   }
 
-  // Step past the call to handle when it returns.
+  // 将插入点移动到 call 之后，即 ret 指令返回之处
   ++InsertPt;
 
-  // If we didn't pre-compute the expected return address into a register, then
-  // red zones are enabled and the return address is still available on the
-  // stack immediately after the call. As the very first instruction, we load it
-  // into a register.
+  // 如果 CPU 支持从 -8(%rsp) 获取返回地址，那么就插入访存指令
+  // 将 -8(%rsp) 中存放的地址载入寄存器 ExpectedRetAddrReg 中
   if (!ExpectedRetAddrReg) {
     ExpectedRetAddrReg = MRI->createVirtualRegister(AddrRC);
     BuildMI(MBB, InsertPt, Loc, TII->get(X86::MOV64rm), ExpectedRetAddrReg)
         .addReg(/*Base*/ X86::RSP)
         .addImm(/*Scale*/ 1)
         .addReg(/*Index*/ 0)
-        .addImm(/*Displacement*/ -8) // The stack pointer has been popped, so
-                                     // the return address is 8-bytes past it.
+        .addImm(/*Displacement*/ -8) // ret 将进行 pop 操作
+                                     // 因此返回地址现在存放在 -8(%rsp)
         .addReg(/*Segment*/ 0);
   }
 
-  // Now we extract the callee's predicate state from the stack pointer.
+  // 从 ret 返回后，需要解码保存在 RSP 中的 predicate state
   unsigned NewStateReg = extractPredStateFromSP(MBB, InsertPt, Loc);
 
-  // Test the expected return address against our actual address. If we can
-  // form this basic block's address as an immediate, this is easy. Otherwise
-  // we compute it.
+  // 如果代码模型为 small 且代码不是位置无关 (PIC) 的，那么绝对地址在编译时已知
+  // 这时可以直接将 RetSymbol 对应的 label 地址和 ExpectedRetAddrReg 的地址进行比较
+  // 使用 CMP64ri32 比较指令，对一个寄存器和一个立即数进行比较
   if (MF.getTarget().getCodeModel() == CodeModel::Small &&
       !Subtarget->isPositionIndependent()) {
-    // FIXME: Could we fold this with the load? It would require careful EFLAGS
-    // management.
+    // 这里也可以直接将 -8(%rsp) 和 RetSymbol 比较
+    // 也就是把刚才插入的 load 给折叠 (fold) 了
     BuildMI(MBB, InsertPt, Loc, TII->get(X86::CMP64ri32))
         .addReg(ExpectedRetAddrReg, RegState::Kill)
         .addSym(RetSymbol);
   } else {
+  // 如果 RetSymbol 只能通过相对地址寻址，那么先插入一个 LEA 计算 RetSymbol 地址
+    // LEA 指令计算得到的地址存放在 ActualRetAddrReg 寄存器
     Register ActualRetAddrReg = MRI->createVirtualRegister(AddrRC);
     BuildMI(MBB, InsertPt, Loc, TII->get(X86::LEA64r), ActualRetAddrReg)
         .addReg(/*Base*/ X86::RIP)
@@ -2178,16 +2925,16 @@ void X86SpeculativeLoadHardeningPass::tracePredStateThroughCall(
         .addReg(/*Index*/ 0)
         .addSym(RetSymbol)
         .addReg(/*Segment*/ 0);
+    // 插入 CMP64rr 指令，比较 ActualRetAddrReg 和 ExpectedRetAddrReg
     BuildMI(MBB, InsertPt, Loc, TII->get(X86::CMP64rr))
         .addReg(ExpectedRetAddrReg, RegState::Kill)
         .addReg(ActualRetAddrReg, RegState::Kill);
   }
 
-  // Now conditionally update the predicate state we just extracted if we ended
-  // up at a different return address than expected.
+  // 插入 cmov 指令，使用之前的 cmp 的比较结果
+  // cmov 的目的寄存器 UpdatedStateReg 存放的就是更新后的 predicate state
   int PredStateSizeInBytes = TRI->getRegSizeInBits(*PS->RC) / 8;
   auto CMovOp = X86::getCMovOpcode(PredStateSizeInBytes);
-
   Register UpdatedStateReg = MRI->createVirtualRegister(PS->RC);
   auto CMovI = BuildMI(MBB, InsertPt, Loc, TII->get(CMovOp), UpdatedStateReg)
                    .addReg(NewStateReg, RegState::Kill)
@@ -2197,27 +2944,30 @@ void X86SpeculativeLoadHardeningPass::tracePredStateThroughCall(
   ++NumInstsInserted;
   LLVM_DEBUG(dbgs() << "  Inserting cmov: "; CMovI->dump(); dbgs() << "\n");
 
+  // 更新后的 UpdatedStateReg 加入 PS->SSA，以便基本块内后续指令，以及后继基本块
+  // 能够使用更新后的 predicate state
   PS->SSA.AddAvailableValue(&MBB, UpdatedStateReg);
 }
 
-/// An attacker may speculatively store over a value that is then speculatively
-/// loaded and used as the target of an indirect call or jump instruction. This
-/// is called Spectre v1.2 or Bounds Check Bypass Store (BCBS) and is described
-/// in this paper:
-/// https://people.csail.mit.edu/vlk/spectre11.pdf
-///
-/// When this happens, the speculative execution of the call or jump will end up
-/// being steered to this attacker controlled address. While most such loads
-/// will be adequately hardened already, we want to ensure that they are
-/// definitively treated as needing post-load hardening. While address hardening
-/// is sufficient to prevent secret data from leaking to the attacker, it may
-/// not be sufficient to prevent an attacker from steering speculative
-/// execution. We forcibly unfolded all relevant loads above and so will always
-/// have an opportunity to post-load harden here, we just need to scan for cases
-/// not already flagged and add them.
+/**
+ *  Spectre v1.1 (又名 Bounds Check Bypass Store, BCBS) 不仅能通过 store，
+ *  将攻击者控制的值注入 stack，在瞬态执行时劫持 ret 的控制流；
+ *  也能通过注入 call 和 jmp 的地址寄存器，在瞬态执行时劫持 call 和 jmp 的控制流。
+ *  相关 paper: https://people.csail.mit.edu/vlk/spectre11.pdf
+ * 
+ *  这并不是 Spectre v2 或者 Spectre RSB 这种触发新的推测执行，而是在 Spectre v1
+ *  的瞬态执行中，确定性地劫持控制流。因此，SLH 可以通过加固地址寄存器，来防御
+ *  Spectre v1.1 这种瞬态 store 的攻击。
+ * 
+ *  @param MI: 代加固的 call 指令或 jmp 指令
+ *  @param AddrRegToHardenedReg: 基本块中目前已被加固的寄存器映射表
+ *                               key 是被加固的原虚拟寄存器编号，
+ *                               value 是加固后的新虚拟寄存器编号
+ */
 void X86SpeculativeLoadHardeningPass::hardenIndirectCallOrJumpInstr(
     MachineInstr &MI,
     SmallDenseMap<unsigned, unsigned, 32> &AddrRegToHardenedReg) {
+  
   switch (MI.getOpcode()) {
   case X86::FARCALL16m:
   case X86::FARCALL32m:
@@ -2225,55 +2975,63 @@ void X86SpeculativeLoadHardeningPass::hardenIndirectCallOrJumpInstr(
   case X86::FARJMP16m:
   case X86::FARJMP32m:
   case X86::FARJMP64m:
-    // We don't need to harden either far calls or far jumps as they are
-    // safe from Spectre.
+    // 不加固长跳转指令，因为它们不会受到 Spectre 攻击
     return;
 
   default:
     break;
   }
 
-  // We should never see a loading instruction at this point, as those should
-  // have been unfolded.
+  // MI 本身不是带有 load 的分支指令，因为这类指令已经被展开了
+  // 详情参考 TII->unfoldMemoryOperand 函数的调用
   assert(!MI.mayLoad() && "Found a lingering loading instruction!");
 
-  // If the first operand isn't a register, this is a branch or call
-  // instruction with an immediate operand which doesn't need to be hardened.
+  // 如果分支指令的第一个操作数不是寄存器，说明这是一个直接分支指令，不会被毒化，无需加固
   if (!MI.getOperand(0).isReg())
     return;
 
-  // For all of these, the target register is the first operand of the
-  // instruction.
+  // 如果第一个操作数是寄存器，那么获取第一个操作数对应的初始寄存器
   auto &TargetOp = MI.getOperand(0);
   Register OldTargetReg = TargetOp.getReg();
 
-  // Try to lookup a hardened version of this register. We retain a reference
-  // here as we want to update the map to track any newly computed hardened
-  // register.
+  // 如果这个寄存器已经被加固，那么就获取加固后寄存器
   unsigned &HardenedTargetReg = AddrRegToHardenedReg[OldTargetReg];
 
-  // If we don't have a hardened register yet, compute one. Otherwise, just use
-  // the already hardened register.
-  //
-  // FIXME: It is a little suspect that we use partially hardened registers that
-  // only feed addresses. The complexity of partial hardening with SHRX
-  // continues to pile up. Should definitively measure its value and consider
-  // eliminating it.
+  // 如果寄存器还未加固，那么调用 hardenValueInRegister 函数进行加固
+  // 加固后寄存器为 HardenedTargetReg
   if (!HardenedTargetReg)
     HardenedTargetReg = hardenValueInRegister(
         OldTargetReg, *MI.getParent(), MI.getIterator(), MI.getDebugLoc());
 
-  // Set the target operand to the hardened register.
+  // 设置第一个操作数对应的寄存器为加固后的寄存器
   TargetOp.setReg(HardenedTargetReg);
 
+  // 更新调试信息
   ++NumCallsOrJumpsHardened;
 }
 
+/**
+ * ====================================== 
+ *  X86SpeculativeLoadHardeningPass 注册 
+ * ======================================
+ */
+
+// 声明与初始化 X86SpeculativeLoadHardeningPass
+// 第一个参数是 Pass 的 LLVM 类
+// 第二个参数 PASS_KEY 是 Pass 的唯一标识符（字符串常量），在注册和查找 Pass 时使用
+// 第三个参数是 Pass 的描述
+// 第四个参数表示 Pass 是 Analysis Pass (true) 还是 Transformer Pass (false)
+// 第五个参数表示 Pass 是否修改 CFG，即控制流图 (true / false)
 INITIALIZE_PASS_BEGIN(X86SpeculativeLoadHardeningPass, PASS_KEY,
                       "X86 speculative load hardener", false, false)
 INITIALIZE_PASS_END(X86SpeculativeLoadHardeningPass, PASS_KEY,
                     "X86 speculative load hardener", false, false)
 
+// 这个函数用于在 X86TargetMachine.cpp 中给后端添加自动化的 Pass 调用
+// 添加 Pass 代码：addPass(createX86SpeculativeLoadHardeningPass());
+// X86SpeculativeLoadHardeningPass 被加在 X86PassConfig::addPreRegAlloc 中
+// 因此，后端会在寄存器分配前 (虚拟寄存器 -> 物理寄存器) 调用这个 Pass
 FunctionPass *llvm::createX86SpeculativeLoadHardeningPass() {
   return new X86SpeculativeLoadHardeningPass();
 }
+ 
\ No newline at end of file
diff --git a/llvm/lib/Target/X86/X86TargetMachine.cpp b/llvm/lib/Target/X86/X86TargetMachine.cpp
index 7344116e14a..7b47c14833b 100644
--- a/llvm/lib/Target/X86/X86TargetMachine.cpp
+++ b/llvm/lib/Target/X86/X86TargetMachine.cpp
@@ -82,6 +82,7 @@ extern "C" LLVM_EXTERNAL_VISIBILITY void LLVMInitializeX86Target() {
   initializeX86AvoidSFBPassPass(PR);
   initializeX86AvoidTrailingCallPassPass(PR);
   initializeX86SpeculativeLoadHardeningPassPass(PR);
+  initializeX86MDUMitigationPassPass(PR);
   initializeX86SpeculativeExecutionSideEffectSuppressionPass(PR);
   initializeX86FlagsCopyLoweringPassPass(PR);
   initializeX86CondBrFoldingPassPass(PR);
@@ -479,6 +480,7 @@ void X86PassConfig::addPreRegAlloc() {
   }
 
   addPass(createX86SpeculativeLoadHardeningPass());
+  addPass(createX86MDUMitigationPass()); 
   addPass(createX86FlagsCopyLoweringPass());
   addPass(createX86WinAllocaExpander());
 }
diff --git a/llvm/lib/Transforms/IPO/ForceFunctionAttrs.cpp b/llvm/lib/Transforms/IPO/ForceFunctionAttrs.cpp
index 2cb184e8d4f..2834047b8fc 100644
--- a/llvm/lib/Transforms/IPO/ForceFunctionAttrs.cpp
+++ b/llvm/lib/Transforms/IPO/ForceFunctionAttrs.cpp
@@ -61,6 +61,7 @@ static Attribute::AttrKind parseAttrKind(StringRef Kind) {
       .Case("sanitize_thread", Attribute::SanitizeThread)
       .Case("sanitize_memtag", Attribute::SanitizeMemTag)
       .Case("speculative_load_hardening", Attribute::SpeculativeLoadHardening)
+      .Case("mdu_mitigation", Attribute::MDUMitigation)
       .Case("ssp", Attribute::StackProtect)
       .Case("sspreq", Attribute::StackProtectReq)
       .Case("sspstrong", Attribute::StackProtectStrong)
diff --git a/llvm/lib/Transforms/Utils/CodeExtractor.cpp b/llvm/lib/Transforms/Utils/CodeExtractor.cpp
index 8cdbb9d3565..25a2d2d5aa7 100644
--- a/llvm/lib/Transforms/Utils/CodeExtractor.cpp
+++ b/llvm/lib/Transforms/Utils/CodeExtractor.cpp
@@ -924,6 +924,7 @@ Function *CodeExtractor::constructFunction(const ValueSet &inputs,
       case Attribute::SanitizeHWAddress:
       case Attribute::SanitizeMemTag:
       case Attribute::SpeculativeLoadHardening:
+      case Attribute::MDUMitigation:
       case Attribute::StackProtect:
       case Attribute::StackProtectReq:
       case Attribute::StackProtectStrong:
diff --git a/llvm/utils/benchmark/src/benchmark_register.h b/llvm/utils/benchmark/src/benchmark_register.h
index 0705e219f2f..6001fb8e0e4 100644
--- a/llvm/utils/benchmark/src/benchmark_register.h
+++ b/llvm/utils/benchmark/src/benchmark_register.h
@@ -2,6 +2,7 @@
 #define BENCHMARK_REGISTER_H
 
 #include <vector>
+#include <limits>
 
 #include "check.h"
 
diff --git a/llvm/utils/gn/secondary/llvm/lib/Target/X86/BUILD.gn b/llvm/utils/gn/secondary/llvm/lib/Target/X86/BUILD.gn
index 87d58156d06..84bb4f75207 100644
--- a/llvm/utils/gn/secondary/llvm/lib/Target/X86/BUILD.gn
+++ b/llvm/utils/gn/secondary/llvm/lib/Target/X86/BUILD.gn
@@ -120,6 +120,7 @@ static_library("LLVMX86CodeGen") {
     "X86ShuffleDecodeConstantPool.cpp",
     "X86SpeculativeExecutionSideEffectSuppression.cpp",
     "X86SpeculativeLoadHardening.cpp",
+    "X86MDUMitigation.cpp",
     "X86Subtarget.cpp",
     "X86TargetMachine.cpp",
     "X86TargetObjectFile.cpp",
